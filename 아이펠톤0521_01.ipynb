{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPI/noaLL5bAFwHbgPqeMW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeounghwanPark/first-repository/blob/master/%EC%95%84%EC%9D%B4%ED%8E%A0%ED%86%A40521_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 한글 폰트 설치 (Google Colab 전용)\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq -y fonts-nanum\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# 2. matplotlib에서 한글 폰트 설정\n",
        "def set_korean_font():\n",
        "    font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"  # 폰트 경로 설정\n",
        "    if os.path.exists(font_path):\n",
        "        fm.fontManager.addfont(font_path)  # 폰트 매니저에 추가\n",
        "        plt.rc('font', family='NanumGothic')  # 기본 폰트 설정\n",
        "    else:\n",
        "        print(\"한글 폰트 경로를 찾을 수 없습니다.\")\n",
        "\n",
        "# 3. 폰트 적용 및 캐시 리셋 (중요)\n",
        "set_korean_font()\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
        "fm._load_fontmanager(try_read_cache=False)  # 폰트 매니저 캐시 리셋\n",
        "\n",
        "# 4. 한글 폰트 적용 확인을 위한 테스트 그래프\n",
        "labels = ['사과', '바나나', '포도', '딸기', '오렌지']\n",
        "values = [10, 20, 15, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, values)\n",
        "plt.xlabel(\"과일\")\n",
        "plt.ylabel(\"개수\")\n",
        "plt.title(\"과일 개수 분포\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "MStkeVJ6h_Xi",
        "outputId": "a4e35edf-232f-4b03-ac11-aa97ceb30bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5/21일 crosswalk_lat_lon.csv / streetlight_lat_lon.csv\n",
        "# 성철님 작업하신 데이터 접수후 연관 검토 진행"
      ],
      "metadata": {
        "id": "B5Qq4gFgv4DW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "ShDjcU44xbS_",
        "outputId": "c56818bb-4eb8-4f3c-eb8b-508c46e05d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03ce382d-fcf2-4afb-8c23-2937d512e199\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03ce382d-fcf2-4afb-8c23-2937d512e199\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 강남구_횡단보도_WGS84.csv to 강남구_횡단보도_WGS84.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "WyUdZImlCaMN",
        "outputId": "aacb3c95-4e3d-40d8-e0ab-0a37d0d3ab1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6970fc4-d53a-44bb-8e93-13e0cd197a84\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c6970fc4-d53a-44bb-8e93-13e0cd197a84\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving streetlight_lat_lon.csv to streetlight_lat_lon.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‘보행등’(streetlight) 데이터를 기존 분석에 결합하여, 횡단보도 설치 필요 구역을 더욱 정교하게 시각화할 수 있다."
      ],
      "metadata": {
        "id": "ndZCSApXvb5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# '강남구_횡단보도_WGS84.csv', 'streetlight_lat_lon.csv' 파일이 보여야 합니다.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "4pP5u8wCxiVi",
        "outputId": "2b905002-93e8-400a-c23e-314874c9efc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9f78f744-17eb-4c71-b40a-6ef9c6efe3f1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9f78f744-17eb-4c71-b40a-6ef9c6efe3f1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 강남구_횡단보도_WGS84.csv to 강남구_횡단보도_WGS84 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://data.seoul.go.kr/dataList/OA-22364/F/1/datasetView.do   자치구별 신호등 및 횡단보도 위치 및"
      ],
      "metadata": {
        "id": "vG2J5zgqFRGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "WCZ7lKfYFQMu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "e7910968-2bf5-47ec-cd05-cf35935351e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b0c2a35-8dc1-4d70-97aa-b1b657a069c5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b0c2a35-8dc1-4d70-97aa-b1b657a069c5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 강남구_횡단보도_WGS84.csv to 강남구_횡단보도_WGS84 (2).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from shapely.geometry import LineString\n"
      ],
      "metadata": {
        "id": "rFy_EF3mFi5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<!-- # 1. 한글 폰트 설치 (Google Colab 전용)\n",
        "!apt-get update -qq\n",
        "!apt-get install -qq -y fonts-nanum\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import os\n",
        "\n",
        "# 2. matplotlib에서 한글 폰트 설정\n",
        "def set_korean_font():\n",
        "    font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"  # 폰트 경로 설정\n",
        "    if os.path.exists(font_path):\n",
        "        fm.fontManager.addfont(font_path)  # 폰트 매니저에 추가\n",
        "        plt.rc('font', family='NanumGothic')  # 기본 폰트 설정\n",
        "    else:\n",
        "        print(\"한글 폰트 경로를 찾을 수 없습니다.\")\n",
        "\n",
        "# 3. 폰트 적용 및 캐시 리셋 (중요)\n",
        "set_korean_font()\n",
        "plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지\n",
        "fm._load_fontmanager(try_read_cache=False)  # 폰트 매니저 캐시 리셋\n",
        "\n",
        "# 4. 한글 폰트 적용 확인을 위한 테스트 그래프\n",
        "labels = ['사과', '바나나', '포도', '딸기', '오렌지']\n",
        "values = [10, 20, 15, 25, 30]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(labels, values)\n",
        "plt.xlabel(\"과일\")\n",
        "plt.ylabel(\"개수\")\n",
        "plt.title(\"과일 개수 분포\")\n",
        "plt.show()\n",
        "     \n",
        "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
        "Selecting previously unselected package fonts-nanum.\n",
        "(Reading database ... 126315 files and directories currently installed.)\n",
        "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
        "Unpacking fonts-nanum (20200506-1) ...\n",
        "Setting up fonts-nanum (20200506-1) ...\n",
        "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
        "\n",
        "\n",
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "     \n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving train___.csv to train___.csv\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# titanic.csv 파일 읽기\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "# DataFrame을 테이블 형태로 출력\n",
        "display(df.head())\n",
        "     \n",
        "<ipython-input-6-6fd71f543c44>:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttrafficCampaign\tisFirstVisit\ttotalVisits\ttotalHits\ttotalPageviews\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t15.0\t12.0\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\n",
        "5 rows × 21 columns\n",
        "\n",
        "\n",
        "# 2. 데이터 기초 EDA\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# # =================================================================\n",
        "# # 1. 데이터 불러오기 및 기본 정보 확인 (이미 df가 로드된 상태라고 가정)\n",
        "# # =================================================================\n",
        "# print(\"----- 데이터 미리보기 -----\")\n",
        "# print(df.head(), \"\\n\")\n",
        "# print(\"----- 데이터 정보 -----\")\n",
        "# print(df.info(), \"\\n\")  > 이미완\n",
        "\n",
        "# =================================================================\n",
        "# 2. 날짜 및 시간 형 변환\n",
        "# - 'date': ISO 포맷 문자열 → datetime (UTC)\n",
        "# - 'visitStartTime': Unix timestamp → datetime (UTC)\n",
        "# =================================================================\n",
        "df['date'] = pd.to_datetime(df['date'], utc=True)\n",
        "df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], unit='s', utc=True)\n",
        "\n",
        "# =================================================================\n",
        "# 3. 결측치 및 중복 데이터 확인 & 처리\n",
        "# =================================================================\n",
        "print(\"----- 결측치 확인 -----\")\n",
        "print(df.isnull().sum(), \"\\n\")\n",
        "print(\"----- 중복 데이터 수 -----\")\n",
        "print(df.duplicated().sum(), \"\\n\")\n",
        "\n",
        "# 중복 데이터 제거 (필요한 경우)\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# 기본 통계치 확인 (수치형 데이터)\n",
        "print(\"----- 수치형 데이터 기본 통계 -----\")\n",
        "print(df.describe(), \"\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# 【Retention 분석 전용 EDA 시작】\n",
        "# =================================================================\n",
        "\n",
        "# 1) 유니크 방문자 (fullVisitorId) 수 확인\n",
        "unique_visitors = df['fullVisitorId'].nunique()\n",
        "print(\"유니크 방문자 수:\", unique_visitors, \"\\n\")\n",
        "\n",
        "# 2) 전체 방문횟수(totalVisits) 분포 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['totalVisits'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title(\"전체 방문횟수 분포 (totalVisits)\")\n",
        "plt.xlabel(\"방문횟수\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 3) 코호트 분석을 위한 전처리\n",
        "# ──────────────────────────\n",
        "# - 각 방문자별 첫 방문일 계산 (first_visit_date)\n",
        "df['first_visit_date'] = df.groupby('fullVisitorId')['date'].transform('min')\n",
        "\n",
        "# - 첫 방문일과 현재 방문일 사이의 경과 일수 계산 (재방문 간격 분석)\n",
        "df['days_since_first_visit'] = (df['date'] - df['first_visit_date']).dt.days\n",
        "\n",
        "# 4) 코호트 데이터 생성\n",
        "# ──────────────────────────\n",
        "# 첫 방문일과 경과 일수별로 유니크 방문자 수 집계\n",
        "cohort_data = df.groupby(['first_visit_date', 'days_since_first_visit']).agg(\n",
        "    n_users=('fullVisitorId', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "print(\"----- 코호트 데이터 예시 -----\")\n",
        "print(cohort_data.head(), \"\\n\")\n",
        "\n",
        "# 5) 특정 코호트의 재방문 패턴 시각화\n",
        "# ──────────────────────────\n",
        "# 예를 들어, 가장 첫 방문한 코호트의 재방문률 추이 시각화\n",
        "first_cohort_date = cohort_data['first_visit_date'].min()\n",
        "first_cohort = cohort_data[cohort_data['first_visit_date'] == first_cohort_date]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(first_cohort['days_since_first_visit'], first_cohort['n_users'], marker='o')\n",
        "plt.title(\"코호트 (\" + str(first_cohort_date.date()) + \") 재방문율\")\n",
        "plt.xlabel(\"첫 방문 이후 경과 일수\")\n",
        "plt.ylabel(\"재방문 유저 수\")\n",
        "plt.show()\n",
        "\n",
        "# =================================================================\n",
        "# 클라우드 슈퍼셋에서 시각화를 진행하기 위한 데이터 파일 저장 (Retention 전용)\n",
        "# =================================================================\n",
        "cohort_data.to_csv('retention_cohort_data.csv', index=False)\n",
        "print(\"Retention 코호트 데이터가 'retention_cohort_data.csv'로 저장되었습니다.\")\n",
        "\n",
        "\n",
        "# ──────────────────────────────\n",
        "# 추가 EDA: 디바이스 및 운영체제, 브라우저 정보 분석\n",
        "# ──────────────────────────────\n",
        "\n",
        "# 디바이스 카테고리(deviceCategory) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['deviceCategory'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black')\n",
        "plt.title(\"디바이스 카테고리 분포\")\n",
        "plt.xlabel(\"디바이스\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 상위 10개 운영체제(operatingSystem) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['operatingSystem'].value_counts().head(10).plot(kind='bar', color='lightcoral', edgecolor='black')\n",
        "plt.title(\"상위 10개 운영체제 분포\")\n",
        "plt.xlabel(\"운영체제\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 상위 10개 브라우저(browser) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['browser'].value_counts().head(10).plot(kind='bar', color='lightseagreen', edgecolor='black')\n",
        "plt.title(\"상위 10개 브라우저 분포\")\n",
        "plt.xlabel(\"브라우저\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "----- 결측치 확인 -----\n",
        "fullVisitorId         0\n",
        "visitStartTime        0\n",
        "date                  0\n",
        "deviceCategory        0\n",
        "isMobile              0\n",
        "operatingSystem       0\n",
        "browser               0\n",
        "country               0\n",
        "city                  0\n",
        "trafficSource         0\n",
        "trafficMedium         0\n",
        "trafficCampaign       0\n",
        "isFirstVisit          0\n",
        "totalVisits           1\n",
        "totalHits             1\n",
        "totalPageviews        1\n",
        "totalTimeOnSite       1\n",
        "productPagesViewed    1\n",
        "addedToCart           1\n",
        "dtype: int64\n",
        "\n",
        "----- 중복 데이터 수 -----\n",
        "0\n",
        "\n",
        "----- 수치형 데이터 기본 통계 -----\n",
        "        isFirstVisit  totalVisits      totalHits  totalPageviews  \\\n",
        "count  748134.000000     748133.0  748133.000000   748133.000000   \n",
        "mean        0.776159          1.0       4.648589        3.887324   \n",
        "std         0.416817          0.0       9.888969        7.205425   \n",
        "min         0.000000          1.0       1.000000        0.000000   \n",
        "25%         1.000000          1.0       1.000000        1.000000   \n",
        "50%         1.000000          1.0       2.000000        2.000000   \n",
        "75%         1.000000          1.0       4.000000        4.000000   \n",
        "max         1.000000          1.0     500.000000      469.000000   \n",
        "\n",
        "       totalTimeOnSite  productPagesViewed    addedToCart  \n",
        "count    748133.000000       748133.000000  748133.000000  \n",
        "mean        129.751052            0.409680       0.054742  \n",
        "std         365.579472            1.771054       0.227475  \n",
        "min           0.000000            0.000000       0.000000  \n",
        "25%           0.000000            0.000000       0.000000  \n",
        "50%           2.000000            0.000000       0.000000  \n",
        "75%          82.000000            0.000000       0.000000  \n",
        "max       19017.000000          168.000000       1.000000   \n",
        "\n",
        "유니크 방문자 수: 594848\n",
        "\n",
        "\n",
        "----- 코호트 데이터 예시 -----\n",
        "           first_visit_date  days_since_first_visit  n_users\n",
        "0 2016-08-01 00:00:00+00:00                       0     1551\n",
        "1 2016-08-01 00:00:00+00:00                       1       77\n",
        "2 2016-08-01 00:00:00+00:00                       2       62\n",
        "3 2016-08-01 00:00:00+00:00                       3       41\n",
        "4 2016-08-01 00:00:00+00:00                       4       39\n",
        "\n",
        "\n",
        "Retention 코호트 데이터가 'retention_cohort_data.csv'로 저장되었습니다.\n",
        "\n",
        "\n",
        "\n",
        "코드 설명\n",
        "데이터 기본 확인 및 전처리\n",
        "\n",
        "데이터 미리보기와 info()를 통해 데이터 구조와 타입, 결측치 및 중복 데이터를 확인\n",
        "\n",
        "date와 visitStartTime 컬럼을 적절하게 datetime으로 변환하여 시간 기반 연산을 원활하게 진행할 수 있도록\n",
        "\n",
        "Retention 분석 준비\n",
        "\n",
        "유니크 방문자 수: fullVisitorId 기준 고유 방문자 수를 확인\n",
        "\n",
        "방문횟수 분포: 전체 방문횟수(totalVisits)의 분포를 히스토그램으로 시각화.\n",
        "\n",
        "코호트 전처리:\n",
        "\n",
        "각 방문자별 최초 방문일(first_visit_date)을 계산하고,\n",
        "\n",
        "재방문 간격 분석을 위해 첫 방문일과 각 방문일 간의 경과 일수(days_since_first_visit)를 산출\n",
        "\n",
        "코호트 데이터 집계:\n",
        "\n",
        "최초 방문일과 경과 일수를 기준으로 유니크 방문자 수를 집계하여 재방문 패턴을 분석할 수 있는 데이터셋을 생성\n",
        "\n",
        "Retention 시각화\n",
        "\n",
        "가장 첫 코호트를 대상으로 첫 방문 후 경과 일수에 따른 재방문 유저 수 변화를 선 그래프로 시각화\n",
        "\n",
        "클라우드 슈퍼셋 활용 준비\n",
        "\n",
        "생성된 코호트 데이터를 CSV 파일(retention_cohort_data.csv)로 저장해 클라우드 슈퍼셋에 업로드 후 추가 시각화 및 리포트 작업에 활용할 수 있도록\n",
        "\n",
        "클라우드 슈퍼셋 환경에서 추가적인 시각화 및 대시보드를 구성하면,\n",
        "\n",
        "Retention 분석 담당으로서 재방문 패턴과 유저 충성도에 대한 인사이트 도출 및\n",
        "\n",
        "보고서 작성목표\n",
        "\n",
        "추가 EDA 항목\n",
        "효용성:\n",
        "\n",
        "디바이스(예: desktop, mobile)나 운영체제, 브라우저별 분포를 알면,\n",
        "\n",
        "특정 기기나 환경에서 재방문률이 낮은 경우 UI/UX 개선이나 리텐션 전략 수립\n",
        "\n",
        "시 참고할 수 있다.\n",
        "\n",
        "혹은 전체 유저 분포를 보다 직관적으로 이해할 수 있어, 다른 팀원들과의 협업\n",
        "\n",
        "(예: Revenue, Referral 분석)에서도 공통적인 유저 특성을 공유할 때 도움이 됨.\n",
        "\n",
        "필요 여부:\n",
        "\n",
        "만약 Retention 분석 담당으로서 재방문 행동 패턴, 코호트 분류, 사용 빈도,\n",
        "\n",
        "재참여 간격에 집중하는 것이 목표라면, 이 부분은 핵심 분석에 직접적으로\n",
        "\n",
        "포함되지는 않는다.\n",
        "\n",
        "단, 추가 보조 자료로 유저의 접속환경을 파악하는 것은 추가 인사이트를\n",
        "\n",
        "제공하므로 필요할 수 있다.\n",
        "\n",
        "클라우드 슈퍼셋에서 대시보드로 확장할 때 “세그먼트별 리텐션” 혹은\n",
        "\n",
        "리텐션과 디바이스 특성 연계 분석” 등으로 활용가능.\n",
        "\n",
        "그래프 결과 해석\n",
        "전체 방문횟수 분포 (Histogram)\n",
        "데이터 내용:\n",
        "\n",
        "전체 방문횟수가 모두 1인 것으로 나타나 대부분의 고객이 단 한 번의 방문만 기록됨.\n",
        "\n",
        "해석:\n",
        "\n",
        "회사가 매우 독점적이거나 회원 가입, 혹은 접근이 제한된 형태일 경우, 일반 고객은 한 번 방문 후 정보 확인만 하고 쉽게 재방문하기 어렵거나, 재방문을 위한 절차(대기, 승인 등)가 존재할 수 있다.\n",
        "\n",
        "“못 들어가서 안달”하는 고객들의 경우, 첫 방문시 큰 관심을 보이지만 실제 재방문(또는 가입 절차 완료)이 어려워 단일 방문으로 집계될 가능성이 있다.\n",
        "\n",
        "전략적 시사점:\n",
        "\n",
        "이 결과는 접근 장벽을 낮추거나, 재방문 의사를 높이기 위한 추가 인센티브(예: 대기자 명단 업데이트, 예약형 접근 서비스 등)를 마련할 필요가 있음을 시사\n",
        "\n",
        "코호트 재방문 패턴 시각화 (Line Plot)\n",
        "데이터 내용:\n",
        "\n",
        "첫 방문 당일에는 다수의 고객(예: 1551명)이 기록되지만, 이후 재방문 고객 수가 급격히 감소함.\n",
        "\n",
        "해석:\n",
        "\n",
        "프리미엄 브랜드나 독점 서비스의 경우, 첫 방문에 많은 관심을 보이지만 실제로 정기적으로 서비스를 이용하는 고객은 매우 소수일 수 있다.\n",
        "\n",
        "이는 “입장”이 어려운 구조 때문에 초기 관심은 높으나, 재방문이나\n",
        "\n",
        "충성 고객으로 전환되는 비율이 낮아 지속적인 Retention이 관건임을 보여준다.\n",
        "\n",
        "전략적 시사점:\n",
        "\n",
        "고객이 “입장”에 성공하면 재방문하도록 유도하는 리텐션 전략(예: 성공적인\n",
        "\n",
        "회원가입 후 특별 혜택 제공, 대기자 해소를 위한 적극적 커뮤니케이션 강화 등)이\n",
        "\n",
        "필요하다.\n",
        "\n",
        "디바이스 카테고리 분포 (Bar Chart)\n",
        "데이터 내용:\n",
        "\n",
        "방문자들이 주로 사용하는 디바이스(예: 모바일, 데스크톱 등)의 분포.\n",
        "\n",
        "해석:\n",
        "\n",
        "유명 브랜드의 경우, 고객들은 다양한 디바이스를 활용해 접근할 가능성이 높다.\n",
        "\n",
        "만약 모바일 접근 비중이 높다면, 언제 어디서나 서비스를 확인하려는 “안달”하는\n",
        "\n",
        "고객의 특성이 반영된 것으로 볼 수 있다.\n",
        "\n",
        "전략적 시사점:\n",
        "\n",
        "각 디바이스 환경에 최적화된 UX/UI 개선을 통해, 고객의 첫 방문뿐 아니라 재방문\n",
        "\n",
        "경험을 향상시킬 필요가 있다.\n",
        "\n",
        "특히, 모바일 접근성을 강화해 고객의 접근 장벽을 낮추면 재방문율 개선에 도움이\n",
        "\n",
        "될 수 있다.\n",
        "\n",
        "상위 10개 운영체제 분포 (Bar Chart)\n",
        "데이터 내용:\n",
        "\n",
        "고객들이 사용 중인 상위 운영체제의 분포를 보여줌.\n",
        "\n",
        "해석:\n",
        "\n",
        "독점적이고 유명한 브랜드의 고객은 일반적으로 최신 기술을 활용하는 경향이 있을\n",
        "\n",
        "수 있으나, 동시에 전통적인 OS를 사용하는 고객도 존재할 가능성이 있다.\n",
        "\n",
        "특정 운영체제(예: Windows, iOS 등) 사용자가 현저하게 높다면, 해당 플랫폼에\n",
        "\n",
        "최적화된 경험 제공이 중요\n",
        "\n",
        "전략적 시사점:\n",
        "\n",
        "주요 운영체제를 위한 맞춤형 최적화 전략(예: 앱, 웹사이트 호환성 개선 등)을 수립해, 고객이 “들어가고 싶어 하는” 브랜드 경험을 제고해야\n",
        "\n",
        "상위 10개 브라우저 분포 (Bar Chart)\n",
        "데이터 내용:\n",
        "\n",
        "고객들이 사용 중인 주요 브라우저의 분포를 나타냄.\n",
        "\n",
        "해석:\n",
        "\n",
        "특정 브라우저(예: Chrome, Firefox 등) 사용이 두드러진다면, 그 브라우저에서의 성능 이슈나 접근성 개선이 중요한 과제로 떠오른다.\n",
        "\n",
        "유명 브랜드의 경우, 고객들이 안정적이고 프리미엄한 경험을 기대하므로\n",
        "\n",
        "브라우저별 최적화가 고객 충성도에 큰 영향을 줄 수 있다.\n",
        "\n",
        "전략적 시사점:\n",
        "\n",
        "최적의 브라우저 호환성을 보장해 고객이 언제 어디서나 원활하게 접속하고 재방문할 수 있도록 기술적 지원을 강화해야 함.\n",
        "\n",
        "종합 해석\n",
        "데이터 인사이트:\n",
        "\n",
        "전체 방문횟수와 코호트 분석 결과는, 독점적/프리미엄 서비스가 고객 유입은\n",
        "\n",
        "많으나 실제 재방문으로 이어지기 어렵다는 특성을 보여줌.\n",
        "\n",
        "이는 “사람들이 못 들어가서 안달”하는 상황과 맞물려, 첫 방문 후 고객이\n",
        "\n",
        "지속적으로 이용할 수 있도록 유도하는 Retention 전략이 매우 중요\n",
        "\n",
        "전략적 관점:\n",
        "\n",
        "접근성 개선: 고객들이 “입장”에 실패하지 않도록, 기다림 없이 원활한\n",
        "\n",
        "서비스 접근 경로를 마련해야\n",
        "\n",
        "재방문 유도: 회원 혜택, 개별 맞춤 커뮤니케이션, 예약 시스템 등으로 재방문을\n",
        "\n",
        "적극적으로 유도할 필요가 있다.\n",
        "\n",
        "사용자 환경 최적화: 디바이스, 운영체제, 브라우저별 접근성을 높여 모든 고객에게\n",
        "\n",
        "일관되고 프리미엄한 서비스를 제공함으로써, 고객 만족도를 향상시켜야 한다.\n",
        "\n",
        "이러한 해석과 전략적 인사이트를 바탕으로, 해당 회사에서는 높은 관심과 수요를\n",
        "\n",
        "실제 충성 고객으로 전환하기 위한 Retention 전략을 보다 체계적으로 수립할 수\n",
        "\n",
        "있다\n",
        "\n",
        "코호트 분석하기전 3가지 기준을 먼저 잡아보자\n",
        "1. 측정 기간 정의:\n",
        "\n",
        "주별 또는 월별 집계 – 분석 노이즈를 줄이고 패턴을 명확하게 파악할 수 있음\n",
        "\n",
        "2. 코호트 측정 기준 정의:\n",
        "\n",
        "유입/첫 방문 기준 – 최초 경험(첫 접속, 가입, 구매 등)을 기준으로\n",
        "\n",
        "그룹화하여 코호트 간 비교가 쉽도록\n",
        "\n",
        "3. 측정값 정의:\n",
        "\n",
        "활성 사용자 수/재방문 비율 – Retention의 핵심 지표로,\n",
        "\n",
        "코호트의 유지율을 효과적으로 시각화 가능\n",
        "\n",
        "\n",
        "\n",
        "     \n",
        "\n",
        "# 1. 히트맵 차트 (Heatmap)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# (1) 먼저, 각 코호트별 기본 데이터를 피벗 테이블로 재구성.\n",
        "# cohort_data: 첫 방문일(first_visit_date), 경과 일수(days_since_first_visit), 해당일 재방문 유저 수(n_users)\n",
        "cohort_pivot = cohort_data.pivot(index='first_visit_date',\n",
        "                                 columns='days_since_first_visit',\n",
        "                                 values='n_users')\n",
        "\n",
        "# (2) 각 코호트의 기준(첫 방문 당일, day 0) 사용자 수로 나눠 비율(%)로 변환\n",
        "baseline = cohort_pivot[0]\n",
        "retention_rate = cohort_pivot.divide(baseline, axis=0) * 100\n",
        "\n",
        "# (3) 히트맵 그리기\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(retention_rate, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
        "plt.title('코호트별 Retention 히트맵')\n",
        "plt.xlabel('첫 방문 후 경과 일수')\n",
        "plt.ylabel('코호트 (최초 방문일)')\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "목표:\n",
        "\n",
        "각 코호트(최초 방문일)를 행으로,\n",
        "\n",
        "최초 방문 후 경과 일수(또는 주/월)를 열로 하여,\n",
        "\n",
        "해당 일자에 남아있는 활성 사용자 비율(Retention Rate)을 색상으로 표현.\n",
        "\n",
        "x축: \"Days Since First Visit\" (첫 방문 후 경과 일수)\n",
        "\n",
        "y축: \"Cohort (First Visit Date)\" (최초 방문일, 즉 코호트 그룹)\n",
        "\n",
        "날짜가 새로운 코호트일수록 히트맵의 오른쪽까지 데이터가 적어서 삼각형 형태가 형성\n",
        "\n",
        "1~3일차가 되면 대부분의 코호트(각 행)에서 색상이 빠르게 흐려지면서(낮은 %)\n",
        "\n",
        "Retention이 크게 떨어지는 현상이 보임.\n",
        "\n",
        "시간이 지나면서(일수가 커질수록) Retention 값이 극소수만 남아 0에 가깝거나\n",
        "\n",
        "일부 코호트에서만 약간의 잔존율이 관찰됨.\n",
        "\n",
        "히트맵을 내려다볼수록(최근 코호트) x축이 충분히 경과하지 않아, 자연스럽게\n",
        "\n",
        "오른쪽 상단은 데이터가 채워지지 않는 삼각형 형태가 나타남.\n",
        "\n",
        "\n",
        "#2. 특정 코호트의 N-day Retention 선 그래프\n",
        "# 특정 코호트(예: 가장 첫 코호트)의 데이터를 선택합니다.\n",
        "specific_cohort_date = cohort_data['first_visit_date'].min()\n",
        "specific_cohort = cohort_data[cohort_data['first_visit_date'] == specific_cohort_date].copy()\n",
        "\n",
        "# 해당 코호트의 기준값: day 0의 사용자 수\n",
        "baseline_value = specific_cohort[specific_cohort['days_since_first_visit'] == 0]['n_users'].iloc[0]\n",
        "\n",
        "# Retention Rate (%) 계산\n",
        "specific_cohort['retention_rate'] = specific_cohort['n_users'] / baseline_value * 100\n",
        "\n",
        "# 선 그래프로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(specific_cohort['days_since_first_visit'], specific_cohort['retention_rate'], marker='o')\n",
        "plt.title(f\"N-day Retention for Cohort ({specific_cohort_date.date()})\")\n",
        "plt.xlabel(\"첫 방문 후 경과 일수\")\n",
        "plt.ylabel(\"남아있는 활성 사용자의 비율(%)\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "목표:\n",
        "\n",
        "특정 코호트(예: 최초 코호트)의 N-day Retention 변화를 선 그래프로 나타내어,\n",
        "\n",
        "첫 방문 후 시간이 지남에 따라 유지되는 사용자의 비율을 명확하게 보여준다.\n",
        "\n",
        "x축: \"Days Since First Visit\" (첫 방문 후 경과 일수)\n",
        "\n",
        "y축: \"Retention Rate (%)\" (해당 일자에 남아있는 활성 사용자의 비율)\n",
        "\n",
        "그래프에서는 300일차에 가까운 시점에 Retention Rate가\n",
        "\n",
        "매우 낮은 수치(거의 0% 근접)로 유지.\n",
        "\n",
        "처음 유입된 사용자들이 얼마나 빠르게 이탈하는지를 단일 라인으로 명확히 확인\n",
        "\n",
        "시사점\n",
        "\n",
        "신규 유저가 긴 시간 동안 남아있지 않는 서비스 구조임을 재확인.\n",
        "\n",
        "이를 개선하기 위해서는 가입 이후 즉시 이탈을 막는 온보딩 프로세스, 튜토리얼,\n",
        "\n",
        "마케팅 캠페인, 재참여 알림 등을 강화할 필요가 있다.\n",
        "\n",
        "\n",
        "# 3. 다수 코호트의 Retention 변화(코호트 차트)\n",
        "# 분석에 사용할 몇 개의 코호트를 선택합니다. (예: 처음 5개의 코호트)\n",
        "selected_cohorts = sorted(cohort_data['first_visit_date'].unique())[:5]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for cohort in selected_cohorts:\n",
        "    cohort_subset = cohort_data[cohort_data['first_visit_date'] == cohort].copy()\n",
        "    # 각 코호트의 day 0 기준 사용자 수 계산\n",
        "    baseline_value = cohort_subset[cohort_subset['days_since_first_visit'] == 0]['n_users'].iloc[0]\n",
        "    cohort_subset['retention_rate'] = cohort_subset['n_users'] / baseline_value * 100\n",
        "    plt.plot(cohort_subset['days_since_first_visit'],\n",
        "             cohort_subset['retention_rate'], marker='o', label=str(cohort.date()))\n",
        "\n",
        "plt.title(\"선택된 코호트의 N-day Retention 비교\")\n",
        "plt.xlabel(\"첫 방문 후 경과 일수\")\n",
        "plt.ylabel(\"Retention Rate (%)\")\n",
        "plt.legend(title=\"코호트 (최초 방문일)\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "목표:\n",
        "\n",
        "여러 코호트의 Retention Rate 변화를 한 그래프에 비교하여,\n",
        "\n",
        "시간에 따른 유지 패턴의 차이를 확인\n",
        "\n",
        "x축: \"Days Since First Visit\" (첫 방문 후 경과 일수)\n",
        "\n",
        "y축: \"Retention Rate (%)\" (해당 일자에 남아있는 활성 사용자의 비율)\n",
        "\n",
        "라인별 구분: 각 라인은 서로 다른 코호트(최초 방문일)를 나타냄.\n",
        "\n",
        "Mixpanel 및 Amplitude\n",
        "Mixpanel과 Amplitude는 자체 대시보드 및 시각화 기능을 제공하는 SaaS 분석 플랫폼\n",
        "\n",
        "시사점\n",
        "\n",
        "모든 코호트가 비슷한 형태로 급격히 떨어진다면, 초기 사용자 이탈 방지에\n",
        "\n",
        "공통된 문제가 있을 가능성이 큼.\n",
        "\n",
        "코호트별 Retention 차이가 거의 없다면, 새로운 사용자 유입 구조나 온보딩/마케팅\n",
        "\n",
        "전략 개선 효과가 아직 뚜렷이 나타나지 않았을 수도 있다.\n",
        "\n",
        "종합 결론\n",
        "초기 급락:\n",
        "\n",
        "세 그래프 모두 공통적으로 “Day 0 → Day 1” 구간에서 Retention이 매우 빠르게\n",
        "\n",
        "하락하는 모습을 보여, 초기 이탈이 큰 과제로 드러남.\n",
        "\n",
        "장기 잔존율 미미:\n",
        "\n",
        "30일, 100일, 300일 등 장기 구간으로 갈수록 Retention이 극소수 수준으로 떨어져,\n",
        "\n",
        "서비스가 꾸준히 재방문을 유도하기 어렵다는 점을 시사.\n",
        "\n",
        "코호트별 큰 차이 없음:\n",
        "\n",
        "여러 코호트를 비교하는 선 그래프나 히트맵에서, 특별히 Retention이 양호한\n",
        "\n",
        "코호트가 눈에 띄지 않는다면, 전반적인 사용자 유지 전략을 재점검해야 함.\n",
        "\n",
        "실무적 대응\n",
        "\n",
        "온보딩 최적화: 첫 방문 후 1~3일 안에 사용자 만족도를 높이고, 재방문 동기를\n",
        "\n",
        "부여할 수 있는 전략 마련이 중요.\n",
        "\n",
        "코호트별 실험:\n",
        "\n",
        "특정 기간(예: 특정 프로모션을 진행했던 주간)의 Retention이 개선되는지\n",
        "\n",
        "AB 테스트 혹은 마케팅 캠페인을 통해 확인하고, 효과적인 전략을 확대 적용.\n",
        "\n",
        "장기 이용 혜택 강화:\n",
        "\n",
        "Day 30 이상부터도 재방문할 만한 가치를 부여(예: 지속적인 콘텐츠 업데이트,\n",
        "\n",
        "멤버십 혜택 등)하여 낮은 장기 유지율을 개선할 수 있다.\n",
        "\n",
        "이로써, 그래프 전반은 “초기 뚜렷한 이탈과 꾸준한 하락세”라는 Retention 패턴을 보여주며,\n",
        "\n",
        "이를 해소하기 위해 초기 정착(온보딩) → 단기 재방문 유도 → 장기 로열티 구축의 전 단계에 걸친\n",
        "\n",
        "노력이 필요함을 한눈에 알 수 있다.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 첫번째 데이터셋 읽기\n",
        "df = pd.read_csv('train___.csv')\n",
        "\n",
        "# visitStartTime을 Unix timestamp(초)에서 datetime(UTC)로 변환\n",
        "df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], unit='s', utc=True)\n",
        "\n",
        "# date 컬럼을 datetime(UTC) 형식으로 변환\n",
        "df['date'] = pd.to_datetime(df['date'], utc=True)\n",
        "\n",
        "# 각 fullVisitorId별로 첫 방문 날짜를 계산 (첫 번째 데이터셋에 포함되지 않은 방문 기록이 있을 경우에도 이를 반영)\n",
        "df['first_visit_date'] = df.groupby('fullVisitorId')['date'].transform('min')\n",
        "\n",
        "# 현재 방문 날짜와 첫 방문 날짜의 차이를 일 단위로 계산\n",
        "df['days_since_first_visit'] = (df['date'] - df['first_visit_date']).dt.days\n",
        "\n",
        "# 결과 출력: 두번째 데이터셋과 동일한 형태의 DataFrame\n",
        "display(df.head())\n",
        "\n",
        "     \n",
        "<ipython-input-5-0aef57565ad1>:4: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('train___.csv')\n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttrafficCampaign\tisFirstVisit\ttotalVisits\ttotalHits\ttotalPageviews\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t15.0\t12.0\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\n",
        "5 rows × 21 columns\n",
        "\n",
        "\n",
        "# 4. Mixpanel 및 Amplitude 활용을 위한 데이터 준비\n",
        "# Mixpanel/Amplitude에서 활용할 코호트 데이터를 CSV 파일로 저장합니다.\n",
        "# DataFrame을 'cohort_data_for_mixpanel_amplitude.csv' 파일로 저장 (인덱스는 제외)\n",
        "df.to_csv('cohort_data_for_mixpanel_amplitude.csv', index=False)\n",
        "print(\"코호트 데이터가 'cohort_data_for_mixpanel_amplitude.csv'로 저장되었습니다.\")\n",
        "     \n",
        "코호트 데이터가 'cohort_data_for_mixpanel_amplitude.csv'로 저장되었습니다.\n",
        "\n",
        "# 파일 저장\n",
        "df.to_csv('cohort_data_for_mixpanel_amplitude.csv', index=False)\n",
        "\n",
        "# 파일 다운로드\n",
        "from google.colab import files\n",
        "files.download('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "     \n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# CSV 파일 로드 (파일 이름: cohort_data_for_mixpanel_amplitude.csv)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "# 데이터 미리보기 및 정보 확인\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "# first_visit_date가 문자열인 경우 datetime 형으로 변환 (UTC 기준)\n",
        "df['first_visit_date'] = pd.to_datetime(df['first_visit_date'], utc=True)\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 1. 코호트별 재방문 유저 수 계산\n",
        "# ---------------------------------------------------\n",
        "# fullVisitorId 컬럼을 기준으로, 각 코호트(최초 방문일)별,\n",
        "# 첫 방문 후 경과 일수(days_since_first_visit)마다 고유 방문자 수(n_users)를 계산\n",
        "cohort_data = df.groupby(['first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index(name='n_users')\n",
        "\n",
        "print(\"코호트 데이터 예시:\")\n",
        "display(cohort_data.head())\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 2. 단일 코호트의 N-day Retention 선 그래프\n",
        "# ---------------------------------------------------\n",
        "# 예시로, 가장 오래된(최초) 코호트를 선택하여 일별 재방문 유저 수 추이를 시각화\n",
        "first_cohort_date = cohort_data['first_visit_date'].min()\n",
        "first_cohort = cohort_data[cohort_data['first_visit_date'] == first_cohort_date]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(first_cohort['days_since_first_visit'], first_cohort['n_users'], marker='o')\n",
        "plt.title(\"코호트 (\" + str(first_cohort_date.date()) + \") 재방문 유저 추이\")\n",
        "plt.xlabel(\"첫 방문 후 경과 일수\")\n",
        "plt.ylabel(\"재방문 유저 수\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3. 코호트별 Retention Heatmap 만들기\n",
        "# ---------------------------------------------------\n",
        "# 피벗 테이블 형태로 전환:\n",
        "# - 인덱스: first_visit_date (코호트)\n",
        "# - 컬럼: days_since_first_visit (경과 일수)\n",
        "# - 값: n_users (고유 재방문 유저 수)\n",
        "cohort_pivot = cohort_data.pivot(index='first_visit_date', columns='days_since_first_visit', values='n_users')\n",
        "\n",
        "# 각 코호트의 Day 0(첫 방문일)의 사용자 수로 나누어 Retention Rate(%) 계산\n",
        "baseline = cohort_pivot[0]  # 모든 코호트에서 day 0 값\n",
        "retention_rate = cohort_pivot.divide(baseline, axis=0) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(retention_rate, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
        "plt.title(\"코호트별 Retention Heatmap (Retention Rate %)\")\n",
        "plt.xlabel(\"첫 방문 후 경과 일수\")\n",
        "plt.ylabel(\"코호트 (최초 방문일)\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "<ipython-input-7-b9e777550bd8>:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "데이터 미리보기:\n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttrafficCampaign\tisFirstVisit\ttotalVisits\ttotalHits\ttotalPageviews\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t15.0\t12.0\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\n",
        "5 rows × 21 columns\n",
        "\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 21 columns):\n",
        " #   Column                  Non-Null Count   Dtype  \n",
        "---  ------                  --------------   -----  \n",
        " 0   fullVisitorId           748134 non-null  object\n",
        " 1   visitStartTime          748134 non-null  object\n",
        " 2   date                    748134 non-null  object\n",
        " 3   deviceCategory          748134 non-null  object\n",
        " 4   isMobile                748134 non-null  bool   \n",
        " 5   operatingSystem         748134 non-null  object\n",
        " 6   browser                 748134 non-null  object\n",
        " 7   country                 748134 non-null  object\n",
        " 8   city                    748134 non-null  object\n",
        " 9   trafficSource           748134 non-null  object\n",
        " 10  trafficMedium           748134 non-null  object\n",
        " 11  trafficCampaign         748134 non-null  object\n",
        " 12  isFirstVisit            748134 non-null  int64  \n",
        " 13  totalVisits             748133 non-null  float64\n",
        " 14  totalHits               748133 non-null  float64\n",
        " 15  totalPageviews          748133 non-null  float64\n",
        " 16  totalTimeOnSite         748133 non-null  float64\n",
        " 17  productPagesViewed      748133 non-null  float64\n",
        " 18  addedToCart             748133 non-null  float64\n",
        " 19  first_visit_date        748134 non-null  object\n",
        " 20  days_since_first_visit  748134 non-null  int64  \n",
        "dtypes: bool(1), float64(6), int64(2), object(12)\n",
        "memory usage: 114.9+ MB\n",
        "None\n",
        "코호트 데이터 예시:\n",
        "first_visit_date\tdays_since_first_visit\tn_users\n",
        "0\t2016-08-01 00:00:00+00:00\t0\t1551\n",
        "1\t2016-08-01 00:00:00+00:00\t1\t77\n",
        "2\t2016-08-01 00:00:00+00:00\t2\t62\n",
        "3\t2016-08-01 00:00:00+00:00\t3\t41\n",
        "4\t2016-08-01 00:00:00+00:00\t4\t39\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "# titanic.csv 파일 읽기\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "# DataFrame을 테이블 형태로 출력\n",
        "display(df.head())\n",
        "     \n",
        "<ipython-input-16-6fd71f543c44>:5: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttrafficCampaign\tisFirstVisit\ttotalVisits\ttotalHits\ttotalPageviews\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t15.0\t12.0\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\n",
        "5 rows × 21 columns\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기 (파일명에 맞게 경로를 수정하세요)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv', parse_dates=['first_visit_date', 'date'])\n",
        "\n",
        "# 코호트 기준: 여기서는 first_visit_date를 주별(cohort_week)로 집계\n",
        "df['cohort_week'] = df['first_visit_date'].dt.to_period('W')\n",
        "\n",
        "# 각 코호트(주별)와 days_since_first_visit 별로 고유 사용자(fullVisitorId) 수를 계산합니다.\n",
        "cohort_data = df.groupby(['cohort_week', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗테이블을 생성하여, 각 행은 코호트(주), 각 열은 첫 방문 후 경과 일수, 값은 고유 사용자 수를 나타냅니다.\n",
        "cohort_pivot = cohort_data.pivot(index='cohort_week', columns='days_since_first_visit', values='fullVisitorId')\n",
        "\n",
        "# 각 코호트의 첫 방문일 기준 사용자 수 (days_since_first_visit == 0)를 구합니다.\n",
        "cohort_size = cohort_pivot[0]\n",
        "\n",
        "# Retention Rate를 계산: 각 코호트의 해당 일수의 사용자 수를 최초 방문일의 사용자 수로 나눕니다.\n",
        "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
        "\n",
        "# Retention Heatmap 시각화: x축은 첫 방문 후 경과 일수, y축은 코호트(주별)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(retention_matrix, aspect='auto', cmap='Blues', vmin=0, vmax=1)\n",
        "plt.colorbar(label='Retention Rate')\n",
        "plt.title('코호트 Retention 분석 (주별 코호트)')\n",
        "plt.xlabel('Days Since First Visit')\n",
        "plt.ylabel('Cohort Week')\n",
        "\n",
        "# x축, y축 tick 지정\n",
        "plt.xticks(ticks=np.arange(len(retention_matrix.columns)),\n",
        "           labels=retention_matrix.columns)\n",
        "plt.yticks(ticks=np.arange(len(retention_matrix.index)),\n",
        "           labels=retention_matrix.index.astype(str))\n",
        "\n",
        "plt.show()\n",
        "     \n",
        "<ipython-input-8-163733a9171d>:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv', parse_dates=['first_visit_date', 'date'])\n",
        "<ipython-input-8-163733a9171d>:9: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
        "  df['cohort_week'] = df['first_visit_date'].dt.to_period('W')\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기 (low_memory 옵션과 parse_dates를 사용)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv',\n",
        "                 parse_dates=['first_visit_date', 'date'],\n",
        "                 low_memory=False)\n",
        "\n",
        "# fullVisitorId 컬럼을 문자열로 변환하여 데이터 타입 혼합 문제 해결\n",
        "df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
        "\n",
        "# first_visit_date에서 timezone 정보를 제거한 후 주별(cohort_week)로 변환\n",
        "df['cohort_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# 각 코호트(주별)와 days_since_first_visit별로 고유 사용자(fullVisitorId) 수를 계산합니다.\n",
        "cohort_data = df.groupby(['cohort_week', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗테이블 생성: 각 행은 코호트(주), 각 열은 첫 방문 후 경과 일수, 값은 고유 사용자 수\n",
        "cohort_pivot = cohort_data.pivot(index='cohort_week', columns='days_since_first_visit', values='fullVisitorId')\n",
        "\n",
        "# 각 코호트의 첫 방문일(첫 날, days_since_first_visit == 0) 기준 사용자 수를 구합니다.\n",
        "cohort_size = cohort_pivot[0]\n",
        "\n",
        "# Retention Rate 계산: 각 코호트의 해당 일수의 사용자 수를 첫 방문일의 사용자 수로 나눕니다.\n",
        "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
        "\n",
        "# Retention Heatmap 시각화: x축은 첫 방문 후 경과 일수, y축은 코호트(주별)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(retention_matrix, aspect='auto', cmap='Blues', vmin=0, vmax=1)\n",
        "plt.colorbar(label='Retention Rate')\n",
        "plt.title('코호트 Retention 분석 (주별 코호트)')\n",
        "plt.xlabel('Days Since First Visit')\n",
        "plt.ylabel('Cohort Week')\n",
        "\n",
        "# x축, y축 tick 지정\n",
        "plt.xticks(ticks=np.arange(len(retention_matrix.columns)), labels=retention_matrix.columns)\n",
        "plt.yticks(ticks=np.arange(len(retention_matrix.index)), labels=retention_matrix.index.astype(str))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "실제 활용 방안\n",
        "코호트 비교:\n",
        "코호트 간(즉, 주차별)로 일정 일수 후의 Retention을 비교하여, 특정 시점에 신규 유입된 사용자들의 재방문 성향을 평가할 수 있다.\n",
        "예를 들어 “최초 방문 후 7일차 재방문율”을 코호트별로 나란히 비교해보면, 어떤 주차(또는 어떤 시점)에 유입된 사용자들의 장기 활성이 더 높은지 식별할 수 있다.\n",
        "마케팅/이벤트 평가:\n",
        "특정 기간 동안 진행한 마케팅 캠페인이나 이벤트가 실제로 사용자 재방문에 긍정적인 영향을 미쳤는지, Retention 지표가 개선되었는지 판단할 수 있다.\n",
        "프로덕트 개선 효과 측정:\n",
        "프로덕트 혹은 웹사이트 개선을 특정 시점에 적용했을 때, 그 이후로 최초 방문한 코호트의 Retention 개선 여부를 모니터링할 수 있다.\n",
        "코호트 간(즉, 주차별)로 일정 일수 후의 Retention을 비교하여,\n",
        "\n",
        "특정 시점에 신규 유입된 사용자들의 재방문 성향을 평가필요.\n",
        "\n",
        "\n",
        "# 중요데이터 검증과정으로 사용한 코드\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기 (low_memory 옵션과 parse_dates를 사용)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv',\n",
        "                 parse_dates=['first_visit_date', 'date'],\n",
        "                 low_memory=False)\n",
        "\n",
        "# fullVisitorId 컬럼을 문자열로 변환하여 데이터 타입 혼합 문제 해결\n",
        "df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
        "\n",
        "# first_visit_date에서 timezone 정보를 제거한 후 주별(cohort_week)로 변환\n",
        "df['cohort_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# 각 코호트(주별)와 days_since_first_visit별로 고유 사용자(fullVisitorId) 수를 계산합니다.\n",
        "cohort_data = df.groupby(['cohort_week', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗테이블 생성: 각 행은 코호트(주), 각 열은 첫 방문 후 경과 일수, 값은 고유 사용자 수\n",
        "cohort_pivot = cohort_data.pivot(index='cohort_week', columns='days_since_first_visit', values='fullVisitorId')\n",
        "\n",
        "# 각 코호트의 첫 방문일(첫 날, days_since_first_visit == 0) 기준 사용자 수를 구합니다.\n",
        "cohort_size = cohort_pivot[0]\n",
        "\n",
        "# Retention Rate 계산: 각 코호트의 해당 일수의 사용자 수를 첫 방문일의 사용자 수로 나눕니다.\n",
        "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
        "\n",
        "# 특정 일수(예: 7일차)의 Retention을 비교하도록 설정\n",
        "desired_day = 7\n",
        "\n",
        "# 원하는 일수의 Retention 데이터가 존재하는지 확인\n",
        "if desired_day in retention_matrix.columns:\n",
        "    # 각 코호트별로 원하는 day의 Retention Rate를 추출합니다.\n",
        "    retention_day = retention_matrix[desired_day]\n",
        "\n",
        "    # 바 차트를 사용해 코호트별 Retention Rate를 시각화합니다.\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(retention_day.index.astype(str), retention_day.values, color='skyblue')\n",
        "    plt.xlabel('코호트 주 (Cohort Week)')\n",
        "    plt.ylabel(f'{desired_day}일차 Retention Rate')\n",
        "    plt.title(f'코호트별 {desired_day}일차 Retention 비교')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"데이터에 {desired_day}일차 Retention 정보가 존재하지 않습니다.\")\n",
        "\n",
        "     \n",
        "\n",
        "“주별 코호트(cohort_week)”마다 “7일차에 남아있는 사용자 비율(Retention Rate)”을\n",
        "\n",
        "바 차트로 나타낸 것\n",
        "\n",
        "각 코호트가 첫 방문 후 7일째에 돌아오는 비율이 상당히 낮다는 점을 보여주며,\n",
        "\n",
        "이는 유입 후 7일이 지났을 때 사용자의 흥미 또는 재방문 동기가 부족할 가능성이\n",
        "\n",
        "높다는 신호이다.\n",
        "\n",
        "이런 경우,\n",
        "\n",
        "7일차 이전에 적절한 재방문 유도,\n",
        "\n",
        "7일차에 맞춘 알림/이벤트 등을 기획해 Retention을 높일 방안을 검토해볼 수 있다.\n",
        "\n",
        "1) 7일차 이전에 적절한 재방문 유도,\n",
        "\n",
        "게임화된 “연속 보상 챌린지(Progressive Reward Challenge)”\n",
        "개념:\n",
        "\n",
        "사용자가 앱이나 웹사이트를 매일 방문할 때마다 미션이나 퀘스트를 수행하도록 유도하고,\n",
        "\n",
        "각 일일 임무를 완료하면 점수, 뱃지, 또는 소정의 보상을 제공\n",
        "\n",
        "실행 전략:\n",
        "\n",
        "연속 출석 보상: 매일 출석 시 보상이 조금씩 커지거나 보너스 포인트를 제공해\n",
        "\n",
        "‘스트릭(연속 방문)’을 유지하도록 유도\n",
        "\n",
        "미션 또는 챌린지 진행:\n",
        "\n",
        "첫 방문 이후 3일차부터 6일차까지 단기 챌린지를 구성.\n",
        "\n",
        "예를 들어, ‘오늘의 미션’을 완료하면 다음 날 사용할 수 있는 쿠폰이나 특별 컨텐츠를 제공하는 방식\n",
        "\n",
        "리더보드 도입:\n",
        "\n",
        "친구와 경쟁할 수 있는 리더보드를 도입하면,\n",
        "\n",
        "사용자 간의 상호작용과 동기 부여 효과를 높일 수 있다.\n",
        "\n",
        "장점:\n",
        "\n",
        "게임 요소와 보상 체계를 도입함으로써 단순 반복 방문을 넘어서 재미와 경쟁 심리를 유발할 수 있다.\n",
        "\n",
        "사용자가 매일 새로운 챌린지를 기대하게 되어 7일차 이전에도 사이트나 앱에 접속하는 동기를 부여\n",
        "\n",
        "퍼스널라이즈드 스토리텔링 및 미스터리 콘텐츠 시리즈\n",
        "개념:\n",
        "\n",
        "사용자의 관심사와 행동 패턴을 분석해 개인 맞춤형 ‘스토리’나 ‘미스터리 콘텐츠’를 제공\n",
        "\n",
        "실행 전략:\n",
        "\n",
        "스토리 시리즈 공개: 첫 방문 후 1일차부터 6일차까지 매일 차별화된 에피소드의 스토리를 공개\n",
        "\n",
        "각 에피소드는 이전 에피소드의 내용과 연결되어 사용자들이 자연스럽게 다음\n",
        "\n",
        "내용을 확인하기 위해 재방문하도록 한다.\n",
        "\n",
        "미스터리 박스/서프라이즈:\n",
        "\n",
        "특정 방문 횟수를 달성하면 ‘미스터리 박스’를 오픈할 수 있도록 하여\n",
        "\n",
        "보상 또는 특별 콘텐츠(예: 한정판 아이템, 할인 쿠폰 등)를 제공\n",
        "\n",
        "개인화 알림:\n",
        "\n",
        "사용자가 관심을 가질 만한 스토리나 콘텐츠 업데이트에 대한 알림을 푸시\n",
        "\n",
        "또는 이메일로 전송해 재방문을 유도\n",
        "\n",
        "장점:\n",
        "\n",
        "일련의 연속적인 스토리나 미스터리 콘텐츠는 사용자의 호기심을 자극해 매일 방문하도록 유도\n",
        "\n",
        "개별 사용자가 자신진의 흥미에 맞게 맞춤형 콘텐츠를 받으면, 플랫폼에 대한 충성도가 높아진다.\n",
        "\n",
        "인터랙티브 이벤트 및 커뮤니티 기반 참여 프로그램\n",
        "개념:\n",
        "\n",
        "사용자가 단순히 콘텐츠 소비를 넘어, 직접 참여할 수 있는 인터랙티브 이벤트나 커뮤니티\n",
        "\n",
        "기반 프로그램을 통해 활발한 상호작용 환경을 만든다.\n",
        "\n",
        "실행 전략:\n",
        "\n",
        "실시간 Q&A 또는 라이브 스트림 이벤트:\n",
        "\n",
        "7일차 이전 특정 시점(예: 5일차)에 전문가나 인플루언서와의 라이브 스트리밍 이벤트를 개최\n",
        "\n",
        "이벤트 참여 시 추가 보상을 제공.\n",
        "\n",
        "사용자 생성 콘텐츠(UGC) 공모전:\n",
        "\n",
        "플랫폼 내에서 사용자가 직접 참여할 수 있는 공모전이나 챌린지를 진행하여,\n",
        "\n",
        "우수 참여자에게 보상을 제공하면 다른 사용자들도 자연스럽게 콘텐츠를 확인하러 방문할 수 있다.\n",
        "\n",
        "커뮤니티 포럼 및 소셜 피드 통합:\n",
        "\n",
        "커뮤니티 포럼을 활성화하여 사용자들 간의 소통을 장려하고, 일일 토론 주제를 통해 사용자들이 매일 돌아오도록 유도\n",
        "\n",
        "장점:\n",
        "\n",
        "사용자들이 단순 소비자가 아니라 직접 이벤트에 참여함으로써 정서적 유대감과 소속감을 형성할 수 있다.\n",
        "\n",
        "커뮤니티 내에서의 활발한 소통은 자연스러운 재방문을 유도할 뿐 아니라, 입소문 마케팅 효과도 기대할 수 있다.\n",
        "\n",
        "개인화된 리마인더 및 AI 기반 인터랙티브 챗봇 활용\n",
        "개념:\n",
        "\n",
        "사용자의 행동 데이터와 선호도를 분석하여 개인 맞춤형 메시지와 추천 콘텐츠를 제공하는 AI 챗봇을 도입\n",
        "\n",
        "실행 전략:\n",
        "\n",
        "개인화 알림:\n",
        "\n",
        "사용자가 방문하지 않았을 때, AI 챗봇이 개인 맞춤형 리마인더 메시지를 보내어\n",
        "\n",
        "“오늘의 핫이슈”나 “새로운 이벤트” 정보를 제공\n",
        "\n",
        "상호작용 챗봇:\n",
        "\n",
        "사용자가 궁금한 점을 실시간으로 응답하며, 챗봇을 통해 이벤트 정보,\n",
        "\n",
        "보상 혜택, 또는 새로운 콘텐츠 안내 등을 제공\n",
        "\n",
        "데이터 기반 추천:\n",
        "\n",
        "과거 방문 기록과 관심 콘텐츠를 기반으로, 다음에 확인할 만한 콘텐츠나\n",
        "\n",
        "이벤트를 추천하여 재방문을 유도\n",
        "\n",
        "장점:\n",
        "\n",
        "자동화된 알림 시스템은 사용자가 잊지 않고 사이트 또는 앱을 재방문하도록 한다.\n",
        "\n",
        "인터랙티브한 챗봇은 사용자가 직접 대화하면서 정보를 얻을 수 있어,\n",
        "\n",
        "사용자 경험(UX)을 크게 향상시킨다.\n",
        "\n",
        "결론\n",
        "\n",
        "7일차 이전에 재방문을 유도하기 위해서는 사용자의 참여와 흥미를\n",
        "\n",
        "지속적으로 자극하는 전략을 선택하는 것이 중요\n",
        "\n",
        "예를 들어, 게임화된 챌린지나 연속 스토리텔링은 사용자의 호기심과 경쟁심을 유발하여\n",
        "\n",
        "매일 방문하게 할 수 있으며, 커뮤니티 기반 이벤트와 개인화된 알림 시스템은\n",
        "\n",
        "사용자와의 상호작용 및 정서적 유대를 강화할 수 있다.\n",
        "\n",
        "이러한 방법들을 통합하여 실행한다면, 플랫폼 전반의 Retention을 효과적으로 높일 수 있을 것이다.\n",
        "\n",
        "아래는 가상의 Retention 데이터를 생성하여,\n",
        "\n",
        "기존 상태(Baseline)와 7일차 이전에 재방문 유도를 위한\n",
        "\n",
        "전략(Intervention: 게임화, 스토리텔링, 커뮤니티, AI 챗봇 등 통합 효과)\n",
        "\n",
        "를 비교하는 두 개의 시각화 입니다.\n",
        "\n",
        "첫 번째 그래프는 첫 방문 후 0일부터 7일까지의 Retention 변화를 선 그래프\n",
        "\n",
        "두 번째 그래프는 7일차 Retention 값을 바 차트로 비교\n",
        "\n",
        "참고: 실제 데이터 대신, Retention 개선 효과를 가정한 가상의 시뮬레이션 입니다.\n",
        "\n",
        "실제 운영 데이터와 비교하여 효과를 판단하거나 전략을 도출할 수 있습니다.\n",
        "\n",
        "Retention전략이 반영되게 가상의 데이터 추가작업\n",
        "목표 : Retention전략 전/후 비교\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 1. CSV 파일에서 데이터 로드\n",
        "# -------------------------------------------------\n",
        "# CSV 파일 이름은 상황에 맞게 수정\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 2. baseline Retention 계산 (0일 ~ 7일)\n",
        "# -----------------------------------------------\n",
        "# 먼저 days_since_first_visit 값이 0~7인 데이터만 선택\n",
        "df_retention = df[df['days_since_first_visit'] <= 7]\n",
        "\n",
        "# 각 일자별로 고유 fullVisitorId의 수를 계산\n",
        "# (즉, 해당 일자에 방문한 유니크 사용자의 수)\n",
        "baseline_counts = df_retention.groupby('days_since_first_visit')['fullVisitorId'].nunique().sort_index()\n",
        "\n",
        "# 0일(첫 방문) 기준으로 비율(= retention rate)로 계산\n",
        "# 첫 방문일의 방문자 수를 기준으로 각 일자의 비율을 구하면 0일은 1 (100%)가 됨\n",
        "baseline_retention = baseline_counts / baseline_counts.iloc[0]\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 3. Intervention(가상 Retention 전략) 시나리오 적용\n",
        "# -------------------------------------------------\n",
        "# 기존 예시에서 사용된 가상의 multiplier를 이용해 intervention retention 값을 만든다.\n",
        "# (실제 데이터와 다를 수 있으므로, 원하는 전략 시나리오에 맞춰 multiplier 값을 조정.)\n",
        "sample_multipliers = {\n",
        "    0: 1.0,    # 첫 방문은 항상 100%\n",
        "    1: 1.5,    # day1: 예시 baseline 값에 1.5배 적용\n",
        "    2: 1.67,   # day2: 1.67배 적용\n",
        "    3: 2.25,   # day3: 2.25배 적용\n",
        "    4: 2.67,   # day4: 2.67배 적용\n",
        "    5: 3.8,    # day5: 3.8배 적용\n",
        "    6: 4.375,  # day6: 4.375배 적용\n",
        "    7: 6.0     # day7: 6.0배 적용\n",
        "}\n",
        "\n",
        "# baseline_retention 값에 multiplier를 적용하여 intervention retention을 계산\n",
        "# 단, 계산된 값이 1을 초과하면 1로 제한\n",
        "intervention_retention = baseline_retention.copy()\n",
        "for day in baseline_retention.index:\n",
        "    multiplier = sample_multipliers.get(day, 1.0)\n",
        "    intervention_retention.loc[day] = min(baseline_retention.loc[day] * multiplier, 1.0)\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 4. Retention 비교 DataFrame 생성 (일자별)\n",
        "# -------------------------------------------------\n",
        "df_plot = pd.DataFrame({\n",
        "    'Day': baseline_retention.index,\n",
        "    'Baseline': baseline_retention.values,\n",
        "    'Intervention': intervention_retention.values\n",
        "})\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 5. 라인 차트: 0일 ~ 7일차 Retention 비교\n",
        "# -------------------------------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(df_plot['Day'], df_plot['Baseline'], marker='o',\n",
        "         label='Baseline (No Intervention)\\n(기본, 재방문 유도 미적용)')\n",
        "plt.plot(df_plot['Day'], df_plot['Intervention'], marker='o',\n",
        "         label='Intervention (retention 전략반영)')\n",
        "plt.title('Retention Rate Comparison Over Time\\n(방문 후 재방문율 비교)')\n",
        "plt.xlabel('Days Since First Visit\\n(첫 방문 후 경과 일수)')\n",
        "plt.ylabel('Retention Rate\\n(재방문률)')\n",
        "plt.xticks(df_plot['Day'])\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------\n",
        "# 6. 바 차트: 7일차 Retention 비교\n",
        "# -------------------------------------------------\n",
        "# day 7의 Retention 값을 추출\n",
        "day7_baseline = df_plot[df_plot['Day'] == 7]['Baseline'].values[0]\n",
        "day7_intervention = df_plot[df_plot['Day'] == 7]['Intervention'].values[0]\n",
        "\n",
        "df_day7 = pd.DataFrame({\n",
        "    'Condition': ['Baseline (No Intervention)', 'Intervention (retention 전략반영)'],\n",
        "    'Day7_Retention': [day7_baseline, day7_intervention]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.bar(df_day7['Condition'], df_day7['Day7_Retention'], color=['lightgray', 'skyblue'])\n",
        "plt.title('Day 7 Retention Comparison\\n(7일차 재방문율 비교)')\n",
        "plt.xlabel('Condition\\n(조건)')\n",
        "plt.ylabel('Retention Rate\\n(재방문률)')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "<ipython-input-14-0e268c112ca3>:9: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "\n",
        "– “days_since_first_visit” (첫 방문 이후 경과 일수) 기준으로\n",
        "\n",
        "각 일자별(0일~7일)의 고유 방문자수를 집계하여 baseline(기본) retention 값을 계산\n",
        "\n",
        "– 기존 예시에서처럼 “retention 전략반영” 케이스를 가상으로 재현하기 위해,\n",
        "\n",
        "각 일자별 baseline retention에 (day별 가상의)\n",
        "\n",
        "multiplier를 적용하여 intervention retention 값을 산출\n",
        "\n",
        "– 최종적으로 두 retention curve(라인 차트)와 7일차 비교(바 차트)\n",
        "\n",
        "모든 검토기준 주별 → 월별로 수정\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# =================================================================\n",
        "# 1. 데이터 불러오기 및 기본 정보 확인\n",
        "# =================================================================\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv', low_memory=False)\n",
        "\n",
        "# =================================================================\n",
        "# 2. 날짜 및 시간 형 변환\n",
        "# - 'date': ISO 포맷 문자열 → datetime (UTC)\n",
        "# - 'visitStartTime': 이미 ISO 포맷 문자열이므로 unit 옵션 없이 datetime (UTC)으로 변환\n",
        "# =================================================================\n",
        "df['date'] = pd.to_datetime(df['date'], utc=True)\n",
        "df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], utc=True)\n",
        "\n",
        "# =================================================================\n",
        "# 3. 결측치 및 중복 데이터 확인 & 처리\n",
        "# =================================================================\n",
        "print(\"----- 결측치 확인 -----\")\n",
        "print(df.isnull().sum(), \"\\n\")\n",
        "\n",
        "print(\"----- 중복 데이터 수 -----\")\n",
        "print(df.duplicated().sum(), \"\\n\")\n",
        "\n",
        "# 중복 데이터 제거 (필요한 경우)\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"----- 수치형 데이터 기본 통계 -----\")\n",
        "print(df.describe(), \"\\n\")\n",
        "\n",
        "# =================================================================\n",
        "# 【Retention 분석 전용 EDA 시작】 (월 단위 코호트 기준)\n",
        "# =================================================================\n",
        "\n",
        "# 1) 유니크 방문자 (fullVisitorId) 수 확인\n",
        "unique_visitors = df['fullVisitorId'].nunique()\n",
        "print(\"유니크 방문자 수:\", unique_visitors, \"\\n\")\n",
        "\n",
        "# 2) 전체 방문횟수(totalVisits) 분포 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['totalVisits'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "plt.title(\"전체 방문횟수 분포 (totalVisits)\")\n",
        "plt.xlabel(\"방문횟수\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 3) 코호트 분석을 위한 전처리 (월 단위 기준)\n",
        "# ──────────────────────────────\n",
        "# - 각 방문자별 첫 방문일 계산 (first_visit_date)\n",
        "df['first_visit_date'] = df.groupby('fullVisitorId')['date'].transform('min')\n",
        "\n",
        "# - 첫 방문일 기준으로 **첫 방문월** 도출 (Period 단위, 월)\n",
        "df['first_visit_month'] = df['first_visit_date'].dt.to_period('M')\n",
        "\n",
        "# - 방문일의 월 (현재 방문월) 도출\n",
        "df['visit_month'] = df['date'].dt.to_period('M')\n",
        "\n",
        "# - 첫 방문월과 방문월 차이 계산 (월 단위 경과)\n",
        "df['months_since_first_visit'] = (df['visit_month'] - df['first_visit_month']).apply(lambda x: x.n)\n",
        "\n",
        "# 4) 월별 코호트 데이터 생성\n",
        "# ──────────────────────────────\n",
        "# 첫 방문월과 경과 월수별로 유니크 방문자 수 집계\n",
        "cohort_data = df.groupby(['first_visit_month', 'months_since_first_visit']).agg(\n",
        "    n_users=('fullVisitorId', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "print(\"----- 월별 코호트 데이터 예시 -----\")\n",
        "print(cohort_data.head(), \"\\n\")\n",
        "\n",
        "# 5) 특정 코호트의 재방문 패턴 시각화 (예: 가장 첫 코호트)\n",
        "first_cohort_month = cohort_data['first_visit_month'].min()\n",
        "first_cohort = cohort_data[cohort_data['first_visit_month'] == first_cohort_month]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(first_cohort['months_since_first_visit'], first_cohort['n_users'], marker='o')\n",
        "plt.title(\"코호트 (\" + str(first_cohort_month) + \") 재방문 패턴 (월별)\")\n",
        "plt.xlabel(\"첫 방문 이후 경과 월\")\n",
        "plt.ylabel(\"재방문 유저 수\")\n",
        "plt.show()\n",
        "\n",
        "# =================================================================\n",
        "# 6. 클라우드 슈퍼셋에서 시각화를 진행하기 위한 데이터 파일 저장 (Retention 전용)\n",
        "# =================================================================\n",
        "cohort_data.to_csv('retention_cohort_data.csv', index=False)\n",
        "print(\"Retention 코호트 데이터가 'retention_cohort_data.csv'로 저장되었습니다.\")\n",
        "\n",
        "# ──────────────────────────────\n",
        "# 추가 EDA: 디바이스 및 운영체제, 브라우저 정보 분석\n",
        "# ──────────────────────────────\n",
        "\n",
        "# 디바이스 카테고리(deviceCategory) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['deviceCategory'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black')\n",
        "plt.title(\"디바이스 카테고리 분포\")\n",
        "plt.xlabel(\"디바이스\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 상위 10개 운영체제(operatingSystem) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['operatingSystem'].value_counts().head(10).plot(kind='bar', color='lightcoral', edgecolor='black')\n",
        "plt.title(\"상위 10개 운영체제 분포\")\n",
        "plt.xlabel(\"운영체제\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "# 상위 10개 브라우저(browser) 분포\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['browser'].value_counts().head(10).plot(kind='bar', color='lightseagreen', edgecolor='black')\n",
        "plt.title(\"상위 10개 브라우저 분포\")\n",
        "plt.xlabel(\"브라우저\")\n",
        "plt.ylabel(\"빈도수\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "----- 결측치 확인 -----\n",
        "fullVisitorId             0\n",
        "visitStartTime            0\n",
        "date                      0\n",
        "deviceCategory            0\n",
        "isMobile                  0\n",
        "operatingSystem           0\n",
        "browser                   0\n",
        "country                   0\n",
        "city                      0\n",
        "trafficSource             0\n",
        "trafficMedium             0\n",
        "trafficCampaign           0\n",
        "isFirstVisit              0\n",
        "totalVisits               1\n",
        "totalHits                 1\n",
        "totalPageviews            1\n",
        "totalTimeOnSite           1\n",
        "productPagesViewed        1\n",
        "addedToCart               1\n",
        "first_visit_date          0\n",
        "days_since_first_visit    0\n",
        "dtype: int64\n",
        "\n",
        "----- 중복 데이터 수 -----\n",
        "0\n",
        "\n",
        "----- 수치형 데이터 기본 통계 -----\n",
        "        isFirstVisit  totalVisits      totalHits  totalPageviews  \\\n",
        "count  748134.000000     748133.0  748133.000000   748133.000000   \n",
        "mean        0.776159          1.0       4.648589        3.887324   \n",
        "std         0.416817          0.0       9.888969        7.205425   \n",
        "min         0.000000          1.0       1.000000        0.000000   \n",
        "25%         1.000000          1.0       1.000000        1.000000   \n",
        "50%         1.000000          1.0       2.000000        2.000000   \n",
        "75%         1.000000          1.0       4.000000        4.000000   \n",
        "max         1.000000          1.0     500.000000      469.000000   \n",
        "\n",
        "       totalTimeOnSite  productPagesViewed    addedToCart  \\\n",
        "count    748133.000000       748133.000000  748133.000000   \n",
        "mean        129.751052            0.409680       0.054742   \n",
        "std         365.579472            1.771054       0.227475   \n",
        "min           0.000000            0.000000       0.000000   \n",
        "25%           0.000000            0.000000       0.000000   \n",
        "50%           2.000000            0.000000       0.000000   \n",
        "75%          82.000000            0.000000       0.000000   \n",
        "max       19017.000000          168.000000       1.000000   \n",
        "\n",
        "       days_since_first_visit  \n",
        "count           748134.000000  \n",
        "mean                 4.695886  \n",
        "std                 20.742925  \n",
        "min                  0.000000  \n",
        "25%                  0.000000  \n",
        "50%                  0.000000  \n",
        "75%                  0.000000  \n",
        "max                303.000000   \n",
        "\n",
        "유니크 방문자 수: 593742\n",
        "\n",
        "\n",
        "<ipython-input-17-c35b487cd9db>:54: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
        "  df['first_visit_month'] = df['first_visit_date'].dt.to_period('M')\n",
        "<ipython-input-17-c35b487cd9db>:57: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
        "  df['visit_month'] = df['date'].dt.to_period('M')\n",
        "----- 월별 코호트 데이터 예시 -----\n",
        "  first_visit_month  months_since_first_visit  n_users\n",
        "0           2016-08                         0    60223\n",
        "1           2016-08                         1     2594\n",
        "2           2016-08                         2     1163\n",
        "3           2016-08                         3      628\n",
        "4           2016-08                         4      468\n",
        "\n",
        "\n",
        "Retention 코호트 데이터가 'retention_cohort_data.csv'로 저장되었습니다.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# =================================================================\n",
        "# 1. 데이터 불러오기\n",
        "# =================================================================\n",
        "# 이미 df가 로드되어 있다고 가정합니다.\n",
        "# 예) df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv', low_memory=False)\n",
        "\n",
        "# =================================================================\n",
        "# 2. 날짜 및 시간 형 변환\n",
        "# - 'date': ISO 포맷 문자열 → datetime (UTC)\n",
        "# - 'visitStartTime': 이미 ISO 포맷 문자열이므로 바로 datetime (UTC)으로 변환\n",
        "# =================================================================\n",
        "df['date'] = pd.to_datetime(df['date'], utc=True)\n",
        "df['visitStartTime'] = pd.to_datetime(df['visitStartTime'], utc=True)\n",
        "\n",
        "# =================================================================\n",
        "# 3. 코호트 분석을 위한 전처리 (주 단위 기준)\n",
        "# =================================================================\n",
        "# 각 방문자별 첫 방문일 계산\n",
        "df['first_visit_date'] = df.groupby('fullVisitorId')['date'].transform('min')\n",
        "\n",
        "# dt.to_period() 전 tz 정보를 제거하여 경고 메시지를 피합니다.\n",
        "df['first_visit_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "df['visit_week'] = df['date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# 첫 방문주와 방문주 차이 계산 (주 단위 경과, 정수값)\n",
        "df['weeks_since_first_visit'] = (df['visit_week'] - df['first_visit_week']).apply(lambda x: x.n)\n",
        "\n",
        "# =================================================================\n",
        "# 4. 주별 코호트 데이터 생성\n",
        "# 첫 방문주와 경과 주수별로 유니크 방문자 수를 집계\n",
        "# =================================================================\n",
        "cohort_data = df.groupby(['first_visit_week', 'weeks_since_first_visit']).agg(\n",
        "    n_users=('fullVisitorId', 'nunique')\n",
        ").reset_index()\n",
        "\n",
        "# =================================================================\n",
        "# 5. 피벗 테이블 생성 및 히트맵 작성\n",
        "# =================================================================\n",
        "# (1) 피벗 테이블 생성: 인덱스는 첫 방문주, 컬럼은 첫 방문 이후 경과 주수, 값은 해당 주의 유니크 방문자 수\n",
        "cohort_pivot = cohort_data.pivot(index='first_visit_week',\n",
        "                                 columns='weeks_since_first_visit',\n",
        "                                 values='n_users')\n",
        "\n",
        "# (2) 코호트의 첫 방문주(경과 주 0)의 유저 수를 기준으로 비율(%)로 변환\n",
        "baseline = cohort_pivot[0]      # 각 코호트의 첫 방문주 유저 수\n",
        "retention_rate = cohort_pivot.divide(baseline, axis=0) * 100\n",
        "\n",
        "# (3) 히트맵 그리기\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(retention_rate, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
        "plt.title('코호트별 Retention 히트맵 (주별)')\n",
        "plt.xlabel('첫 방문 후 경과 주')\n",
        "plt.ylabel('코호트 (최초 방문 주)')\n",
        "plt.show()\n",
        "     \n",
        "\n",
        "그래프 상에서 (주간 단위) 첫 주 이후 컬럼 대부분이 0%인 것은,\n",
        "\n",
        "“최초 방문 후 다음 주에 재방문한 유저가 극히 적거나 없는 상태”임을 의미합니다.\n",
        "\n",
        "전자상거래나 특정 웹사이트에 서 첫 방문자를 반복 방문자로 전환시키는 데 실패했을 가능성이큼.\n",
        "\n",
        "실제로 1% 미만의 아주 낮은 비율이지만, 차트에 표시될 때 0으로 반올림된 것일 수도 있으므로\n",
        "\n",
        "데이터 수집 정확성을 점검\n",
        "\n",
        "마케팅/유입 전략이 재방문을 유도하는 데 충분하지 않았는지 확인\n",
        "\n",
        "더 나은 코호트 유지 전략\n",
        "\n",
        "(예: 푸시알림, 메일링, 리마케팅 등)을 기획해볼 필요가 있음.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 2. 특정 코호트의 N-week Retention 선 그래프 (주별 기준)\n",
        "# ------------------------------------------------------------------\n",
        "\n",
        "# 특정 코호트(예: 가장 첫 방문 주에 해당하는 코호트)를 선택합니다.\n",
        "# 기존 코드에서는 'first_visit_date'와 'days_since_first_visit'를 사용하였으나,\n",
        "# 주별 기준에서는 각각 'first_visit_week'와 'weeks_since_first_visit'를 사용합니다.\n",
        "specific_cohort_week = cohort_data['first_visit_week'].min()\n",
        "specific_cohort = cohort_data[cohort_data['first_visit_week'] == specific_cohort_week].copy()\n",
        "\n",
        "# 해당 코호트의 기준값: week 0 (첫 방문 주)의 사용자 수\n",
        "baseline_value = specific_cohort[specific_cohort['weeks_since_first_visit'] == 0]['n_users'].iloc[0]\n",
        "\n",
        "# Retention Rate (%) 계산\n",
        "specific_cohort['retention_rate'] = specific_cohort['n_users'] / baseline_value * 100\n",
        "\n",
        "# 선 그래프로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(specific_cohort['weeks_since_first_visit'], specific_cohort['retention_rate'], marker='o')\n",
        "plt.title(f\"N-week Retention for Cohort ({specific_cohort_week})\")\n",
        "plt.xlabel(\"첫 방문 후 경과 주\")\n",
        "plt.ylabel(\"남아있는 활성 사용자의 비율(%)\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 3. 다수 코호트의 Retention 변화(코호트 차트, 주별 기준)\n",
        "# ------------------------------------------------------------------\n",
        "# 처음 5개의 코호트를 선택합니다.\n",
        "selected_cohorts = sorted(cohort_data['first_visit_week'].unique())[:5]\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for cohort in selected_cohorts:\n",
        "    cohort_subset = cohort_data[cohort_data['first_visit_week'] == cohort].copy()\n",
        "    # 각 코호트의 기준: week 0의 사용자 수 (첫 방문 주)\n",
        "    baseline_value = cohort_subset[cohort_subset['weeks_since_first_visit'] == 0]['n_users'].iloc[0]\n",
        "    # Retention Rate (%) 계산\n",
        "    cohort_subset['retention_rate'] = cohort_subset['n_users'] / baseline_value * 100\n",
        "    plt.plot(cohort_subset['weeks_since_first_visit'],\n",
        "             cohort_subset['retention_rate'],\n",
        "             marker='o', label=str(cohort))\n",
        "\n",
        "plt.title(\"선택된 코호트의 N-week Retention 비교\")\n",
        "plt.xlabel(\"첫 방문 후 경과 주\")\n",
        "plt.ylabel(\"Retention Rate (%)\")\n",
        "plt.legend(title=\"코호트 (최초 방문 주)\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "그래프는 각 코호트의 사용자가 시간이 지남에 따라 얼마나 잘 재방문하는지를 보여줌.\n",
        "\n",
        "빠른 감소는 초기 이탈율이 높음,\n",
        "\n",
        "완만한 감소는 사용자의 지속적인 관심과 참여를 의미할 수 있다.\n",
        "\n",
        "5개의 코호트 모두, 0주차(첫 방문 주)에는 100%, 다음 주(1주차)로 넘어가면서\n",
        "\n",
        "Retention Rate가 급격히 0% 근처로 하락하고, 이후(2주차~40주차)는 거의\n",
        "\n",
        "낮은 수준(사실상 1% 미만 혹은 0%에 가까운)으로 유지되는 패턴을 보임. 굵은 텍스트\n",
        "\n",
        "\n",
        "# 결과 출력: 두번째 데이터셋과 동일한 형태의 DataFrame\n",
        "display(df.head())\n",
        "     \n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\tfirst_visit_month\tvisit_month\tmonths_since_first_visit\tfirst_visit_week\tvisit_week\tweeks_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\t2016-10\t2016-10\t0\t2016-10-03/2016-10-09\t2016-10-10/2016-10-16\t1\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\t2017-04\t2017-04\t0\t2017-04-24/2017-04-30\t2017-04-24/2017-04-30\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\t2017-03\t2017-03\t0\t2017-03-20/2017-03-26\t2017-03-20/2017-03-26\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\t2017-03\t2017-04\t1\t2017-03-27/2017-04-02\t2017-03-27/2017-04-02\t0\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\t2017-04\t2017-05\t1\t2017-04-17/2017-04-23\t2017-05-15/2017-05-21\t4\n",
        "5 rows × 27 columns\n",
        "\n",
        "CSV 파일을 읽은 후 first_visit_date를 datetime(UTC)로 변환\n",
        "\n",
        "기존의 days_since_first_visit를 7로 나눈 몫으로 주 단위(weeks_since_first_visit)를 새롭게 추가\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# CSV 파일 로드 (파일 이름: cohort_data_for_mixpanel_amplitude.csv)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "\n",
        "# 데이터 미리보기 및 정보 확인\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "# first_visit_date가 문자열인 경우 datetime 형으로 변환 (UTC 기준)\n",
        "df['first_visit_date'] = pd.to_datetime(df['first_visit_date'], utc=True)\n",
        "\n",
        "# ----------------------------------------------------------------\n",
        "# **추가**: days_since_first_visit를 주(week) 단위로 변환\n",
        "# ----------------------------------------------------------------\n",
        "# days_since_first_visit 값을 7로 나눈 몫을 계산하여 주 단위 값으로 사용\n",
        "df['weeks_since_first_visit'] = df['days_since_first_visit'] // 7\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 1. 코호트별 재방문 유저 수 계산 (주별 기준)\n",
        "# ---------------------------------------------------\n",
        "# fullVisitorId 컬럼을 기준으로, 각 코호트(최초 방문일)별,\n",
        "# 첫 방문 후 경과 주(weeks_since_first_visit)마다 고유 방문자 수(n_users)를 계산\n",
        "cohort_data = df.groupby(['first_visit_date', 'weeks_since_first_visit'])['fullVisitorId'] \\\n",
        "                .nunique().reset_index(name='n_users')\n",
        "\n",
        "print(\"코호트 데이터 예시:\")\n",
        "display(cohort_data.head())\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 2. 단일 코호트의 N-week Retention 선 그래프\n",
        "# ---------------------------------------------------\n",
        "# 예시로, 가장 오래된(최초) 코호트를 선택하여 주별 재방문 유저 수 추이를 시각화\n",
        "first_cohort_date = cohort_data['first_visit_date'].min()\n",
        "first_cohort = cohort_data[cohort_data['first_visit_date'] == first_cohort_date]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(first_cohort['weeks_since_first_visit'], first_cohort['n_users'], marker='o')\n",
        "plt.title(\"코호트 (\" + str(first_cohort_date.date()) + \") 재방문 유저 추이\")\n",
        "plt.xlabel(\"첫 방문 후 경과 주\")\n",
        "plt.ylabel(\"재방문 유저 수\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# 3. 코호트별 Retention Heatmap 만들기 (주별 기준)\n",
        "# ---------------------------------------------------\n",
        "# 피벗 테이블 형태로 전환:\n",
        "# - 인덱스: first_visit_date (코호트)\n",
        "# - 컬럼: weeks_since_first_visit (경과 주)\n",
        "# - 값: n_users (고유 재방문 유저 수)\n",
        "cohort_pivot = cohort_data.pivot(index='first_visit_date',\n",
        "                                 columns='weeks_since_first_visit',\n",
        "                                 values='n_users')\n",
        "\n",
        "# 각 코호트의 주 0(첫 방문 주)의 사용자 수로 나누어 Retention Rate(%) 계산\n",
        "baseline = cohort_pivot[0]  # 모든 코호트에서 주 0 값\n",
        "retention_rate = cohort_pivot.divide(baseline, axis=0) * 100\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(retention_rate, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
        "plt.title(\"코호트별 Retention Heatmap (Retention Rate %)\")\n",
        "plt.xlabel(\"첫 방문 후 경과 주\")\n",
        "plt.ylabel(\"코호트 (최초 방문일)\")\n",
        "plt.show()\n",
        "     \n",
        "<ipython-input-24-6ada73f49f34>:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv')\n",
        "데이터 미리보기:\n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttrafficCampaign\tisFirstVisit\ttotalVisits\ttotalHits\ttotalPageviews\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t(not set)\t0\t1.0\t2.0\t2.0\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t(not set)\t0\t1.0\t1.0\t1.0\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t(not set)\t0\t1.0\t15.0\t12.0\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\n",
        "5 rows × 21 columns\n",
        "\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 21 columns):\n",
        " #   Column                  Non-Null Count   Dtype  \n",
        "---  ------                  --------------   -----  \n",
        " 0   fullVisitorId           748134 non-null  object\n",
        " 1   visitStartTime          748134 non-null  object\n",
        " 2   date                    748134 non-null  object\n",
        " 3   deviceCategory          748134 non-null  object\n",
        " 4   isMobile                748134 non-null  bool   \n",
        " 5   operatingSystem         748134 non-null  object\n",
        " 6   browser                 748134 non-null  object\n",
        " 7   country                 748134 non-null  object\n",
        " 8   city                    748134 non-null  object\n",
        " 9   trafficSource           748134 non-null  object\n",
        " 10  trafficMedium           748134 non-null  object\n",
        " 11  trafficCampaign         748134 non-null  object\n",
        " 12  isFirstVisit            748134 non-null  int64  \n",
        " 13  totalVisits             748133 non-null  float64\n",
        " 14  totalHits               748133 non-null  float64\n",
        " 15  totalPageviews          748133 non-null  float64\n",
        " 16  totalTimeOnSite         748133 non-null  float64\n",
        " 17  productPagesViewed      748133 non-null  float64\n",
        " 18  addedToCart             748133 non-null  float64\n",
        " 19  first_visit_date        748134 non-null  object\n",
        " 20  days_since_first_visit  748134 non-null  int64  \n",
        "dtypes: bool(1), float64(6), int64(2), object(12)\n",
        "memory usage: 114.9+ MB\n",
        "None\n",
        "코호트 데이터 예시:\n",
        "first_visit_date\tweeks_since_first_visit\tn_users\n",
        "0\t2016-08-01 00:00:00+00:00\t0\t1551\n",
        "1\t2016-08-01 00:00:00+00:00\t1\t114\n",
        "2\t2016-08-01 00:00:00+00:00\t2\t76\n",
        "3\t2016-08-01 00:00:00+00:00\t3\t54\n",
        "4\t2016-08-01 00:00:00+00:00\t4\t48\n",
        "\n",
        "\n",
        "전반적 Retention이 매우 낮음:\n",
        "\n",
        "첫 방문(week 0) 이후 1주차부터 재방문자가 거의 사라지는 구조가 반복적으로 나타남.\n",
        "\n",
        "사용자 초기 이탈률이 높음:\n",
        "\n",
        "온보딩 개선, 재방문 혜택 및 프로모션, 마케팅 채널 최적화 등의 전략이 요구됨.\n",
        "\n",
        "코호트 간 차이 미미:\n",
        "\n",
        "특정 코호트에만 예외적으로 높은 Retention이 관찰되지 않는 한,\n",
        "\n",
        "전반적으로 일관된 문제(혹은 서비스 특성)로 해석됨.\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기 (low_memory 옵션과 parse_dates를 사용)\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv',\n",
        "                 parse_dates=['first_visit_date', 'date'],\n",
        "                 low_memory=False)\n",
        "\n",
        "# fullVisitorId 컬럼을 문자열로 변환하여 데이터 타입 혼합 문제 해결\n",
        "df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
        "\n",
        "# first_visit_date에서 timezone 정보를 제거한 후 주별(cohort_week)로 변환\n",
        "df['cohort_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# ※ 추가: days_since_first_visit을 주 단위(weeks_since_first_visit)로 변환\n",
        "#     (정수 나눗셈 // 7로 계산: 예를 들어, 0~6일은 week 0, 7~13일은 week 1로 처리)\n",
        "df['weeks_since_first_visit'] = df['days_since_first_visit'] // 7\n",
        "\n",
        "# 각 코호트(주별)와 weeks_since_first_visit별로 고유 사용자(fullVisitorId) 수를 계산합니다.\n",
        "cohort_data = df.groupby(['cohort_week', 'weeks_since_first_visit'])['fullVisitorId'] \\\n",
        "                .nunique().reset_index()\n",
        "\n",
        "# 피벗테이블 생성: 각 행은 코호트(주), 각 열은 첫 방문 후 경과 주(weeks_since_first_visit), 값은 고유 사용자 수\n",
        "cohort_pivot = cohort_data.pivot(index='cohort_week',\n",
        "                                 columns='weeks_since_first_visit',\n",
        "                                 values='fullVisitorId')\n",
        "\n",
        "# 각 코호트의 첫 방문일(첫 주, weeks_since_first_visit == 0) 기준 사용자 수를 구합니다.\n",
        "cohort_size = cohort_pivot[0]\n",
        "\n",
        "# Retention Rate 계산: 각 코호트의 해당 주의 사용자 수를 첫 방문 주의 사용자 수로 나눕니다.\n",
        "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
        "\n",
        "# Retention Heatmap 시각화: x축은 첫 방문 후 경과 주, y축은 코호트(주별)\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(retention_matrix, aspect='auto', cmap='Blues', vmin=0, vmax=1)\n",
        "plt.colorbar(label='Retention Rate')\n",
        "plt.title('코호트 Retention 분석 (주별 코호트)')\n",
        "plt.xlabel('Weeks Since First Visit')\n",
        "plt.ylabel('Cohort Week')\n",
        "\n",
        "# x축, y축 tick 지정\n",
        "plt.xticks(ticks=np.arange(len(retention_matrix.columns)), labels=retention_matrix.columns)\n",
        "plt.yticks(ticks=np.arange(len(retention_matrix.index)), labels=retention_matrix.index.astype(str))\n",
        "\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "\n",
        "그래프 전체가 Week 0에서 진한 파랑(= 100%) → 이후 주(Week 1, 2, 3...)가 모두 흰색에 가까움:\n",
        "\n",
        "“대다수 사용자가 첫 방문 주 이후 재방문하지 않는 심각한 초기 이탈” 패턴\n",
        "\n",
        "코호트 간 유의미한 차이가 없을 정도로 낮은 Retention:\n",
        "\n",
        "전 시기에 걸쳐 공통된 과제가 존재하며, 온보딩 개선 및 재방문 유인책이 시급하다고 해석할수있다.\n",
        "\n",
        "추가 세그먼테이션 분석(트래픽 소스, 디바이스, 캠페인별 등)을 통해\n",
        "\n",
        "어느 구간에서라도 Retention이 개선될 여지가 있는지 확인하고, 이를 기반으로\n",
        "\n",
        "초기 유지 전략을 강화할 필요가 있다.\n",
        "\n",
        "\n",
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "     \n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving cohort_data_for_mixpanel_amplitude.csv to cohort_data_for_mixpanel_amplitude.csv\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기\n",
        "df = pd.read_csv('cohort_data_for_mixpanel_amplitude.csv',\n",
        "                 parse_dates=['first_visit_date', 'date'],\n",
        "                 low_memory=False)\n",
        "\n",
        "# fullVisitorId를 문자열로 변환\n",
        "df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
        "\n",
        "# timezone 제거 후, 코호트(주 단위) 생성\n",
        "df['cohort_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# days_since_first_visit -> 주 단위로 변환 (예: 정수 나눗셈 // 7)\n",
        "df['weeks_since_first_visit'] = df['days_since_first_visit'] // 7\n",
        "\n",
        "# 트래픽 소스별 Retention 계산:\n",
        "segment = 'trafficSource'  # 예시로 트래픽 소스 기준\n",
        "\n",
        "seg_cohort = df.groupby([segment, 'cohort_week', 'weeks_since_first_visit'])['fullVisitorId'] \\\n",
        "                .nunique().reset_index(name='n_users')\n",
        "\n",
        "def compute_retention_rate(seg_name):\n",
        "    \"\"\"\n",
        "    특정 세그먼트(seg_name)에 대한\n",
        "    (1) 주(week) 단위 피벗 테이블 생성\n",
        "    (2) baseline(week 0) 대비 Retention(%) 계산\n",
        "    (3) 모든 코호트의 평균 곡선을 반환\n",
        "    \"\"\"\n",
        "    subset = seg_cohort[seg_cohort[segment] == seg_name].copy()\n",
        "    pivot = subset.pivot(index='cohort_week',\n",
        "                         columns='weeks_since_first_visit',\n",
        "                         values='n_users')\n",
        "\n",
        "    # 만약 week 0 컬럼이 없으면(즉, 해당 세그먼트가 0주차 데이터가 없는 경우) 빈 시리즈 반환\n",
        "    if 0 not in pivot.columns:\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    # baseline(week 0) 대비 Retention 계산\n",
        "    baseline = pivot[0]\n",
        "    retention = pivot.divide(baseline, axis=0) * 100  # 백분율(%)\n",
        "\n",
        "    # 세그먼트 내 모든 코호트의 평균 Retention 곡선을 계산\n",
        "    avg_retention = retention.mean(axis=0)\n",
        "    return avg_retention\n",
        "\n",
        "# 각 트래픽 소스별로 Retention Curve를 그리기\n",
        "traffic_sources = seg_cohort[segment].unique()\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for src in traffic_sources:\n",
        "    ret_rate = compute_retention_rate(src)\n",
        "\n",
        "    # 만약 주(week) 0 데이터가 없어 빈 시리즈가 반환됐다면, 스킵\n",
        "    if ret_rate.empty:\n",
        "        print(f\"[WARN] {src} 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\")\n",
        "        continue\n",
        "\n",
        "    plt.plot(ret_rate.index, ret_rate.values, marker='o', label=src)\n",
        "\n",
        "plt.title(\"Traffic Source별 Retention Curve (주 단위)\")\n",
        "plt.xlabel(\"첫 방문 후 경과 주 (Weeks)\")\n",
        "plt.ylabel(\"Retention Rate (%)\")\n",
        "plt.legend(title=segment)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "[WARN] 9to5google.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] br.pinterest.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] businessinsider.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] datastudio.google.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] es.search.yahoo.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] fr.yhs4.search.yahoo.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] google.com.tw 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] in.search.yahoo.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "[WARN] mail.verizon.com 세그먼트에는 week 0 데이터가 없어 스킵됩니다.\n",
        "\n",
        "Traffic Source종류가 많아 구분이 안감 분류를 나눠서 분석필요\n",
        "\n",
        "트래픽 소스 문자열에서 국가(TLD)와 플랫폼(브랜드) 정보를 추출하여 분류 컬럼을 만든다.\n",
        "\n",
        "원본처럼 세그먼트 기준은 trafficSource로 두고,\n",
        "\n",
        "리텐션 계산 함수(compute_retention_rate) 역시 그대로 유지한다.\n",
        "\n",
        "플로팅할 때, 국가 그룹 또는 플랫폼 그룹을 기준으로 서브셋을 묶어서\n",
        "\n",
        "(=공통 분류를 가진 여러 trafficSource) 동일 그래프에 표시한다.\n",
        "\n",
        "한꺼번에 50~100개가 섞인 복잡한 그래프 대신, 국가별·플랫폼별로 나뉜\n",
        "\n",
        "여러 개의 그래프를 얻을 수 있어 동일 분류 내 트래픽 소스들의 차이를 비교하기 훨씬 쉬워짐\n",
        "\n",
        "TLD 파싱/매핑, 플랫폼 매핑 로직은 예시일 뿐이므로,\n",
        "\n",
        "실제 환경에 맞게 세밀하게 구성해야 됨.\n",
        "\n",
        "week 0 데이터가 없는 트래픽 소스(코호트)들은 스킵되므로,\n",
        "\n",
        "수집 로깅이 정상적으로 되고 있는지 확인이 필요\n",
        "\n",
        "국가/플랫폼 이외에도, 디바이스 종류, 캠페인 ID, 광고 채널 등 다른 기준으로도\n",
        "\n",
        "동일 패턴으로 세분화 분석이 가능할듯.\n",
        "\n",
        "\n",
        "#1. 국가(TLD) 및 플랫폼 분류 컬럼 만들기\n",
        "# 1.1 TLD(도메인 뒷부분) 추출 & 국가 매핑\n",
        "def extract_tld(source):\n",
        "    \"\"\"예: 'google.ru' -> 'ru' \"\"\"\n",
        "    if '.' not in source:\n",
        "        return 'unknown'\n",
        "    return source.strip().split('.')[-1].lower()\n",
        "\n",
        "# TLD -> Country 매핑 테이블 (예시)\n",
        "tld_to_country = {\n",
        "    'ru': 'Russia',\n",
        "    'be': 'Belgium',\n",
        "    'kr': 'Korea',\n",
        "    'jp': 'Japan',\n",
        "    'com': 'Global/Unknown',\n",
        "    'co': 'Global/Unknown',\n",
        "    'de': 'Germany',\n",
        "    # 필요에 따라 추가...\n",
        "}\n",
        "\n",
        "def map_tld_to_country(tld):\n",
        "    return tld_to_country.get(tld, 'Other')\n",
        "     \n",
        "\n",
        "# 1.2 플랫폼(브랜드) 분류\n",
        "def map_source_to_platform(source):\n",
        "    \"\"\"플랫폼 분류: google, naver, bing, facebook 등\"\"\"\n",
        "    s = source.lower()\n",
        "    if 'google' in s:\n",
        "        return 'Google'\n",
        "    elif 'naver' in s:\n",
        "        return 'Naver'\n",
        "    elif 'bing' in s:\n",
        "        return 'Bing'\n",
        "    elif 'facebook' in s:\n",
        "        return 'Facebook'\n",
        "    # ... 필요 시 추가\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "     \n",
        "DataFrame에 새 컬럼 추가\n",
        "\n",
        "# DataFrame에 새 컬럼 추가\n",
        "df['tld'] = df['trafficSource'].apply(extract_tld)\n",
        "df['country_group'] = df['tld'].apply(map_tld_to_country)\n",
        "\n",
        "df['platform_group'] = df['trafficSource'].apply(map_source_to_platform)\n",
        "\n",
        "     \n",
        "\n",
        "# 2. 기존 코호트/리텐션 계산 로직(유지)\n",
        "# compute_retention_rate(seg_name) 함수를 그대로 사용하되, segment = 'trafficSource'로 유지합니다.\n",
        "# 즉, 리텐션 계산을 “트래픽 소스별”로 하되, 출력(플로팅) 시에 ‘같은 국가/같은 플랫폼’ 소스들끼리 묶어서 그린다\n",
        "segment = 'trafficSource'  # 세그먼트 기준은 그대로 'trafficSource'\n",
        "\n",
        "seg_cohort = df.groupby([segment, 'cohort_week', 'weeks_since_first_visit'])['fullVisitorId'] \\\n",
        "                .nunique().reset_index(name='n_users')\n",
        "\n",
        "def compute_retention_rate(seg_name):\n",
        "    \"\"\"\n",
        "    특정 트래픽 소스(seg_name)에 대한 주(week) 단위 피벗 및\n",
        "    baseline(week 0) 대비 백분율(%) 계산 → 전체 코호트 평균 리턴\n",
        "    \"\"\"\n",
        "    subset = seg_cohort[seg_cohort[segment] == seg_name].copy()\n",
        "    pivot = subset.pivot(index='cohort_week',\n",
        "                         columns='weeks_since_first_visit',\n",
        "                         values='n_users')\n",
        "\n",
        "    if 0 not in pivot.columns:\n",
        "        # week 0 데이터가 없으면 빈 시리즈 반환\n",
        "        return pd.Series(dtype=float)\n",
        "\n",
        "    baseline = pivot[0]\n",
        "    retention = pivot.divide(baseline, axis=0) * 100  # % 계산\n",
        "    avg_retention = retention.mean(axis=0)\n",
        "    return avg_retention\n",
        "\n",
        "     \n",
        "\n",
        "# 3. 국가별로 묶어서 그리기\n",
        "# ountry_group 기준으로 묶어서, 각 국가마다 새 그래프를 하나씩 그리고,\n",
        "# 그 국가에 속해 있는 여러 트래픽 소스(google.ru, google.be, ...)의 리텐션 곡선을 한 장에 그림\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "country_list = df['country_group'].unique()\n",
        "\n",
        "for country in country_list:\n",
        "    # 1) 해당 country_group에 속한 모든 trafficSource\n",
        "    traffic_sources_in_country = df.loc[df['country_group'] == country, 'trafficSource'].unique()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(f\"Traffic Source Retention Curve by Country = {country}\")\n",
        "    plt.xlabel(\"첫 방문 후 경과 주 (Weeks)\")\n",
        "    plt.ylabel(\"Retention Rate (%)\")\n",
        "\n",
        "    valid_plot = False  # 실제로 그려진 라인이 하나라도 있는지 확인\n",
        "\n",
        "    for src in traffic_sources_in_country:\n",
        "        ret_rate = compute_retention_rate(src)\n",
        "        if ret_rate.empty:\n",
        "            # week 0 데이터가 없으면 스킵\n",
        "            continue\n",
        "        plt.plot(ret_rate.index, ret_rate.values, marker='o', label=src)\n",
        "        valid_plot = True\n",
        "\n",
        "    if valid_plot:\n",
        "        plt.legend(title='Traffic Source', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()  # 각 국가별 그래프를 순차적으로 표시\n",
        "    else:\n",
        "        print(f\"[WARN] '{country}' 국가에 속한 트래픽 소스 중 week 0 데이터가 있는 세그먼트가 없습니다.\")\n",
        "\n",
        "     \n",
        "<ipython-input-21-c1417fcbc0e8>:30: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
        "  plt.tight_layout()\n",
        "\n",
        "<ipython-input-21-c1417fcbc0e8>:30: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Other 그래프\n",
        "일부 소스가 상대적으로 높거나 꾸준한 리텐션을 유지할 수 있으므로,\n",
        "\n",
        "해당 소스를 선별해 집중 분석/마케팅하는 전략이 필요, 추가로 세분화(검색, 광고, SNS 등)하거나,\n",
        "\n",
        "데이터 매핑 규칙을 정교화해 별도 그래프를 뽑는 방법이 필요함.\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Global/Unknown 그래프\n",
        "대체로 장기 유지율이 낮고 단발성 방문이 많다\n",
        "\n",
        "세부적인 브라우저별, 디바이스별, 플랫폼별 세부적으로 더 파고들어 정밀한 채널 분류 및 마케팅 최적화 전\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Germany 그래프\n",
        "독일 사용자에 대한 장기사용자 유지를 위한 대응 필요\n",
        "\n",
        "장기 사용자 유지를 위한 재참여 전략, UX 개선 및 마케팅 조정 등의 추가적인 대응이 필요\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Russia 그래프\n",
        "러시아 시장 확대 전략 고려\n",
        "\n",
        "google.ru, yandex-team.ru, go.mail.ru 등을 통한 러시아 지역 트래픽이 실제로 의미 있는 규모라면,\n",
        "\n",
        "러시아 사용자 대상 콘텐츠/서비스 현지화, 마케팅 최적화 등을 검토할 수 있다.\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Japan 그래프\n",
        "일본 코호트 전반에서 주차별 완전한 선형 그래프가 아닌, 제한된 주차/점만 보이는 이유는\n",
        "\n",
        "데이터 누락 또는 매우 적은 샘플 때문일 가능성이 높음.\n",
        "\n",
        "결론적으로, 이 그래프는 일본 도메인(트래픽 소스) 유입이 소규모이거나 특정 이벤트에 집중되어\n",
        "\n",
        "있음을 시사하며, 더 풍부한 샘플이 모이거나 별도의 캠페인/마케팅 로깅이 정교하게 이뤄져야\n",
        "\n",
        "안정적인 리텐션 패턴을 파악할 수 있을 것으로 보임.\n",
        "\n",
        "▣ Traffic Source Retention Curve by Country = Belgium\n",
        "google.be 트래픽 소스에서 주차별 유효 데이터가 거의 없거나,\n",
        "\n",
        "딱 한 주차만 측정되어 점만 하나 찍힌 상태\n",
        "\n",
        "따라서 벨기에(google.be)에서 유입된 사용자의 리텐션을 제대로 분석하려면,\n",
        "\n",
        "데이터가 충분히 확보될 때까지 기다리거나, 코호트 로깅/집계 로직을 재점검할 필요가 있다.\n",
        "\n",
        "결국 이 그래프는 “벨기에에서 오는 트래픽이 현재 매우 적고, Week 0 ~ 1 이상의 연속 데이터가 거의 없다” 정도로.\n",
        "\n",
        "\n",
        "# 4. 플랫폼별로 묶어서 그리기\n",
        "# platform_group 기준으로 반복\n",
        "# Google / Naver / Bing / Facebook / Other 등 플랫폼별로 묶어서 플롯:\n",
        "platform_list = df['platform_group'].unique()\n",
        "\n",
        "for platform in platform_list:\n",
        "    traffic_sources_in_platform = df.loc[df['platform_group'] == platform, 'trafficSource'].unique()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(f\"Traffic Source Retention Curve by Platform = {platform}\")\n",
        "    plt.xlabel(\"첫 방문 후 경과 주 (Weeks)\")\n",
        "    plt.ylabel(\"Retention Rate (%)\")\n",
        "\n",
        "    valid_plot = False\n",
        "\n",
        "    for src in traffic_sources_in_platform:\n",
        "        ret_rate = compute_retention_rate(src)\n",
        "        if ret_rate.empty:\n",
        "            continue\n",
        "        plt.plot(ret_rate.index, ret_rate.values, marker='o', label=src)\n",
        "        valid_plot = True\n",
        "\n",
        "    if valid_plot:\n",
        "        plt.legend(title='Traffic Source', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"[WARN] '{platform}' 플랫폼에 속한 트래픽 소스 중 week 0 데이터가 있는 세그먼트가 없습니다.\")\n",
        "\n",
        "     \n",
        "<ipython-input-18-445b8ee11213>:26: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "<ipython-input-18-445b8ee11213>:26: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
        "  plt.tight_layout()\n",
        "\n",
        "\n",
        "▣ Traffic Source Retention Curve by Platform = other 그래프\n",
        "“Other” 플랫폼에 포함된 다양한 소스들은 보통 소규모·일회성 트래픽이 많아,\n",
        "\n",
        "Week 1 이후 급격한 이탈과 낮은 장기 리텐션이 일반적\n",
        "\n",
        "그래프에서 보이는 극단적 스파이크(>100%) 는 적은 표본 수와 이벤트성 유입의 영향으로 해석\n",
        "\n",
        "라인이 많고 변동 폭이 큰 것은, 여러 도메인(검색, 소셜, 광고, 스팸/봇 등)이 뒤섞여 있기 때문.\n",
        "\n",
        "\"Other” 범주를 좀 더 세밀하게 분류(커뮤니티, 소셜, 광고, 언론, etc.)하거나,\n",
        "\n",
        "유입 규모가 큰 소스를 추려 집중 분석하는 방법이 권장됨\n",
        "\n",
        "▣ Traffic Source Retention Curve by Platform = Bing 그래프\n",
        "대부분의 Bing 관련 소스에서 Week 1에 급격한 이탈이 발생하고,\n",
        "\n",
        "이후 5~10% 내외로 유지되는 낮은 장기 리텐션 패턴을 확인\n",
        "\n",
        "이는 검색 엔진 기반 유입 특성상, 단발성 방문이 많고, 재방문 동기가 강하지 않음\n",
        "\n",
        "bing vs. bing.com vs. cn.bing.com 간에도 큰 차이는 없음.\n",
        "\n",
        "마케팅 관점에서는, Bing 채널로부터 유입된 사용자의 초기 이탈을 줄이는 전략\n",
        "\n",
        "및 장기 관여(engagement)를 높이는 장치가 필요할 수 있다.\n",
        "\n",
        "▣ Traffic Source Retention Curve by Platform = Google 그래프\n",
        "다양한 국가/서비스/광고 도메인이 한 그래프에 뒤섞여 복잡한 양상을 보이지만,\n",
        "\n",
        "큰 틀에서 보면 10주차 이후 대부분 0~30% 내외로 떨어지는 전형적인 리텐션 곡선 형태\n",
        "\n",
        "100%를 초과하거나, 출렁이는 곡선은 여러 코호트가 합산/평균되었거나,\n",
        "\n",
        "샘플 수가 작거나, 이벤트성 유입 영향으로 발생할 수 있다.\n",
        "\n",
        "주요 활용:\n",
        "\n",
        "어떤 구글 도메인이 더 효과적인 장기 유입 경로인지 비교·파악하고,\n",
        "\n",
        "광고/마케팅 전략 및 지역별 현지화 전략을 수립하는 근거로 삼을 수 있다.\n",
        "\n",
        "▣ Traffic Source Retention Curve by Platform = Facebook 그래프\n",
        "가장 눈에 띄는 점:\n",
        "\n",
        "facebook(메인 도메인)의 리텐션이 타 서브도메인 대비 매우 높거나 100%를 초과하는 구간이 존재.\n",
        "\n",
        "이는 데이터 집계 로직, 샘플 규모, 이벤트성 유입 등의 영향으로 해석할 수 있음.\n",
        "\n",
        "서브도메인들은 초기 리텐션이나 장기 리텐션이 낮고, 그래프 변동 폭이 큰 편.\n",
        "\n",
        "이는 상대적으로 적은 사용자 규모/특수 기능 이용/이벤트 등에 의한 간헐적 유입으로 인한 현상.\n",
        "\n",
        "분석 활용:\n",
        "\n",
        "어떤 도메인(트래픽 소스)이 우리에게 가장 충성도가 높은 사용자를 주는지, 반대로 이탈이 빠른지\n",
        "\n",
        "비교하여, 마케팅·서비스 개선 아이디어를 도출할 수 있음.\n",
        "\n",
        "전체적인 상위 코호트 그래프에 대한 해석\n",
        "국가 그룹별 그래프 해석 국가별 그룹으로 나눈 그래프\n",
        "초기 리텐션 (Week 0, 1):\n",
        "\n",
        "모든 트래픽 소스는 Week 0(코호트 생성 주)에서 100%가 기준\n",
        "\n",
        "첫 주(Week 1)에서 높은 유지율을 보이는 트래픽 소스는,\n",
        "\n",
        "첫 방문 후에도 사용자가 빠르게 재방문하는 경향이 있음을 의미한다.\n",
        "\n",
        "만약 어느 국가 그룹 내에서 특정 트래픽 소스가 다른 소스보다 Week 1 리텐션이 현저히 높다면,\n",
        "\n",
        "그 소스에서 유입된 사용자의 초기 관심도가 더 높다고 해석할 수 있다.\n",
        "\n",
        "리텐션 하락 패턴:\n",
        "\n",
        "시간이 지남에 따라 대부분의 커브는 점차 하락합니다.\n",
        "\n",
        "완만한 하락:\n",
        "\n",
        "상대적으로 완만한 기울기를 가진 소스는 장기적으로도 사용자가 꾸준히 돌아오는 경향을 보인다.\n",
        "\n",
        "급격한 하락:\n",
        "\n",
        "급격하게 내려가는 경우, 초기 관심은 있었지만 곧 관심이 식어\n",
        "\n",
        "재방문율이 낮은 상황으로 해석할 수 있다.\n",
        "\n",
        "곡선의 분산 및 교차:\n",
        "\n",
        "같은 국가 그룹 내 여러 트래픽 소스의 곡선을 비교하면, 일부 소스는 초반에는 낮은 리텐션을\n",
        "\n",
        "보이다가 중장기에는 다른 소스보다 안정적인 유지율을 보일 수도 있다.\n",
        "\n",
        "곡선들이 서로 교차하는 경우, 시간에 따른 리텐션 성향이 다르다는 점\n",
        "\n",
        "(예: 초기엔 A 소스가 좋지만, 이후 B 소스가 더 나은 유지율을 보임)을 시사\n",
        "\n",
        "플랫폼 그룹별 그래프 해석\n",
        "플랫폼별(예: Google, Naver, Bing, Facebook, 등)로 그룹화된 그래프에서는:\n",
        "\n",
        "플랫폼 간 비교:\n",
        "\n",
        "동일한 플랫폼 그룹 내의 여러 트래픽 소스(예: google.ru, google.com 등)가 함께 나타난다.\n",
        "\n",
        "Google 그룹:\n",
        "\n",
        "Google 관련 트래픽 소스의 경우, 전반적으로 높은 브랜드 인지도와 검색 엔진 특성으로 인해\n",
        "\n",
        "초기 리텐션은 강한 경우가 많다.\n",
        "\n",
        "그러나 국가별 차이가 존재할 수 있으므로, 특정 국가(예: google.ru)와 다른 국가(예: google.be)\n",
        "\n",
        "사이의 유지율 차이가 관찰된다면, 해당 국가의 사용자 행동 또는 서비스 제공 방식의 차이가\n",
        "\n",
        "원인일 수 있다.\n",
        "\n",
        "다른 플랫폼 그룹:\n",
        "\n",
        "Naver, Bing, Facebook 등은 각 플랫폼의 특성(예: 페이스북의 경우 소셜 미디어 환경에서의\n",
        "\n",
        "빠른 트렌드 변화)을 반영하여, 리텐션 커브의 기울기가 다르게 나타날 수 있다.\n",
        "\n",
        "예를 들어, 한 플랫폼 그룹 내에서 일부 트래픽 소스는 초기 리텐션은 낮으나,\n",
        "\n",
        "장기적으로도 사용자의 재방문율이 낮은 경우가 있을 수 있다.\n",
        "\n",
        "시간에 따른 유지력:\n",
        "\n",
        "각 플랫폼 그룹에서 시간이 지남에 따라 유지율이 어떻게 변화하는지 보면,\n",
        "\n",
        "사용자들이 플랫폼을 통한 유입 후 얼마만큼의 기간 동안 재방문하는지가 파악됨.\n",
        "\n",
        "장기적으로 완만하게 유지되는 커브는 해당 플랫폼을 통해 유입된 사용자가 보다\n",
        "\n",
        "충성도가 높다고 볼 수 있다.\n",
        "\n",
        "일반적 관찰 및 시사점\n",
        "데이터 수집 점검:\n",
        "\n",
        "만약 일부 트래픽 소스에서는 Week 0 데이터가 전혀 없거나, 초기 리텐션 데이터가 누락된 경우(그래프에 나타나지 않음),\n",
        "\n",
        "이는 데이터 로깅 문제 혹은 해당 유입 경로의 특징일 수 있으므로 추가 점검이 필요\n",
        "\n",
        "사용자 행동 차이:\n",
        "\n",
        "한 국가나 플랫폼 그룹 내에서 리텐션 곡선의 차이가 크다면, 그만큼 각 트래픽\n",
        "\n",
        "소스가 가져오는 사용자 특성이 다르다는 의미\n",
        "\n",
        "예) 한 트래픽 소스의 경우 초기에는 사용자 관심이 높지만 곧 빠르게 이탈하는 패턴이면,\n",
        "\n",
        "해당 채널의 콘텐츠나 사용자 경험 개선이 필요할 수 있다.\n",
        "\n",
        "비교 분석:\n",
        "\n",
        "같은 그룹 내 여러 소스의 커브를 비교하면, 마케팅 전략이나 채널별 최적화의\n",
        "\n",
        "우선순위를 결정하는 데 참고할 수 있다.\n",
        "\n",
        "초기 유지율과 장기 유지율 모두를 고려해, 특정 트래픽 소스가 단기적인 유입은\n",
        "\n",
        "강하지만, 장기적인 사용자 충성도는 낮다면 채널별 특성을 더 자세히 분석할 필요 있다.\n",
        "\n",
        "전략적 활용:\n",
        "\n",
        "국가별, 플랫폼별로 리텐션을 세분화하면, 각 그룹별로 타겟팅 및 캠페인 전략을 별도로 세울 수 있다.\n",
        "\n",
        "예) 초기 리텐션은 좋으나 장기적으로 유지율이 낮은 국가/플랫폼에 대해서는\n",
        "\n",
        "재방문을 유도하는 추가적인 이벤트나 프로모션 전략이 필요할 수 있다.\n",
        "\n",
        "결론\n",
        "분류별 유효 비교:\n",
        "\n",
        "그래프들을 국가나 플랫폼별로 나누어 표시함으로써, 한꺼번에 수십 개의 트래픽 소스가 뒤섞여\n",
        "\n",
        "나타날 때보다 보다 명확하게 어떤 그룹 내에서 어떤 소스가 상대적으로\n",
        "\n",
        "좋은 리텐션을 보이는지 파악할 수 있다.\n",
        "\n",
        "데이터 기반 의사결정:\n",
        "\n",
        "이러한 시각적 비교 결과는 각 트래픽 소스나 마케팅 채널의 효율성을 평가하고,\n",
        "\n",
        "필요 시 개선 및 최적화 전략 수립에 중요한 기초 자료로 사용될 수 있다.\n",
        "\n",
        "후속 분석 권고:\n",
        "\n",
        "각 그룹 내에서 리텐션 커브 차이에 영향을 줄 수 있는 추가 변수\n",
        "\n",
        "(예: 방문자 특성, 캠페인 내용 등)를 함께 고려하면 더 심층적인 인사이트를 도출할 수 있다.\n",
        "\n",
        "단순한 평균 리텐션 외에도 코호트별 구분, 사용자 세그먼트별 행동 차이 등을\n",
        "\n",
        "고려하는 다각도의 분석이 필요하다.\n",
        "\n",
        "최적의 Retention을 위한 전략\n",
        "7일 이내 유지율 증대 기여 가능성 데이터 기반 근거\n",
        "\n",
        "연속 보상 챌린지 첫 방문 이후 2~3일 이내 급격한 이탈 방지 가능\n",
        "\n",
        "시리즈형 콘텐츠 일부 코호트가 4~5일까지 유지되는 흐름 존재\n",
        "\n",
        "인터랙티브 이벤트 이벤트가 있는 날일수록 잔존율이 높아질 가능성\n",
        "\n",
        "AI 챗봇 & 알림 사용자 행동 기반 개입으로 반복 접속 유도 가능\n",
        "\n",
        "Day 1, Day 3, Day 5 타겟 리텐션 전략 실험군 구성\n",
        "\n",
        "A/B 테스트 형태로 전략별 성과 비교\n",
        "\n",
        "Retention 개선 KPI 설정\n",
        "\n",
        "Day 1 Retention +10%, Week 1 Retention +5% 등 목표 수립\n",
        "\n",
        "\n",
        "# 결과 출력: 두번째 데이터셋과 동일한 형태의 DataFrame\n",
        "display(df.head())\n",
        "     \n",
        "fullVisitorId\tvisitStartTime\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\t...\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-15 00:55:57+00:00\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\t...\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-05-01 04:00:05+00:00\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-21 04:39:07+00:00\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\t...\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 12:00:53+00:00\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\t...\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 14:59:36+00:00\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\t...\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "5 rows × 26 columns\n",
        "\n",
        "visitStartTime 컬럼과 trafficCampaign 컬럼은 삭제\n",
        "\n",
        "# 삭제할 컬럼 리스트 정의\n",
        "columns_to_drop = [\"visitStartTime\", \"trafficCampaign\"]\n",
        "\n",
        "# 컬럼이 실제 존재하는 경우에만 삭제\n",
        "df_cleaned = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
        "\n",
        "     \n",
        "\n",
        "# 결과 출력: 두번째 데이터셋과 동일한 형태의 DataFrame\n",
        "display(df_cleaned.head())\n",
        "     \n",
        "fullVisitorId\tdate\tdeviceCategory\tisMobile\toperatingSystem\tbrowser\tcountry\tcity\ttrafficSource\ttrafficMedium\t...\ttotalTimeOnSite\tproductPagesViewed\taddedToCart\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-14 00:00:00+00:00\tdesktop\tFalse\tWindows\tInternet Explorer\tUnited States\tnot available in demo dataset\task\torganic\t...\t16.0\t0.0\t0.0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-04-30 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\torganic\t...\t0.0\t0.0\t0.0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tBrisbane\task\torganic\t...\t16.0\t0.0\t0.0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tAustralia\tSydney\task\torganic\t...\t0.0\t0.0\t0.0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 00:00:00+00:00\tdesktop\tFalse\tWindows\tChrome\tUnited States\tnot available in demo dataset\task\torganic\t...\t326.0\t1.0\t1.0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "5 rows × 24 columns\n",
        "\n",
        "\n",
        "# 1. CSV 파일로 저장\n",
        "df_cleaned.to_csv('new_train.csv', index=False)\n",
        "\n",
        "# 2. Google Colab에서 사용자가 직접 파일 다운로드\n",
        "from google.colab import files\n",
        "files.download('new_train.csv')\n",
        "\n",
        "     \n",
        "컬럼삭제\n",
        "isMobile, city, trafficMedium, productPagesViewed, addedToCart, first_visit_month, visit_month, months_since_first_visit, first_visit_week, visit_week, totalVisits, totalHits, totalPageviews, totalTimeOnSite 의 컬럼 삭제\n",
        "\n",
        "\n",
        "# 삭제할 컬럼 리스트\n",
        "columns_to_drop = [\n",
        "    \"isMobile\", \"city\", \"trafficMedium\", \"productPagesViewed\", \"addedToCart\",\n",
        "    \"first_visit_month\", \"visit_month\", \"months_since_first_visit\",\n",
        "    \"first_visit_week\", \"visit_week\",\n",
        "    \"totalVisits\", \"totalHits\", \"totalPageviews\", \"totalTimeOnSite\"\n",
        "]\n",
        "\n",
        "# 컬럼 삭제\n",
        "df_cleaned = df_cleaned.drop(columns=[col for col in columns_to_drop if col in df_cleaned.columns])\n",
        "\n",
        "     \n",
        "\n",
        "# 1. CSV 파일로 저장\n",
        "df_cleaned.to_csv('new_train.csv', index=False)\n",
        "\n",
        "# 2. Google Colab에서 사용자가 직접 파일 다운로드\n",
        "from google.colab import files\n",
        "files.download('new_train.csv')\n",
        "     \n",
        "\n",
        "# 파일 직접 업로드해서 데이터 부르기\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "     \n",
        "Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.\n",
        "Saving new_train.csv to new_train.csv\n",
        "\n",
        "# 해당 new_train.csv파일이 처음 검증한 cohort_data_for_mixpanel_amplitude.csv 아래 코드 결과 값이 같은가 체크용 코드\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# CSV 파일 읽기 (low_memory 옵션과 parse_dates를 사용)\n",
        "df = pd.read_csv('new_train.csv',\n",
        "                 parse_dates=['first_visit_date', 'date'],\n",
        "                 low_memory=False)\n",
        "\n",
        "# fullVisitorId 컬럼을 문자열로 변환하여 데이터 타입 혼합 문제 해결\n",
        "df['fullVisitorId'] = df['fullVisitorId'].astype(str)\n",
        "\n",
        "# first_visit_date에서 timezone 정보를 제거한 후 주별(cohort_week)로 변환\n",
        "df['cohort_week'] = df['first_visit_date'].dt.tz_localize(None).dt.to_period('W')\n",
        "\n",
        "# 각 코호트(주별)와 days_since_first_visit별로 고유 사용자(fullVisitorId) 수를 계산합니다.\n",
        "cohort_data = df.groupby(['cohort_week', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗테이블 생성: 각 행은 코호트(주), 각 열은 첫 방문 후 경과 일수, 값은 고유 사용자 수\n",
        "cohort_pivot = cohort_data.pivot(index='cohort_week', columns='days_since_first_visit', values='fullVisitorId')\n",
        "\n",
        "# 각 코호트의 첫 방문일(첫 날, days_since_first_visit == 0) 기준 사용자 수를 구합니다.\n",
        "cohort_size = cohort_pivot[0]\n",
        "\n",
        "# Retention Rate 계산: 각 코호트의 해당 일수의 사용자 수를 첫 방문일의 사용자 수로 나눕니다.\n",
        "retention_matrix = cohort_pivot.divide(cohort_size, axis=0)\n",
        "\n",
        "# 특정 일수(예: 7일차)의 Retention을 비교하도록 설정\n",
        "desired_day = 7\n",
        "\n",
        "# 원하는 일수의 Retention 데이터가 존재하는지 확인\n",
        "if desired_day in retention_matrix.columns:\n",
        "    # 각 코호트별로 원하는 day의 Retention Rate를 추출합니다.\n",
        "    retention_day = retention_matrix[desired_day]\n",
        "\n",
        "    # 바 차트를 사용해 코호트별 Retention Rate를 시각화합니다.\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(retention_day.index.astype(str), retention_day.values, color='skyblue')\n",
        "    plt.xlabel('코호트 주 (Cohort Week)')\n",
        "    plt.ylabel(f'{desired_day}일차 Retention Rate')\n",
        "    plt.title(f'코호트별 {desired_day}일차 Retention 비교')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"데이터에 {desired_day}일차 Retention 정보가 존재하지 않습니다.\")\n",
        "     \n",
        "\n",
        "\n",
        "# 분석 환경 준비\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display  # Colab에서 display() 사용을 위해 필요\n",
        "\n",
        "# 4. CSV 파일 로드\n",
        "df = pd.read_csv('new_train.csv')\n",
        "\n",
        "# 5. 데이터 미리보기\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "\n",
        "# 6. 데이터 정보 확인\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "     \n",
        "<ipython-input-30-c99712d61d74>:8: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  df = pd.read_csv('new_train.csv')\n",
        "데이터 미리보기:\n",
        "fullVisitorId\tdate\tdeviceCategory\toperatingSystem\tbrowser\tcountry\ttrafficSource\tisFirstVisit\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-14 00:00:00+00:00\tdesktop\tWindows\tInternet Explorer\tUnited States\task\t0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-04-30 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 15 columns):\n",
        " #   Column                   Non-Null Count   Dtype\n",
        "---  ------                   --------------   -----\n",
        " 0   fullVisitorId            748134 non-null  object\n",
        " 1   date                     748134 non-null  object\n",
        " 2   deviceCategory           748134 non-null  object\n",
        " 3   operatingSystem          748134 non-null  object\n",
        " 4   browser                  748134 non-null  object\n",
        " 5   country                  748134 non-null  object\n",
        " 6   trafficSource            748134 non-null  object\n",
        " 7   isFirstVisit             748134 non-null  int64\n",
        " 8   first_visit_date         748134 non-null  object\n",
        " 9   days_since_first_visit   748134 non-null  int64\n",
        " 10  cohort_week              748134 non-null  object\n",
        " 11  weeks_since_first_visit  748134 non-null  int64\n",
        " 12  tld                      748134 non-null  object\n",
        " 13  country_group            748134 non-null  object\n",
        " 14  platform_group           748134 non-null  object\n",
        "dtypes: int64(3), object(12)\n",
        "memory usage: 85.6+ MB\n",
        "None\n",
        "fullVisitorId 컬럼에 숫자처럼 보이지만 문자열도 섞여있을 수 있어\n",
        "\n",
        "이 컬럼은 고유 ID이므로, 명시적으로 문자열(str) 타입으로 불러오는 게 안전\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# CSV 불러오기 (ID를 문자열로 처리)\n",
        "df = pd.read_csv('new_train.csv', dtype={'fullVisitorId': str})\n",
        "\n",
        "# 날짜 타입으로 변환\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['first_visit_date'] = pd.to_datetime(df['first_visit_date'])\n",
        "\n",
        "# 데이터 미리보기\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "\n",
        "# 데이터 정보 확인\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "     \n",
        "데이터 미리보기:\n",
        "fullVisitorId\tdate\tdeviceCategory\toperatingSystem\tbrowser\tcountry\ttrafficSource\tisFirstVisit\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-14 00:00:00+00:00\tdesktop\tWindows\tInternet Explorer\tUnited States\task\t0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-04-30 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 15 columns):\n",
        " #   Column                   Non-Null Count   Dtype              \n",
        "---  ------                   --------------   -----              \n",
        " 0   fullVisitorId            748134 non-null  object             \n",
        " 1   date                     748134 non-null  datetime64[ns, UTC]\n",
        " 2   deviceCategory           748134 non-null  object             \n",
        " 3   operatingSystem          748134 non-null  object             \n",
        " 4   browser                  748134 non-null  object             \n",
        " 5   country                  748134 non-null  object             \n",
        " 6   trafficSource            748134 non-null  object             \n",
        " 7   isFirstVisit             748134 non-null  int64              \n",
        " 8   first_visit_date         748134 non-null  datetime64[ns, UTC]\n",
        " 9   days_since_first_visit   748134 non-null  int64              \n",
        " 10  cohort_week              748134 non-null  object             \n",
        " 11  weeks_since_first_visit  748134 non-null  int64              \n",
        " 12  tld                      748134 non-null  object             \n",
        " 13  country_group            748134 non-null  object             \n",
        " 14  platform_group           748134 non-null  object             \n",
        "dtypes: datetime64[ns, UTC](2), int64(3), object(10)\n",
        "memory usage: 85.6+ MB\n",
        "None\n",
        "다음으로 할 분석 순서\n",
        "Day 1, 3, 5 리텐션 분석\n",
        "\n",
        "A/B 테스트 구성 및 리텐션 곡선 비교\n",
        "\n",
        "채널(trafficSource)별 리텐션 비교\n",
        "\n",
        "국가(country)별 재방문률 시각화\n",
        "\n",
        "피벗 테이블로 유입 트렌드 요약\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# =============================================================================\n",
        "# 0. CSV 파일 로드 및 전처리\n",
        "# =============================================================================\n",
        "\n",
        "# fullVisitorId를 문자열로 읽어 Dtype Warning 회피\n",
        "df = pd.read_csv('new_train.csv', dtype={'fullVisitorId': str})\n",
        "\n",
        "# 날짜 컬럼을 datetime 타입으로 변환 (분석 및 시각화 편의를 위해)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['first_visit_date'] = pd.to_datetime(df['first_visit_date'])\n",
        "\n",
        "# 데이터 미리보기 및 기본 정보 출력\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Day 1, 3, 5 리텐션 분석\n",
        "# =============================================================================\n",
        "print(\"\\n[1] Day 1, 3, 5 리텐션 분석\")\n",
        "\n",
        "# 코호트별(첫 방문일)로 days_since_first_visit에 따른 고유 사용자 수 계산\n",
        "cohort_data = df.groupby(['first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (행: first_visit_date, 열: days_since_first_visit)\n",
        "retention_table = cohort_data.pivot(index='first_visit_date', columns='days_since_first_visit', values='fullVisitorId').fillna(0)\n",
        "\n",
        "# Day 0 (첫 방문일 기준) 대비 리텐션 비율 계산 (만약 Day 0 데이터가 있을 경우)\n",
        "if 0 in retention_table.columns:\n",
        "    retention_rate = retention_table.divide(retention_table[0], axis=0)\n",
        "else:\n",
        "    retention_rate = retention_table.copy()\n",
        "\n",
        "# Day 1, 3, 5 데이터만 선택 (해당 컬럼이 존재할 경우)\n",
        "desired_days = [col for col in [1, 3, 5] if col in retention_rate.columns]\n",
        "retention_rate_filtered = retention_rate[desired_days]\n",
        "\n",
        "print(\"Day 1, 3, 5 리텐션 비율 (상위 5 코호트):\")\n",
        "display(retention_rate_filtered.head())\n",
        "\n",
        "# 리텐션 곡선 시각화 (첫 5개의 코호트)\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cohort in retention_rate_filtered.index[:5]:\n",
        "    days = retention_rate_filtered.columns.tolist()\n",
        "    values = retention_rate_filtered.loc[cohort].values\n",
        "    plt.plot(days, values, marker='o', label=str(cohort.date()))\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"Day 1, 3, 5 리텐션 곡선 (첫 5 코호트)\")\n",
        "plt.legend(title=\"첫 방문일\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 2. A/B 테스트 구성 및 리텐션 곡선 비교\n",
        "# =============================================================================\n",
        "print(\"\\n[2] A/B 테스트 구성 및 리텐션 곡선 비교\")\n",
        "\n",
        "# fullVisitorId의 마지막 숫자를 기준으로 그룹 분리 (짝수: A, 홀수: B)\n",
        "df['group'] = df['fullVisitorId'].str[-1].astype(int) % 2\n",
        "df['group'] = df['group'].map({0: \"A\", 1: \"B\"})\n",
        "\n",
        "# 그룹별, 코호트별, days_since_first_visit별 고유 사용자 수 계산\n",
        "ab_data = df.groupby(['group', 'first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (인덱스: group, first_visit_date / 열: days_since_first_visit)\n",
        "ab_pivot = ab_data.pivot_table(index=['group', 'first_visit_date'], columns='days_since_first_visit', values='fullVisitorId', fill_value=0)\n",
        "\n",
        "# Day 0 기준 리텐션 비율 계산 (존재하는 경우)\n",
        "if 0 in ab_pivot.columns:\n",
        "    ab_retention = ab_pivot.divide(ab_pivot[0], axis=0)\n",
        "else:\n",
        "    ab_retention = ab_pivot.copy()\n",
        "\n",
        "# Day 1, 3, 5 컬럼 선택\n",
        "cols_ab = [col for col in [1, 3, 5] if col in ab_retention.columns]\n",
        "print(\"A/B 그룹별 Day 1, 3, 5 리텐션 비율 (일부 예시):\")\n",
        "display(ab_retention[cols_ab].reset_index().head())\n",
        "\n",
        "# A/B 그룹별 리텐션 곡선 시각화 (각 그룹의 첫 3 코호트)\n",
        "plt.figure(figsize=(12, 6))\n",
        "for group in ['A', 'B']:\n",
        "    # group별 데이터 추출\n",
        "    if group in ab_retention.index.get_level_values(0):\n",
        "        group_data = ab_retention.loc[group]\n",
        "        for cohort in group_data.index[:3]:\n",
        "            days = group_data.columns.tolist()\n",
        "            values = group_data.loc[cohort].values\n",
        "            plt.plot(days, values, marker='o', label=f\"{group} - {pd.to_datetime(cohort).date()}\")\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"A/B 테스트: Day 1, 3, 5 리텐션 곡선\")\n",
        "plt.legend(title=\"그룹 및 코호트\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 3. 채널(trafficSource)별 리텐션 비교\n",
        "# =============================================================================\n",
        "print(\"\\n[3] 채널(trafficSource)별 리텐션 비교\")\n",
        "\n",
        "# 채널별, 코호트별, days_since_first_visit별 고유 사용자 수 계산\n",
        "channel_data = df.groupby(['trafficSource', 'first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (인덱스: trafficSource, first_visit_date / 열: days_since_first_visit)\n",
        "channel_pivot = channel_data.pivot_table(index=['trafficSource', 'first_visit_date'], columns='days_since_first_visit', values='fullVisitorId', fill_value=0)\n",
        "\n",
        "# Day 0 기준 리텐션 비율 계산 (존재하는 경우)\n",
        "if 0 in channel_pivot.columns:\n",
        "    channel_retention = channel_pivot.divide(channel_pivot[0], axis=0)\n",
        "else:\n",
        "    channel_retention = channel_pivot.copy()\n",
        "\n",
        "# 전체 데이터에서 트래픽 소스 개수가 많은 상위 3개 채널 선택\n",
        "top_channels = df['trafficSource'].value_counts().head(3).index.tolist()\n",
        "channel_retention_filtered = channel_retention.loc[top_channels]\n",
        "print(\"채널별(상위 3) Day 1, 3, 5 리텐션 비율:\")\n",
        "cols_channel = [col for col in [1, 3, 5] if col in channel_retention_filtered.columns]\n",
        "display(channel_retention_filtered[cols_channel].reset_index())\n",
        "\n",
        "# 상위 채널별 첫 코호트의 리텐션 곡선 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "for channel in top_channels:\n",
        "    channel_cohorts = channel_retention.loc[channel]\n",
        "    if not channel_cohorts.empty:\n",
        "        cohort = channel_cohorts.index[0]\n",
        "        days = [col for col in [1, 3, 5] if col in channel_retention.columns]\n",
        "        values = channel_retention.loc[(channel, cohort)][days].values\n",
        "        plt.plot(days, values, marker='o', label=f\"{channel} - {pd.to_datetime(cohort).date()}\")\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"상위 채널별 Day 1, 3, 5 리텐션 곡선\")\n",
        "plt.legend(title=\"TrafficSource & 코호트\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 4. 국가(country)별 재방문률(리텐션) 시각화\n",
        "# =============================================================================\n",
        "print(\"\\n[4] 국가(country)별 재방문률 시각화\")\n",
        "\n",
        "# Day 0 기준 (최초 방문자 수)\n",
        "base_country = df[df['days_since_first_visit'] == 0].groupby('country')['fullVisitorId'].nunique()\n",
        "\n",
        "# Day 0 이후 방문자 수 (재방문)\n",
        "return_country = df[df['days_since_first_visit'] > 0].groupby('country')['fullVisitorId'].nunique()\n",
        "\n",
        "# 국가별 재방문률 계산 (재방문자 수 / 최초 방문자 수)\n",
        "country_retention_rate = (return_country / base_country).fillna(0).sort_values(ascending=False)\n",
        "print(\"국가별 재방문 비율:\")\n",
        "ret_df = country_retention_rate.reset_index()\n",
        "ret_df.columns = [\"country\", \"revisit_ratio\"]\n",
        "display(ret_df)\n",
        "\n",
        "# 바 차트로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=ret_df, x=\"country\", y=\"revisit_ratio\")\n",
        "plt.xlabel(\"Country\")\n",
        "plt.ylabel(\"Revisit Ratio\")\n",
        "plt.title(\"국가별 재방문률\")\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 5. 피벗 테이블로 유입 트렌드 요약 (cohort_week vs trafficSource)\n",
        "# =============================================================================\n",
        "print(\"\\n[5] 피벗 테이블로 유입 트렌드 요약\")\n",
        "\n",
        "# 각 코호트 주별(예: cohort_week)로 트래픽 소스별 고유 사용자 수 집계\n",
        "pivot_trend = pd.pivot_table(df,\n",
        "                             index='cohort_week',\n",
        "                             columns='trafficSource',\n",
        "                             values='fullVisitorId',\n",
        "                             aggfunc=pd.Series.nunique,\n",
        "                             fill_value=0)\n",
        "print(\"피벗 테이블 (cohort_week vs trafficSource):\")\n",
        "display(pivot_trend)\n",
        "\n",
        "# Heatmap 시각화\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_trend, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"유입 트렌드 (코호트 주별 vs 트래픽 소스)\")\n",
        "plt.xlabel(\"TrafficSource\")\n",
        "plt.ylabel(\"Cohort Week\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "데이터 미리보기:\n",
        "fullVisitorId\tdate\tdeviceCategory\toperatingSystem\tbrowser\tcountry\ttrafficSource\tisFirstVisit\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-14 00:00:00+00:00\tdesktop\tWindows\tInternet Explorer\tUnited States\task\t0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-04-30 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 15 columns):\n",
        " #   Column                   Non-Null Count   Dtype              \n",
        "---  ------                   --------------   -----              \n",
        " 0   fullVisitorId            748134 non-null  object             \n",
        " 1   date                     748134 non-null  datetime64[ns, UTC]\n",
        " 2   deviceCategory           748134 non-null  object             \n",
        " 3   operatingSystem          748134 non-null  object             \n",
        " 4   browser                  748134 non-null  object             \n",
        " 5   country                  748134 non-null  object             \n",
        " 6   trafficSource            748134 non-null  object             \n",
        " 7   isFirstVisit             748134 non-null  int64              \n",
        " 8   first_visit_date         748134 non-null  datetime64[ns, UTC]\n",
        " 9   days_since_first_visit   748134 non-null  int64              \n",
        " 10  cohort_week              748134 non-null  object             \n",
        " 11  weeks_since_first_visit  748134 non-null  int64              \n",
        " 12  tld                      748134 non-null  object             \n",
        " 13  country_group            748134 non-null  object             \n",
        " 14  platform_group           748134 non-null  object             \n",
        "dtypes: datetime64[ns, UTC](2), int64(3), object(10)\n",
        "memory usage: 85.6+ MB\n",
        "None\n",
        "\n",
        "[1] Day 1, 3, 5 리텐션 분석\n",
        "Day 1, 3, 5 리텐션 비율 (상위 5 코호트):\n",
        "days_since_first_visit\t1\t3\t5\n",
        "first_visit_date\n",
        "2016-08-01 00:00:00+00:00\t0.049709\t0.026469\t0.009684\n",
        "2016-08-02 00:00:00+00:00\t0.047078\t0.021104\t0.004329\n",
        "2016-08-03 00:00:00+00:00\t0.036550\t0.004107\t0.017659\n",
        "2016-08-04 00:00:00+00:00\t0.029845\t0.005426\t0.011628\n",
        "2016-08-05 00:00:00+00:00\t0.011691\t0.016637\t0.010342\n",
        "\n",
        "[2] A/B 테스트 구성 및 리텐션 곡선 비교\n",
        "A/B 그룹별 Day 1, 3, 5 리텐션 비율 (일부 예시):\n",
        "days_since_first_visit\tgroup\tfirst_visit_date\t1\t3\t5\n",
        "0\tA\t2016-08-01 00:00:00+00:00\t0.056988\t0.025780\t0.012212\n",
        "1\tA\t2016-08-02 00:00:00+00:00\t0.050549\t0.017582\t0.004396\n",
        "2\tA\t2016-08-03 00:00:00+00:00\t0.038238\t0.003325\t0.019119\n",
        "3\tA\t2016-08-04 00:00:00+00:00\t0.025197\t0.003937\t0.009449\n",
        "4\tA\t2016-08-05 00:00:00+00:00\t0.009499\t0.015544\t0.013817\n",
        "\n",
        "[3] 채널(trafficSource)별 리텐션 비교\n",
        "채널별(상위 3) Day 1, 3, 5 리텐션 비율:\n",
        "days_since_first_visit\ttrafficSource\tfirst_visit_date\t1\t3\t5\n",
        "0\t(direct)\t2016-08-01 00:00:00+00:00\t0.056890\t0.031606\t0.011378\n",
        "1\t(direct)\t2016-08-02 00:00:00+00:00\t0.091075\t0.041894\t0.005464\n",
        "2\t(direct)\t2016-08-03 00:00:00+00:00\t0.077061\t0.003584\t0.035842\n",
        "3\t(direct)\t2016-08-04 00:00:00+00:00\t0.045872\t0.010703\t0.019878\n",
        "4\t(direct)\t2016-08-05 00:00:00+00:00\t0.014957\t0.034188\t0.014957\n",
        "...\t...\t...\t...\t...\t...\n",
        "907\tgoogle\t2017-05-27 00:00:00+00:00\t0.019340\t0.005688\t0.000000\n",
        "908\tgoogle\t2017-05-28 00:00:00+00:00\t0.027879\t0.007273\t0.000000\n",
        "909\tgoogle\t2017-05-29 00:00:00+00:00\t0.026624\t0.000000\t0.000000\n",
        "910\tgoogle\t2017-05-30 00:00:00+00:00\t0.028926\t0.000000\t0.000000\n",
        "911\tgoogle\t2017-05-31 00:00:00+00:00\t0.000000\t0.000000\t0.000000\n",
        "912 rows × 5 columns\n",
        "\n",
        "\n",
        "[4] 국가(country)별 재방문률 시각화\n",
        "국가별 재방문 비율:\n",
        "country\trevisit_ratio\n",
        "0\tGuernsey\t0.636364\n",
        "1\tMonaco\t0.230769\n",
        "2\tTogo\t0.190476\n",
        "3\tLiechtenstein\t0.166667\n",
        "4\tDjibouti\t0.166667\n",
        "...\t...\t...\n",
        "213\tU.S. Virgin Islands\t0.000000\n",
        "214\tTurks & Caicos Islands\t0.000000\n",
        "215\tTurkmenistan\t0.000000\n",
        "216\tVanuatu\t0.000000\n",
        "217\tYemen\t0.000000\n",
        "218 rows × 2 columns\n",
        "\n",
        "/usr/local/lib/python3.11/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 227 (\\N{LATIN SMALL LETTER A WITH TILDE}) missing from font(s) NanumGothic.\n",
        "  fig.canvas.print_figure(bytes_io, **kw)\n",
        "\n",
        "[5] 피벗 테이블로 유입 트렌드 요약\n",
        "피벗 테이블 (cohort_week vs trafficSource):\n",
        "trafficSource\t(direct)\t(not set)\t9to5google.com\tPartners\tad.doubleclick.net\tadwords.google.com\tamazon.com\tanalytics.google.com\taol\tarstechnica.com\t...\twanelo.com\twap.sogou.com\tweb.facebook.com\tweb.skype.com\tweb.telegram.org\twheretoget.it\tyahoo\tyahoo.com\tyandex\tyoutube.com\n",
        "cohort_week\n",
        "2016-08-01/2016-08-07\t3575\t0\t0\t566\t0\t1\t0\t55\t0\t0\t...\t0\t0\t0\t0\t0\t0\t15\t0\t0\t4885\n",
        "2016-08-08/2016-08-14\t3240\t1\t0\t304\t0\t0\t0\t57\t0\t0\t...\t0\t0\t0\t0\t0\t0\t4\t0\t0\t5514\n",
        "2016-08-15/2016-08-21\t3224\t0\t0\t221\t0\t0\t0\t46\t0\t0\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t5413\n",
        "2016-08-22/2016-08-28\t2670\t0\t0\t217\t0\t0\t0\t52\t1\t0\t...\t0\t0\t0\t0\t0\t0\t11\t0\t0\t5191\n",
        "2016-08-29/2016-09-04\t2628\t0\t0\t595\t0\t0\t2\t70\t0\t1\t...\t0\t0\t0\t0\t0\t0\t7\t0\t0\t5684\n",
        "2016-09-05/2016-09-11\t2272\t1\t0\t241\t0\t0\t0\t47\t0\t0\t...\t1\t0\t0\t0\t0\t1\t8\t0\t0\t5484\n",
        "2016-09-12/2016-09-18\t2704\t1\t0\t250\t0\t0\t0\t75\t0\t0\t...\t0\t0\t0\t0\t0\t0\t6\t0\t0\t5132\n",
        "2016-09-19/2016-09-25\t4333\t1\t0\t240\t1\t0\t1\t81\t0\t0\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t5291\n",
        "2016-09-26/2016-10-02\t5512\t1\t0\t190\t0\t1\t0\t81\t0\t0\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t4766\n",
        "2016-10-03/2016-10-09\t9411\t0\t0\t195\t0\t0\t0\t70\t0\t0\t...\t0\t0\t0\t0\t0\t0\t30\t0\t0\t5313\n",
        "2016-10-10/2016-10-16\t6022\t0\t0\t196\t0\t0\t0\t87\t0\t0\t...\t0\t0\t1\t0\t0\t0\t19\t0\t0\t6483\n",
        "2016-10-17/2016-10-23\t6719\t0\t0\t210\t0\t0\t0\t63\t0\t0\t...\t0\t0\t0\t0\t0\t0\t34\t0\t0\t10778\n",
        "2016-10-24/2016-10-30\t6713\t0\t0\t266\t0\t3\t0\t70\t0\t0\t...\t0\t0\t0\t0\t0\t0\t14\t0\t0\t13840\n",
        "2016-10-31/2016-11-06\t7033\t0\t0\t230\t0\t1\t1\t73\t0\t1\t...\t0\t0\t0\t0\t0\t0\t12\t0\t0\t13273\n",
        "2016-11-07/2016-11-13\t7900\t0\t0\t255\t0\t0\t0\t104\t1\t0\t...\t0\t0\t0\t0\t1\t0\t21\t0\t1\t12853\n",
        "2016-11-14/2016-11-20\t8290\t0\t0\t261\t0\t0\t0\t124\t0\t0\t...\t0\t0\t0\t0\t0\t0\t23\t0\t0\t13014\n",
        "2016-11-21/2016-11-27\t9404\t0\t0\t226\t0\t0\t2\t84\t3\t0\t...\t0\t0\t0\t0\t0\t0\t32\t0\t0\t11636\n",
        "2016-11-28/2016-12-04\t10254\t0\t0\t208\t0\t0\t0\t78\t0\t0\t...\t0\t0\t0\t0\t0\t0\t34\t0\t0\t11266\n",
        "2016-12-05/2016-12-11\t10690\t2\t0\t212\t0\t0\t0\t89\t0\t0\t...\t0\t1\t0\t0\t0\t0\t28\t0\t0\t3465\n",
        "2016-12-12/2016-12-18\t11860\t0\t0\t183\t1\t1\t2\t82\t0\t0\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t1992\n",
        "2016-12-19/2016-12-25\t6873\t0\t0\t144\t0\t0\t0\t27\t0\t0\t...\t0\t0\t0\t0\t0\t0\t12\t0\t0\t1813\n",
        "2016-12-26/2017-01-01\t4025\t0\t0\t114\t0\t0\t0\t20\t0\t0\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t1787\n",
        "2017-01-02/2017-01-08\t7225\t0\t0\t168\t0\t0\t0\t39\t0\t0\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t1998\n",
        "2017-01-09/2017-01-15\t7862\t0\t0\t263\t1\t0\t1\t73\t0\t0\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t2106\n",
        "2017-01-16/2017-01-22\t7135\t0\t0\t226\t0\t1\t0\t61\t0\t0\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t2089\n",
        "2017-01-23/2017-01-29\t10159\t2\t0\t253\t0\t0\t0\t88\t1\t0\t...\t0\t0\t0\t0\t0\t1\t18\t0\t1\t2008\n",
        "2017-01-30/2017-02-05\t8256\t0\t0\t238\t0\t0\t0\t90\t0\t0\t...\t0\t0\t0\t0\t0\t1\t15\t0\t0\t2161\n",
        "2017-02-06/2017-02-12\t6200\t0\t0\t256\t0\t0\t0\t78\t0\t0\t...\t0\t0\t0\t0\t0\t0\t21\t0\t0\t2299\n",
        "2017-02-13/2017-02-19\t3819\t0\t0\t239\t0\t0\t1\t87\t0\t0\t...\t0\t0\t0\t0\t0\t0\t20\t0\t0\t2155\n",
        "2017-02-20/2017-02-26\t3297\t1\t0\t234\t0\t0\t0\t88\t0\t0\t...\t0\t0\t0\t0\t0\t0\t27\t0\t1\t2215\n",
        "2017-02-27/2017-03-05\t2344\t0\t0\t269\t0\t0\t0\t89\t0\t0\t...\t0\t0\t0\t0\t0\t0\t13\t0\t0\t2417\n",
        "2017-03-06/2017-03-12\t2377\t2\t0\t203\t0\t0\t1\t78\t0\t0\t...\t0\t0\t0\t1\t0\t1\t28\t0\t0\t2478\n",
        "2017-03-13/2017-03-19\t2453\t2\t0\t288\t0\t0\t0\t89\t0\t0\t...\t0\t0\t0\t0\t0\t0\t18\t0\t0\t2644\n",
        "2017-03-20/2017-03-26\t2486\t8\t1\t308\t0\t0\t0\t138\t0\t0\t...\t0\t0\t1\t0\t0\t0\t22\t0\t0\t2471\n",
        "2017-03-27/2017-04-02\t3716\t9\t0\t251\t0\t2\t0\t90\t2\t0\t...\t0\t0\t0\t0\t0\t0\t247\t0\t0\t2651\n",
        "2017-04-03/2017-04-09\t3641\t8\t0\t270\t0\t0\t0\t97\t0\t0\t...\t0\t0\t0\t0\t0\t0\t77\t0\t0\t2609\n",
        "2017-04-10/2017-04-16\t2379\t14\t0\t298\t0\t0\t0\t83\t0\t0\t...\t0\t0\t0\t0\t0\t0\t35\t0\t0\t1896\n",
        "2017-04-17/2017-04-23\t2485\t0\t0\t233\t0\t0\t0\t87\t0\t0\t...\t0\t0\t0\t0\t0\t0\t23\t0\t0\t1753\n",
        "2017-04-24/2017-04-30\t4098\t1\t0\t238\t0\t1\t0\t94\t0\t0\t...\t0\t0\t0\t0\t0\t0\t22\t1\t0\t1713\n",
        "2017-05-01/2017-05-07\t2698\t1\t0\t227\t0\t0\t0\t69\t0\t0\t...\t0\t0\t1\t0\t0\t0\t18\t0\t0\t1146\n",
        "2017-05-08/2017-05-14\t2414\t0\t0\t242\t0\t1\t0\t71\t1\t0\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t70\n",
        "2017-05-15/2017-05-21\t5374\t0\t0\t241\t0\t0\t0\t105\t0\t0\t...\t0\t0\t0\t0\t0\t0\t18\t0\t0\t67\n",
        "2017-05-22/2017-05-28\t3634\t0\t0\t245\t0\t0\t0\t127\t0\t0\t...\t0\t0\t0\t0\t0\t0\t20\t0\t0\t88\n",
        "2017-05-29/2017-06-04\t1267\t0\t0\t107\t0\t0\t0\t43\t0\t0\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t38\n",
        "44 rows × 180 columns\n",
        "\n",
        "\n",
        "Day 1, 3, 5 리텐션 곡선 (첫 5 코호트)\n",
        "\n",
        "A/B 테스트 형태로 전략별 성과 비교\n",
        "\n",
        "Retention 개선 KPI 설정\n",
        "\n",
        "Day 1 Retention +10%, Week 1 Retention +5% 등 목표 수립\n",
        "\n",
        "채널별 비교: Google / SNS / Referral 등의 소스별 리텐션 곡선 도출\n",
        "\n",
        "국가별 비교: Russia, Germany, Japan 등도 동일 방식으로 분석\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# =============================================================================\n",
        "# 0. CSV 파일 로드 및 전처리\n",
        "# =============================================================================\n",
        "# fullVisitorId를 문자열로 읽어 Dtype Warning 회피\n",
        "df = pd.read_csv('new_train.csv', dtype={'fullVisitorId': str})\n",
        "\n",
        "# 날짜 컬럼을 datetime 타입으로 변환 (분석 및 시각화 편의를 위해)\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df['first_visit_date'] = pd.to_datetime(df['first_visit_date'])\n",
        "\n",
        "# 데이터 미리보기 및 기본 정보 출력\n",
        "print(\"데이터 미리보기:\")\n",
        "display(df.head())\n",
        "print(\"데이터 정보:\")\n",
        "print(df.info())\n",
        "\n",
        "# =============================================================================\n",
        "# 1. Day 1, 3, 5 리텐션 분석 및 KPI 설정\n",
        "# =============================================================================\n",
        "print(\"\\n[1] Day 1, 3, 5 리텐션 분석 및 KPI 설정\")\n",
        "\n",
        "# 코호트별(첫 방문일)로 days_since_first_visit에 따른 고유 사용자 수 계산\n",
        "cohort_data = df.groupby(['first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (행: first_visit_date, 열: days_since_first_visit)\n",
        "retention_table = cohort_data.pivot(index='first_visit_date', columns='days_since_first_visit', values='fullVisitorId').fillna(0)\n",
        "\n",
        "# Day 0 (첫 방문일 기준) 대비 리텐션 비율 계산 (존재할 경우)\n",
        "if 0 in retention_table.columns:\n",
        "    retention_rate = retention_table.divide(retention_table[0], axis=0)\n",
        "else:\n",
        "    retention_rate = retention_table.copy()\n",
        "\n",
        "# Day 1, 3, 5 데이터만 선택 (해당 컬럼이 있을 경우)\n",
        "desired_days = [col for col in [1, 3, 5] if col in retention_rate.columns]\n",
        "retention_rate_filtered = retention_rate[desired_days]\n",
        "\n",
        "print(\"Day 1, 3, 5 리텐션 비율 (상위 5 코호트):\")\n",
        "display(retention_rate_filtered.head())\n",
        "\n",
        "# KPI: 전체 코호트의 평균 Day 1 리텐션 및 Week 1 리텐션 (weeks_since_first_visit 사용)\n",
        "if 1 in retention_table.columns:\n",
        "    avg_day1 = retention_table[1].mean() / retention_table[0].mean() if 0 in retention_table.columns else retention_table[1].mean()\n",
        "    target_day1 = avg_day1 * 1.10  # +10% 목표\n",
        "    print(f\"Baseline Day 1 Retention: {avg_day1:.2%}  ->  Target: {target_day1:.2%}\")\n",
        "else:\n",
        "    print(\"Day 1 데이터가 없습니다.\")\n",
        "\n",
        "# Week 1 KPI 설정 (weeks_since_first_visit 컬럼 사용)\n",
        "cohort_week_data = df.groupby(['first_visit_date', 'weeks_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "week_pivot = cohort_week_data.pivot(index='first_visit_date', columns='weeks_since_first_visit', values='fullVisitorId').fillna(0)\n",
        "if 0 in week_pivot.columns and 1 in week_pivot.columns:\n",
        "    week_retention = week_pivot.divide(week_pivot[0], axis=0)\n",
        "    avg_week1 = week_retention[1].mean()\n",
        "    target_week1 = avg_week1 * 1.05  # +5% 목표\n",
        "    print(f\"Baseline Week 1 Retention: {avg_week1:.2%}  ->  Target: {target_week1:.2%}\")\n",
        "else:\n",
        "    print(\"Week 1 데이터가 충분하지 않습니다.\")\n",
        "\n",
        "# 리텐션 곡선 시각화 (첫 5개의 코호트)\n",
        "plt.figure(figsize=(10, 6))\n",
        "for cohort in retention_rate_filtered.index[:5]:\n",
        "    days = retention_rate_filtered.columns.tolist()\n",
        "    values = retention_rate_filtered.loc[cohort].values\n",
        "    plt.plot(days, values, marker='o', label=str(cohort.date()))\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"Day 1, 3, 5 리텐션 곡선 (첫 5 코호트)\")\n",
        "plt.legend(title=\"첫 방문일\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 2. A/B 테스트 구성 및 리텐션 곡선 비교\n",
        "# =============================================================================\n",
        "print(\"\\n[2] A/B 테스트 구성 및 리텐션 곡선 비교\")\n",
        "\n",
        "# fullVisitorId의 마지막 숫자를 기준으로 그룹 분리 (짝수: A, 홀수: B)\n",
        "df['group'] = df['fullVisitorId'].str[-1].astype(int) % 2\n",
        "df['group'] = df['group'].map({0: \"A\", 1: \"B\"})\n",
        "\n",
        "# 그룹별, 코호트별, days_since_first_visit별 고유 사용자 수 계산\n",
        "ab_data = df.groupby(['group', 'first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (인덱스: group, first_visit_date / 열: days_since_first_visit)\n",
        "ab_pivot = ab_data.pivot_table(index=['group', 'first_visit_date'], columns='days_since_first_visit', values='fullVisitorId', fill_value=0)\n",
        "\n",
        "# Day 0 기준 리텐션 비율 계산 (존재할 경우)\n",
        "if 0 in ab_pivot.columns:\n",
        "    ab_retention = ab_pivot.divide(ab_pivot[0], axis=0)\n",
        "else:\n",
        "    ab_retention = ab_pivot.copy()\n",
        "\n",
        "# Day 1, 3, 5 컬럼 선택\n",
        "cols_ab = [col for col in [1, 3, 5] if col in ab_retention.columns]\n",
        "print(\"A/B 그룹별 Day 1, 3, 5 리텐션 비율 (일부 예시):\")\n",
        "display(ab_retention[cols_ab].reset_index().head())\n",
        "\n",
        "# A/B 그룹별 리텐션 곡선 시각화 (각 그룹의 첫 3 코호트)\n",
        "plt.figure(figsize=(12, 6))\n",
        "for group in ['A', 'B']:\n",
        "    if group in ab_retention.index.get_level_values(0):\n",
        "        group_data = ab_retention.loc[group]\n",
        "        for cohort in group_data.index[:3]:\n",
        "            days = group_data.columns.tolist()\n",
        "            values = group_data.loc[cohort].values\n",
        "            plt.plot(days, values, marker='o', label=f\"{group} - {pd.to_datetime(cohort).date()}\")\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"A/B 테스트: Day 1, 3, 5 리텐션 곡선\")\n",
        "plt.legend(title=\"그룹 및 코호트\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 3. 채널(trafficSource)별 리텐션 비교\n",
        "# =============================================================================\n",
        "print(\"\\n[3] 채널(trafficSource)별 리텐션 비교\")\n",
        "# 원하는 유입 채널 설정: Google, SNS, Referral\n",
        "desired_channels = [\"Google\", \"SNS\", \"Referral\"]\n",
        "# trafficSource 컬럼에 대소문자 이슈가 있을 수 있으므로 일괄 소문자화 후 필터링 (필요에 따라 수정)\n",
        "df['trafficSource'] = df['trafficSource'].str.lower()\n",
        "desired_channels = [ch.lower() for ch in desired_channels]\n",
        "\n",
        "channel_df = df[df['trafficSource'].isin(desired_channels)]\n",
        "\n",
        "# 채널별, 코호트별, days_since_first_visit별 고유 사용자 수 계산\n",
        "channel_data = channel_df.groupby(['trafficSource', 'first_visit_date', 'days_since_first_visit'])['fullVisitorId'].nunique().reset_index()\n",
        "\n",
        "# 피벗 테이블 생성 (인덱스: trafficSource, first_visit_date / 열: days_since_first_visit)\n",
        "channel_pivot = channel_data.pivot_table(index=['trafficSource', 'first_visit_date'], columns='days_since_first_visit', values='fullVisitorId', fill_value=0)\n",
        "\n",
        "# Day 0 기준 리텐션 비율 계산\n",
        "if 0 in channel_pivot.columns:\n",
        "    channel_retention = channel_pivot.divide(channel_pivot[0], axis=0)\n",
        "else:\n",
        "    channel_retention = channel_pivot.copy()\n",
        "\n",
        "print(\"채널별 (Google, SNS, Referral) Day 1, 3, 5 리텐션 비율:\")\n",
        "cols_channel = [col for col in [1, 3, 5] if col in channel_retention.columns]\n",
        "display(channel_retention[cols_channel].reset_index())\n",
        "\n",
        "# 각 채널별 첫 코호트의 리텐션 곡선 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "for channel in desired_channels:\n",
        "    try:\n",
        "        channel_cohorts = channel_retention.loc[channel]\n",
        "        if not channel_cohorts.empty:\n",
        "            cohort = channel_cohorts.index[0]\n",
        "            days = [col for col in [1, 3, 5] if col in channel_retention.columns]\n",
        "            values = channel_retention.loc[(channel, cohort)][days].values\n",
        "            plt.plot(days, values, marker='o', label=f\"{channel.title()} - {pd.to_datetime(cohort).date()}\")\n",
        "    except Exception as e:\n",
        "        continue\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"유입 채널별 (Google, SNS, Referral) Day 1, 3, 5 리텐션 곡선\")\n",
        "plt.legend(title=\"채널 & 코호트\", loc='best')\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 4. 국가별 비교: Russia, Germany, Japan\n",
        "# =============================================================================\n",
        "print(\"\\n[4] 국가별 비교: Russia, Germany, Japan\")\n",
        "desired_countries = [\"Russia\", \"Germany\", \"Japan\"]\n",
        "# 대소문자 통일 (필요시)\n",
        "df['country'] = df['country'].str.title()\n",
        "desired_countries = [ctry.title() for ctry in desired_countries]\n",
        "\n",
        "country_df = df[df['country'].isin(desired_countries)]\n",
        "\n",
        "# Day 0 기준 (최초 방문자 수)와 Day 0 이후 방문자 수 (재방문)\n",
        "base_country = country_df[country_df['days_since_first_visit'] == 0].groupby('country')['fullVisitorId'].nunique()\n",
        "return_country = country_df[country_df['days_since_first_visit'] > 0].groupby('country')['fullVisitorId'].nunique()\n",
        "\n",
        "# 국가별 재방문률 계산 (재방문자 수 / 최초 방문자 수)\n",
        "country_retention_rate = (return_country / base_country).fillna(0).sort_values(ascending=False)\n",
        "print(\"선택 국가별 재방문 비율:\")\n",
        "country_retention_rate_df = country_retention_rate.reset_index()\n",
        "country_retention_rate_df.columns = [\"country\", \"revisit_ratio\"]\n",
        "display(country_retention_rate_df)\n",
        "\n",
        "# 바 차트로 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=country_retention_rate_df, x=\"country\", y=\"revisit_ratio\")\n",
        "plt.xlabel(\"Country\")\n",
        "plt.ylabel(\"Revisit Ratio\")\n",
        "plt.title(\"Russia, Germany, Japan 국가별 재방문률\")\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 5. 피벗 테이블로 유입 트렌드 요약 (cohort_week vs trafficSource)\n",
        "# =============================================================================\n",
        "print(\"\\n[5] 피벗 테이블로 유입 트렌드 요약 (cohort_week vs trafficSource)\")\n",
        "\n",
        "pivot_trend = pd.pivot_table(df,\n",
        "                             index='cohort_week',\n",
        "                             columns='trafficSource',\n",
        "                             values='fullVisitorId',\n",
        "                             aggfunc=pd.Series.nunique,\n",
        "                             fill_value=0)\n",
        "print(\"피벗 테이블 (cohort_week vs trafficSource):\")\n",
        "display(pivot_trend)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(pivot_trend, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"유입 트렌드 (코호트 주별 vs 트래픽 소스)\")\n",
        "plt.xlabel(\"TrafficSource\")\n",
        "plt.ylabel(\"Cohort Week\")\n",
        "plt.show()\n",
        "\n",
        "     \n",
        "데이터 미리보기:\n",
        "fullVisitorId\tdate\tdeviceCategory\toperatingSystem\tbrowser\tcountry\ttrafficSource\tisFirstVisit\tfirst_visit_date\tdays_since_first_visit\tcohort_week\tweeks_since_first_visit\ttld\tcountry_group\tplatform_group\n",
        "0\t4214259466202417480\t2016-10-14 00:00:00+00:00\tdesktop\tWindows\tInternet Explorer\tUnited States\task\t0\t2016-10-06 00:00:00+00:00\t8\t2016-10-03/2016-10-09\t1\tunknown\tOther\tOther\n",
        "1\t3541738396641160713\t2017-04-30 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-30 00:00:00+00:00\t0\t2017-04-24/2017-04-30\t0\tunknown\tOther\tOther\n",
        "2\t8276557623242379934\t2017-03-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-20 00:00:00+00:00\t0\t2017-03-20/2017-03-26\t0\tunknown\tOther\tOther\n",
        "3\t5855313117666192014\t2017-04-01 00:00:00+00:00\tdesktop\tWindows\tChrome\tAustralia\task\t0\t2017-03-30 00:00:00+00:00\t2\t2017-03-27/2017-04-02\t0\tunknown\tOther\tOther\n",
        "4\t2619633492044211273\t2017-05-20 00:00:00+00:00\tdesktop\tWindows\tChrome\tUnited States\task\t0\t2017-04-22 00:00:00+00:00\t28\t2017-04-17/2017-04-23\t4\tunknown\tOther\tOther\n",
        "데이터 정보:\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 748134 entries, 0 to 748133\n",
        "Data columns (total 15 columns):\n",
        " #   Column                   Non-Null Count   Dtype              \n",
        "---  ------                   --------------   -----              \n",
        " 0   fullVisitorId            748134 non-null  object             \n",
        " 1   date                     748134 non-null  datetime64[ns, UTC]\n",
        " 2   deviceCategory           748134 non-null  object             \n",
        " 3   operatingSystem          748134 non-null  object             \n",
        " 4   browser                  748134 non-null  object             \n",
        " 5   country                  748134 non-null  object             \n",
        " 6   trafficSource            748134 non-null  object             \n",
        " 7   isFirstVisit             748134 non-null  int64              \n",
        " 8   first_visit_date         748134 non-null  datetime64[ns, UTC]\n",
        " 9   days_since_first_visit   748134 non-null  int64              \n",
        " 10  cohort_week              748134 non-null  object             \n",
        " 11  weeks_since_first_visit  748134 non-null  int64              \n",
        " 12  tld                      748134 non-null  object             \n",
        " 13  country_group            748134 non-null  object             \n",
        " 14  platform_group           748134 non-null  object             \n",
        "dtypes: datetime64[ns, UTC](2), int64(3), object(10)\n",
        "memory usage: 85.6+ MB\n",
        "None\n",
        "\n",
        "[1] Day 1, 3, 5 리텐션 분석 및 KPI 설정\n",
        "Day 1, 3, 5 리텐션 비율 (상위 5 코호트):\n",
        "days_since_first_visit\t1\t3\t5\n",
        "first_visit_date\n",
        "2016-08-01 00:00:00+00:00\t0.049709\t0.026469\t0.009684\n",
        "2016-08-02 00:00:00+00:00\t0.047078\t0.021104\t0.004329\n",
        "2016-08-03 00:00:00+00:00\t0.036550\t0.004107\t0.017659\n",
        "2016-08-04 00:00:00+00:00\t0.029845\t0.005426\t0.011628\n",
        "2016-08-05 00:00:00+00:00\t0.011691\t0.016637\t0.010342\n",
        "Baseline Day 1 Retention: 2.53%  ->  Target: 2.78%\n",
        "Baseline Week 1 Retention: 2.00%  ->  Target: 2.10%\n",
        "\n",
        "[2] A/B 테스트 구성 및 리텐션 곡선 비교\n",
        "A/B 그룹별 Day 1, 3, 5 리텐션 비율 (일부 예시):\n",
        "days_since_first_visit\tgroup\tfirst_visit_date\t1\t3\t5\n",
        "0\tA\t2016-08-01 00:00:00+00:00\t0.056988\t0.025780\t0.012212\n",
        "1\tA\t2016-08-02 00:00:00+00:00\t0.050549\t0.017582\t0.004396\n",
        "2\tA\t2016-08-03 00:00:00+00:00\t0.038238\t0.003325\t0.019119\n",
        "3\tA\t2016-08-04 00:00:00+00:00\t0.025197\t0.003937\t0.009449\n",
        "4\tA\t2016-08-05 00:00:00+00:00\t0.009499\t0.015544\t0.013817\n",
        "\n",
        "[3] 채널(trafficSource)별 리텐션 비교\n",
        "채널별 (Google, SNS, Referral) Day 1, 3, 5 리텐션 비율:\n",
        "days_since_first_visit\ttrafficSource\tfirst_visit_date\t1\t3\t5\n",
        "0\tgoogle\t2016-08-01 00:00:00+00:00\t0.079320\t0.039660\t0.016997\n",
        "1\tgoogle\t2016-08-02 00:00:00+00:00\t0.050820\t0.021311\t0.004918\n",
        "2\tgoogle\t2016-08-03 00:00:00+00:00\t0.042945\t0.007362\t0.022086\n",
        "3\tgoogle\t2016-08-04 00:00:00+00:00\t0.045213\t0.009309\t0.018617\n",
        "4\tgoogle\t2016-08-05 00:00:00+00:00\t0.018732\t0.018732\t0.012968\n",
        "...\t...\t...\t...\t...\t...\n",
        "299\tgoogle\t2017-05-27 00:00:00+00:00\t0.019340\t0.005688\t0.000000\n",
        "300\tgoogle\t2017-05-28 00:00:00+00:00\t0.027879\t0.007273\t0.000000\n",
        "301\tgoogle\t2017-05-29 00:00:00+00:00\t0.026624\t0.000000\t0.000000\n",
        "302\tgoogle\t2017-05-30 00:00:00+00:00\t0.028926\t0.000000\t0.000000\n",
        "303\tgoogle\t2017-05-31 00:00:00+00:00\t0.000000\t0.000000\t0.000000\n",
        "304 rows × 5 columns\n",
        "\n",
        "\n",
        "[4] 국가별 비교: Russia, Germany, Japan\n",
        "선택 국가별 재방문 비율:\n",
        "country\trevisit_ratio\n",
        "0\tJapan\t0.077375\n",
        "1\tGermany\t0.067509\n",
        "2\tRussia\t0.030552\n",
        "\n",
        "[5] 피벗 테이블로 유입 트렌드 요약 (cohort_week vs trafficSource)\n",
        "피벗 테이블 (cohort_week vs trafficSource):\n",
        "trafficSource\t(direct)\t(not set)\t9to5google.com\tad.doubleclick.net\tadwords.google.com\tamazon.com\tanalytics.google.com\taol\tarstechnica.com\task\t...\twanelo.com\twap.sogou.com\tweb.facebook.com\tweb.skype.com\tweb.telegram.org\twheretoget.it\tyahoo\tyahoo.com\tyandex\tyoutube.com\n",
        "cohort_week\n",
        "2016-08-01/2016-08-07\t3575\t0\t0\t0\t1\t0\t55\t0\t0\t1\t...\t0\t0\t0\t0\t0\t0\t15\t0\t0\t4885\n",
        "2016-08-08/2016-08-14\t3240\t1\t0\t0\t0\t0\t57\t0\t0\t3\t...\t0\t0\t0\t0\t0\t0\t4\t0\t0\t5514\n",
        "2016-08-15/2016-08-21\t3224\t0\t0\t0\t0\t0\t46\t0\t0\t1\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t5413\n",
        "2016-08-22/2016-08-28\t2670\t0\t0\t0\t0\t0\t52\t1\t0\t5\t...\t0\t0\t0\t0\t0\t0\t11\t0\t0\t5191\n",
        "2016-08-29/2016-09-04\t2628\t0\t0\t0\t0\t2\t70\t0\t1\t4\t...\t0\t0\t0\t0\t0\t0\t7\t0\t0\t5684\n",
        "2016-09-05/2016-09-11\t2272\t1\t0\t0\t0\t0\t47\t0\t0\t4\t...\t1\t0\t0\t0\t0\t1\t8\t0\t0\t5484\n",
        "2016-09-12/2016-09-18\t2704\t1\t0\t0\t0\t0\t75\t0\t0\t1\t...\t0\t0\t0\t0\t0\t0\t6\t0\t0\t5132\n",
        "2016-09-19/2016-09-25\t4333\t1\t0\t1\t0\t1\t81\t0\t0\t3\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t5291\n",
        "2016-09-26/2016-10-02\t5512\t1\t0\t0\t1\t0\t81\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t4766\n",
        "2016-10-03/2016-10-09\t9411\t0\t0\t0\t0\t0\t70\t0\t0\t7\t...\t0\t0\t0\t0\t0\t0\t30\t0\t0\t5313\n",
        "2016-10-10/2016-10-16\t6022\t0\t0\t0\t0\t0\t87\t0\t0\t4\t...\t0\t0\t1\t0\t0\t0\t19\t0\t0\t6483\n",
        "2016-10-17/2016-10-23\t6719\t0\t0\t0\t0\t0\t63\t0\t0\t4\t...\t0\t0\t0\t0\t0\t0\t34\t0\t0\t10778\n",
        "2016-10-24/2016-10-30\t6713\t0\t0\t0\t3\t0\t70\t0\t0\t0\t...\t0\t0\t0\t0\t0\t0\t14\t0\t0\t13840\n",
        "2016-10-31/2016-11-06\t7033\t0\t0\t0\t1\t1\t73\t0\t1\t3\t...\t0\t0\t0\t0\t0\t0\t12\t0\t0\t13273\n",
        "2016-11-07/2016-11-13\t7900\t0\t0\t0\t0\t0\t104\t1\t0\t1\t...\t0\t0\t0\t0\t1\t0\t21\t0\t1\t12853\n",
        "2016-11-14/2016-11-20\t8290\t0\t0\t0\t0\t0\t124\t0\t0\t4\t...\t0\t0\t0\t0\t0\t0\t23\t0\t0\t13014\n",
        "2016-11-21/2016-11-27\t9404\t0\t0\t0\t0\t2\t84\t3\t0\t3\t...\t0\t0\t0\t0\t0\t0\t32\t0\t0\t11636\n",
        "2016-11-28/2016-12-04\t10254\t0\t0\t0\t0\t0\t78\t0\t0\t8\t...\t0\t0\t0\t0\t0\t0\t34\t0\t0\t11266\n",
        "2016-12-05/2016-12-11\t10690\t2\t0\t0\t0\t0\t89\t0\t0\t8\t...\t0\t1\t0\t0\t0\t0\t28\t0\t0\t3465\n",
        "2016-12-12/2016-12-18\t11860\t0\t0\t1\t1\t2\t82\t0\t0\t7\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t1992\n",
        "2016-12-19/2016-12-25\t6873\t0\t0\t0\t0\t0\t27\t0\t0\t9\t...\t0\t0\t0\t0\t0\t0\t12\t0\t0\t1813\n",
        "2016-12-26/2017-01-01\t4025\t0\t0\t0\t0\t0\t20\t0\t0\t4\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t1787\n",
        "2017-01-02/2017-01-08\t7225\t0\t0\t0\t0\t0\t39\t0\t0\t5\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t1998\n",
        "2017-01-09/2017-01-15\t7862\t0\t0\t1\t0\t1\t73\t0\t0\t2\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t2106\n",
        "2017-01-16/2017-01-22\t7135\t0\t0\t0\t1\t0\t61\t0\t0\t5\t...\t0\t0\t0\t0\t0\t0\t16\t0\t0\t2089\n",
        "2017-01-23/2017-01-29\t10159\t2\t0\t0\t0\t0\t88\t1\t0\t4\t...\t0\t0\t0\t0\t0\t1\t18\t0\t1\t2008\n",
        "2017-01-30/2017-02-05\t8256\t0\t0\t0\t0\t0\t90\t0\t0\t1\t...\t0\t0\t0\t0\t0\t1\t15\t0\t0\t2161\n",
        "2017-02-06/2017-02-12\t6200\t0\t0\t0\t0\t0\t78\t0\t0\t1\t...\t0\t0\t0\t0\t0\t0\t21\t0\t0\t2299\n",
        "2017-02-13/2017-02-19\t3819\t0\t0\t0\t0\t1\t87\t0\t0\t8\t...\t0\t0\t0\t0\t0\t0\t20\t0\t0\t2155\n",
        "2017-02-20/2017-02-26\t3297\t1\t0\t0\t0\t0\t88\t0\t0\t14\t...\t0\t0\t0\t0\t0\t0\t27\t0\t1\t2215\n",
        "2017-02-27/2017-03-05\t2344\t0\t0\t0\t0\t0\t89\t0\t0\t10\t...\t0\t0\t0\t0\t0\t0\t13\t0\t0\t2417\n",
        "2017-03-06/2017-03-12\t2377\t2\t0\t0\t0\t1\t78\t0\t0\t4\t...\t0\t0\t0\t1\t0\t1\t28\t0\t0\t2478\n",
        "2017-03-13/2017-03-19\t2453\t2\t0\t0\t0\t0\t89\t0\t0\t4\t...\t0\t0\t0\t0\t0\t0\t18\t0\t0\t2644\n",
        "2017-03-20/2017-03-26\t2486\t8\t1\t0\t0\t0\t138\t0\t0\t3\t...\t0\t0\t1\t0\t0\t0\t22\t0\t0\t2471\n",
        "2017-03-27/2017-04-02\t3716\t9\t0\t0\t2\t0\t90\t2\t0\t5\t...\t0\t0\t0\t0\t0\t0\t247\t0\t0\t2651\n",
        "2017-04-03/2017-04-09\t3641\t8\t0\t0\t0\t0\t97\t0\t0\t6\t...\t0\t0\t0\t0\t0\t0\t77\t0\t0\t2609\n",
        "2017-04-10/2017-04-16\t2379\t14\t0\t0\t0\t0\t83\t0\t0\t3\t...\t0\t0\t0\t0\t0\t0\t35\t0\t0\t1896\n",
        "2017-04-17/2017-04-23\t2485\t0\t0\t0\t0\t0\t87\t0\t0\t9\t...\t0\t0\t0\t0\t0\t0\t23\t0\t0\t1753\n",
        "2017-04-24/2017-04-30\t4098\t1\t0\t0\t1\t0\t94\t0\t0\t6\t...\t0\t0\t0\t0\t0\t0\t22\t1\t0\t1713\n",
        "2017-05-01/2017-05-07\t2698\t1\t0\t0\t0\t0\t69\t0\t0\t3\t...\t0\t0\t1\t0\t0\t0\t18\t0\t0\t1146\n",
        "2017-05-08/2017-05-14\t2414\t0\t0\t0\t1\t0\t71\t1\t0\t4\t...\t0\t0\t0\t0\t0\t0\t17\t0\t0\t70\n",
        "2017-05-15/2017-05-21\t5374\t0\t0\t0\t0\t0\t105\t0\t0\t1\t...\t0\t0\t0\t0\t0\t0\t18\t0\t0\t67\n",
        "2017-05-22/2017-05-28\t3634\t0\t0\t0\t0\t0\t127\t0\t0\t6\t...\t0\t0\t0\t0\t0\t0\t20\t0\t0\t88\n",
        "2017-05-29/2017-06-04\t1267\t0\t0\t0\t0\t0\t43\t0\t0\t3\t...\t0\t0\t0\t0\t0\t0\t9\t0\t0\t38\n",
        "44 rows × 180 columns\n",
        "\n",
        "\n",
        "Day 1 → 3 구간: 이탈을 최소화하기 위한 온보딩과 즉시적인 리워드 필요\n",
        "\n",
        "Day 3 → 5 구간: 잠시 떠났던 사용자를 다시 끌어들이는 재참여(Win-back) 캠페인의 효과 기대\n",
        "\n",
        "KPI 설정 적용\n",
        "\n",
        "기본(Baseline) 지표 산출\n",
        "\n",
        "Day 1 리텐션율: 약 8%\n",
        "\n",
        "Day 3 리텐션율: 약 3%\n",
        "\n",
        "Day 5 리텐션율: 약 2% 이하\n",
        "\n",
        "Google 채널을 통한 방문자들이 초기에 대거 이탈하는 전형적인 패턴.\n",
        "\n",
        "Day 1 → Day 3 구간의 급락이 크므로, 초기 3일 내 이탈 방지를 위한 온보딩 강화가 필요한 상황\n",
        "\n",
        "Day 1 Retention KPI:\n",
        "\n",
        "전체 코호트의 Day 0과 Day 1 데이터를 이용해 기본 Day 1 리텐션율(예: 전체 평균)을 계산\n",
        "\n",
        "예를 들어, Day 1 리텐션 비율을 기본값으로 산출한 후,\n",
        "\n",
        "이 값에 10%를 더한 값(즉, 현재의 기본 수치에서 10% 향상된 목표)을 KPI로 설정\n",
        "\n",
        "Week 1 Retention KPI:\n",
        "\n",
        "weeks_since_first_visit 컬럼을 사용해 주 단위 코호트 데이터를 집계한 후,\n",
        "\n",
        "Week 0 대비 Week 1 리텐션률을 계산\n",
        "\n",
        "이 값의 평균에 5%를 추가한 값을 목표로 설정\n",
        "\n",
        "일본:\n",
        "\n",
        "재방문이 잘 이뤄지는 국가로, 성공 패턴을 분석해 글로벌 확장 전략에 반영\n",
        "\n",
        "독일:\n",
        "\n",
        "중간 수준 → 더 나은 현지화, 마케팅 최적화로 8%대 재방문률에 근접 가능\n",
        "\n",
        "**러시아: **\n",
        "\n",
        "개선 여지가 가장 큰 시장\n",
        "\n",
        "→ 전용 마케팅 채널, 러시아어 UI, 현지 결제수단 등 도입 재방문률을 단계적으로 끌어올릴 수 있음\n",
        "\n",
        "2017-03-20/2017-03-26과\n",
        "\n",
        "2017-04-24/2017-04-30 주차가 결정적인 트래픽 변동 시점\n",
        "\n",
        "2016-10월 변동시\n",
        "\n",
        "해당 기간에 어떤 마케팅 활동이나 외부 이벤트가 있었는지 추가 분석필요\n",
        "\n",
        "정리\n",
        "A/B 그룹 간 리텐션 곡선이 대동소이하여, 실험군 간 큰 차이는 관측되지 않음.\n",
        "\n",
        "모든 코호트에서 초기 단기간에 거의 이탈이 이루어지므로, Day 1 ~ 3 구간을 집중 관리하는 전략이 중요.\n",
        "\n",
        "장기적으로는 극소수 사용자가 잔존하며, 5일차 이후 리텐션이 미미하므로, 해당 소수의 잔존 사용자에게도 별도 관리 전략(예: VIP 멤버십, 고도화된 리워드 등)이 필요\n",
        "\n",
        "결론\n",
        "초기 7일 내 집중적 개입이 우선적으로 필요\n",
        "→ 가입 후 첫 7일간 온보딩, 단기 리워드, 푸시 알림 등을 통해 사용자가 꾸준히 재방문하도록 유도하는 것이 가장 효과적\n",
        "정성적 분석 및 외부 요인 연계 또한 병행해야 한다.\n",
        "→ 초기 전략의 효과를 극대화하고, 장기적인 사용자 충성도를 높이기 위해선 이벤트, 마케팅 캠페인,\n",
        "사용자 인터뷰 등을 통해 외부 요인과 연관된 인사이트도 함께 고려하는 것이 좋다.\n",
        "결국, 최적의 전략은 초기 7일 동안 사용자 재참여를 극대화하는 단기 전략과,\n",
        "동시에 정성적 분석을 통한 장기 개선 요소 파악을 병행하는 형태가 된다.\n",
        "이를 통해 전체적인 리텐션 개선 및 고객 생애가치(LTV)를 상승시키는 방향으로 나아갈 수 있다.\n",
        "가상 데이터를 생성하여 각 사용자의 첫 방문 후 14일 동안의 재방문 여부(일별)를 시뮬레이션\n",
        "사용자들을 무작위로 컨트롤군과 개선군(Intervention)으로 나눔\n",
        "\n",
        "각 군별로 Day 0부터 Day 14까지의 리텐션 데이터를 집계하고,\n",
        "\n",
        "초기 7일 동안 개선군에서 리텐션이 상승하는 효과를 모의함.\n",
        "\n",
        "KPI (예: Day 1 및 Week 1 리텐션) 산출 및 목표 설정과 함께 시각화\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "\n",
        "# =============================================================================\n",
        "# 0. 가상 데이터 생성\n",
        "# =============================================================================\n",
        "np.random.seed(42)\n",
        "num_users = 5000\n",
        "\n",
        "# 사용자 ID 생성 (문자형)\n",
        "user_ids = [str(np.random.randint(10**16, 10**17)) for _ in range(num_users)]\n",
        "\n",
        "# 모든 사용자의 첫 방문일을 동일한 날짜로 설정 (단일 코호트)\n",
        "first_date = pd.to_datetime(\"2022-01-01\")\n",
        "\n",
        "# 사용자를 무작위로 두 그룹으로 분할: 'control' vs 'intervention'\n",
        "groups = np.random.choice([\"control\", \"intervention\"], size=num_users, p=[0.5, 0.5])\n",
        "\n",
        "# 설정: 각 군별 기본 재방문 확률 (Day d에 대한 확률)\n",
        "# 컨트롤군: 시간이 지날수록 점진적으로 감소 (예시)\n",
        "control_ret_probs = {\n",
        "    0: 1.0,    # Day 0: 항상 첫 방문 기록 있음\n",
        "    1: 0.10,\n",
        "    2: 0.07,\n",
        "    3: 0.05,\n",
        "    4: 0.04,\n",
        "    5: 0.03,\n",
        "    6: 0.025,\n",
        "    7: 0.02,\n",
        "    8: 0.015,\n",
        "    9: 0.012,\n",
        "    10: 0.01,\n",
        "    11: 0.008,\n",
        "    12: 0.007,\n",
        "    13: 0.006,\n",
        "    14: 0.005\n",
        "}\n",
        "\n",
        "# intervention 그룹: 초기 7일의 확률을 50% 정도 개선 (최대 1.0 넘어가지 않도록)\n",
        "intervention_ret_probs = {}\n",
        "for d, prob in control_ret_probs.items():\n",
        "    if d > 0 and d <= 7:\n",
        "        # 50% 개선 효과 적용 (예: 0.10 -> 0.15 등)\n",
        "        intervention_ret_probs[d] = min(prob * 1.5, 1.0)\n",
        "    else:\n",
        "        intervention_ret_probs[d] = prob\n",
        "\n",
        "# 생성할 행 리스트\n",
        "data_rows = []\n",
        "\n",
        "# 각 사용자에 대해, Day 0는 항상 방문\n",
        "for uid, group in zip(user_ids, groups):\n",
        "    # 첫 방문 기록 (Day 0)\n",
        "    data_rows.append({\n",
        "        \"fullVisitorId\": uid,\n",
        "        \"first_visit_date\": first_date,\n",
        "        \"date\": first_date,\n",
        "        \"days_since_first_visit\": 0,\n",
        "        \"group\": group\n",
        "    })\n",
        "    # 1일부터 14일까지 시뮬레이션\n",
        "    for d in range(1, 15):\n",
        "        # 그룹에 따른 재방문 확률 선택\n",
        "        if group == \"control\":\n",
        "            p = control_ret_probs.get(d, 0)\n",
        "        else:\n",
        "            p = intervention_ret_probs.get(d, 0)\n",
        "        # 해당 일에 재방문할지 결정 (베르누이 시행)\n",
        "        if np.random.rand() < p:\n",
        "            visit_date = first_date + pd.Timedelta(days=d)\n",
        "            data_rows.append({\n",
        "                \"fullVisitorId\": uid,\n",
        "                \"first_visit_date\": first_date,\n",
        "                \"date\": visit_date,\n",
        "                \"days_since_first_visit\": d,\n",
        "                \"group\": group\n",
        "            })\n",
        "\n",
        "# 가상 데이터 DataFrame 생성\n",
        "synthetic_df = pd.DataFrame(data_rows)\n",
        "\n",
        "# 데이터 미리보기\n",
        "print(\"가상 데이터 미리보기:\")\n",
        "display(synthetic_df.head(10))\n",
        "print(\"전체 데이터 수:\", len(synthetic_df))\n",
        "\n",
        "# =============================================================================\n",
        "# 1. 리텐션 분석 & KPI 산출 (일별, 주별)\n",
        "# =============================================================================\n",
        "print(\"\\n[1] Day 1, 3, 5 리텐션 분석 및 KPI 산출\")\n",
        "\n",
        "# 코호트 기준: 모두 동일한 first_visit_date 이므로, 그룹별로 집계\n",
        "# 각 group별 Day별 고유 사용자 수 집계\n",
        "cohort_data = synthetic_df.groupby([\"group\", \"days_since_first_visit\"])[\"fullVisitorId\"].nunique().reset_index()\n",
        "# 피벗 테이블 생성: index=group, columns=days_since_first_visit, 값=고유 사용자 수\n",
        "retention_table = cohort_data.pivot(index=\"group\", columns=\"days_since_first_visit\", values=\"fullVisitorId\").fillna(0)\n",
        "\n",
        "# Day 0이 항상 전체 사용자 수 (각 그룹별)\n",
        "# 리텐션 비율 계산: Day d 값 / Day 0 값\n",
        "retention_rate = retention_table.div(retention_table[0], axis=0)\n",
        "\n",
        "print(\"리텐션 테이블 (전체):\")\n",
        "display(retention_table)\n",
        "print(\"\\n리텐션 비율 (전체):\")\n",
        "display(retention_rate)\n",
        "\n",
        "# KPI 산출: 예를 들어, 평균 Day 1 및 Week 1 리텐션 산출\n",
        "# Day 1 KPI\n",
        "if 1 in retention_rate.columns:\n",
        "    control_day1 = retention_rate.loc[\"control\", 1]\n",
        "    intervention_day1 = retention_rate.loc[\"intervention\", 1]\n",
        "    print(f\"Control Group Day 1 Retention: {control_day1:.2%}\")\n",
        "    print(f\"Intervention Group Day 1 Retention: {intervention_day1:.2%}\")\n",
        "    target_day1_improvement = 1.10  # +10% 목표\n",
        "    print(f\"Target for Intervention Group Day 1: {control_day1 * target_day1_improvement:.2%}\")\n",
        "else:\n",
        "    print(\"Day 1 데이터가 없습니다.\")\n",
        "\n",
        "# 주별 KPI: 각 사용자가 7일 이내를 주 0, 7일을 주 1으로 간주 (단일 코호트이므로 단순 집계)\n",
        "# 먼저, 각 방문의 주 차를 계산 (여기서는 days_since_first_visit // 7)\n",
        "synthetic_df[\"week_since_first_visit\"] = synthetic_df[\"days_since_first_visit\"] // 7\n",
        "\n",
        "week_data = synthetic_df.groupby([\"group\", \"week_since_first_visit\"])[\"fullVisitorId\"].nunique().reset_index()\n",
        "week_pivot = week_data.pivot(index=\"group\", columns=\"week_since_first_visit\", values=\"fullVisitorId\").fillna(0)\n",
        "week_retention = week_pivot.div(week_pivot[0], axis=0)\n",
        "print(\"\\n주별 리텐션 테이블:\")\n",
        "display(week_pivot)\n",
        "print(\"\\n주별 리텐션 비율:\")\n",
        "display(week_retention)\n",
        "\n",
        "if 1 in week_retention.columns:\n",
        "    control_week1 = week_retention.loc[\"control\", 1]\n",
        "    intervention_week1 = week_retention.loc[\"intervention\", 1]\n",
        "    print(f\"Control Group Week 1 Retention: {control_week1:.2%}\")\n",
        "    print(f\"Intervention Group Week 1 Retention: {intervention_week1:.2%}\")\n",
        "    target_week1_improvement = 1.05  # +5% 목표\n",
        "    print(f\"Target for Intervention Group Week 1: {control_week1 * target_week1_improvement:.2%}\")\n",
        "else:\n",
        "    print(\"Week 1 데이터가 충분하지 않습니다.\")\n",
        "\n",
        "# =============================================================================\n",
        "# 2. A/B 테스트 구성 및 리텐션 곡선 비교 (Control vs Intervention)\n",
        "# =============================================================================\n",
        "print(\"\\n[2] A/B 테스트: Control vs Intervention 리텐션 곡선 비교\")\n",
        "\n",
        "# 컨트롤과 인터벤션 그룹의 리텐션 곡선을 시각화 (Day 0~Day 14)\n",
        "plt.figure(figsize=(12, 6))\n",
        "days = sorted(retention_rate.columns)\n",
        "for grp in retention_rate.index:\n",
        "    plt.plot(days, retention_rate.loc[grp], marker='o', label=grp.capitalize())\n",
        "plt.xlabel(\"Days Since First Visit\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"Control vs Intervention 그룹 리텐션 곡선\")\n",
        "plt.legend(title=\"그룹\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 3. 전략 효과 검증: 초기 7일 내 집중적 개입의 효과 시뮬레이션\n",
        "# =============================================================================\n",
        "print(\"\\n[3] 전략 효과 검증: 초기 7일 내 집중적 개입 효과\")\n",
        "\n",
        "# 여기서는 Day 1 ~ Day 7의 리텐션 차이를 집중 비교\n",
        "days_focus = [d for d in retention_rate.columns if d <= 7]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for grp in retention_rate.index:\n",
        "    plt.plot(days_focus, retention_rate.loc[grp, days_focus], marker='o', label=grp.capitalize())\n",
        "plt.xlabel(\"Days Since First Visit (Focus: 0-7일)\")\n",
        "plt.ylabel(\"Retention Rate\")\n",
        "plt.title(\"초기 7일 내 리텐션 비교 (Control vs Intervention)\")\n",
        "plt.legend(title=\"그룹\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# 4. 정성적 분석 및 외부 요인 연계:\n",
        "# =============================================================================\n",
        "print(\"\\n[4] 정성적 분석/외부 요인: (시뮬레이션에서는 추가 로그/메모 등으로 연계 분석 필요)\")\n",
        "print(\"→ 실제 환경에서는 사용자의 피드백, 마케팅 캠페인 로그, A/B 테스트 외 질적 데이터를 함께 분석하여\\n   어떤 요인이 재방문률 개선에 기여했는지 종합적으로 판단해야 함.\")\n",
        "\n",
        "# =============================================================================\n",
        "# 최종 결론 출력\n",
        "# =============================================================================\n",
        "print(\"\\n[최종 결론]\")\n",
        "print(\"가상 데이터 시뮬레이션 결과, 개선(Invention) 그룹은 초기 7일 내 Day 1 및 Week 1 리텐션에서\\n컨트롤 그룹보다 높은 수치를 보입니다. 이는 온보딩 강화, 단기 리워드, 푸시 알림 등의\\n전략이 초기 재참여율 개선에 긍정적인 효과가 있을 수 있음.\")\n",
        "\n",
        "     \n",
        "가상 데이터 미리보기:\n",
        "fullVisitorId\tfirst_visit_date\tdate\tdays_since_first_visit\tgroup\n",
        "0\t72647193815832010\t2022-01-01\t2022-01-01\t0\tcontrol\n",
        "1\t31395404160821591\t2022-01-01\t2022-01-01\t0\tcontrol\n",
        "2\t89646337129577885\t2022-01-01\t2022-01-01\t0\tcontrol\n",
        "3\t89646337129577885\t2022-01-01\t2022-01-10\t9\tcontrol\n",
        "4\t35855174844287361\t2022-01-01\t2022-01-01\t0\tintervention\n",
        "5\t49429311572317115\t2022-01-01\t2022-01-01\t0\tintervention\n",
        "6\t78566733171147936\t2022-01-01\t2022-01-01\t0\tintervention\n",
        "7\t78566733171147936\t2022-01-01\t2022-01-04\t3\tintervention\n",
        "8\t78566733171147936\t2022-01-01\t2022-01-08\t7\tintervention\n",
        "9\t34330083524090108\t2022-01-01\t2022-01-01\t0\tcontrol\n",
        "전체 데이터 수: 7345\n",
        "\n",
        "[1] Day 1, 3, 5 리텐션 분석 및 KPI 산출\n",
        "리텐션 테이블 (전체):\n",
        "days_since_first_visit\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\n",
        "group\n",
        "control\t2525\t260\t182\t110\t101\t78\t63\t62\t44\t30\t21\t11\t11\t15\t18\n",
        "intervention\t2475\t347\t242\t191\t143\t105\t79\t70\t45\t21\t33\t18\t19\t13\t13\n",
        "리텐션 비율 (전체):\n",
        "days_since_first_visit\t0\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\t13\t14\n",
        "group\n",
        "control\t1.0\t0.102970\t0.072079\t0.043564\t0.040000\t0.030891\t0.024950\t0.024554\t0.017426\t0.011881\t0.008317\t0.004356\t0.004356\t0.005941\t0.007129\n",
        "intervention\t1.0\t0.140202\t0.097778\t0.077172\t0.057778\t0.042424\t0.031919\t0.028283\t0.018182\t0.008485\t0.013333\t0.007273\t0.007677\t0.005253\t0.005253\n",
        "Control Group Day 1 Retention: 10.30%\n",
        "Intervention Group Day 1 Retention: 14.02%\n",
        "Target for Intervention Group Day 1: 11.33%\n",
        "\n",
        "주별 리텐션 테이블:\n",
        "week_since_first_visit\t0\t1\t2\n",
        "group\n",
        "control\t2525\t186\t18\n",
        "intervention\t2475\t209\t13\n",
        "주별 리텐션 비율:\n",
        "week_since_first_visit\t0\t1\t2\n",
        "group\n",
        "control\t1.0\t0.073663\t0.007129\n",
        "intervention\t1.0\t0.084444\t0.005253\n",
        "Control Group Week 1 Retention: 7.37%\n",
        "Intervention Group Week 1 Retention: 8.44%\n",
        "Target for Intervention Group Week 1: 7.73%\n",
        "\n",
        "[2] A/B 테스트: Control vs Intervention 리텐션 곡선 비교\n",
        "\n",
        "[3] 전략 효과 검증: 초기 7일 내 집중적 개입 효과\n",
        "\n",
        "[4] 정성적 분석/외부 요인: (시뮬레이션에서는 추가 로그/메모 등으로 연계 분석 필요)\n",
        "→ 실제 환경에서는 사용자의 피드백, 마케팅 캠페인 로그, A/B 테스트 외 질적 데이터를 함께 분석하여\n",
        "   어떤 요인이 재방문률 개선에 기여했는지 종합적으로 판단해야 합니다.\n",
        "\n",
        "[최종 결론]\n",
        "가상 데이터 시뮬레이션 결과, 개선(Invention) 그룹은 초기 7일 내 Day 1 및 Week 1 리텐션에서\n",
        "컨트롤 그룹보다 높은 수치를 보입니다. 이는 온보딩 강화, 단기 리워드, 푸시 알림 등의\n",
        "전략이 초기 재참여율 개선에 긍정적인 효과가 있을 수 있음을 시사합니다.\n",
        "가상데이터와 기존 new_train.csv 데이터를 합치는 과정\n",
        "\n",
        "new_train.csv 파일에 있는 모든 컬럼을 유지하면서, 가상 데이터(synthetic_df)에\n",
        "\n",
        "new_train.csv에 없는 컬럼들을 결측치(NaN)로 채워 넣어 두 데이터셋의 구조를\n",
        "\n",
        "동일하게 맞춘 후 결합하여 train_final.csv로 저장\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. 기존 데이터(new_train.csv) 불러오기 (모든 컬럼 유지)\n",
        "df_main = pd.read_csv('new_train.csv', dtype={'fullVisitorId': str})\n",
        "\n",
        "# 2. 가상 데이터(synthetic_df) 생성\n",
        "# (이미 생성되어 있다면 아래 생성 코드는 생략 가능)\n",
        "np.random.seed(42)\n",
        "num_users = 5000\n",
        "user_ids = [str(np.random.randint(10**16, 10**17)) for _ in range(num_users)]\n",
        "first_date = pd.to_datetime(\"2022-01-01\")\n",
        "groups = np.random.choice([\"control\", \"intervention\"], size=num_users, p=[0.5, 0.5])\n",
        "\n",
        "# 컨트롤군과 개선군의 재방문 확률 설정 (예시)\n",
        "control_ret_probs = {\n",
        "    0: 1.0,\n",
        "    1: 0.10,\n",
        "    2: 0.07,\n",
        "    3: 0.05,\n",
        "    4: 0.04,\n",
        "    5: 0.03,\n",
        "    6: 0.025,\n",
        "    7: 0.02,\n",
        "    8: 0.015,\n",
        "    9: 0.012,\n",
        "    10: 0.01,\n",
        "    11: 0.008,\n",
        "    12: 0.007,\n",
        "    13: 0.006,\n",
        "    14: 0.005\n",
        "}\n",
        "intervention_ret_probs = {}\n",
        "for d, prob in control_ret_probs.items():\n",
        "    if d > 0 and d <= 7:\n",
        "        intervention_ret_probs[d] = min(prob * 1.5, 1.0)\n",
        "    else:\n",
        "        intervention_ret_probs[d] = prob\n",
        "\n",
        "data_rows = []\n",
        "for uid, group in zip(user_ids, groups):\n",
        "    # Day 0: 첫 방문은 항상 기록\n",
        "    data_rows.append({\n",
        "        \"fullVisitorId\": uid,\n",
        "        \"first_visit_date\": first_date,\n",
        "        \"date\": first_date,\n",
        "        \"days_since_first_visit\": 0,\n",
        "        \"group\": group\n",
        "    })\n",
        "    for d in range(1, 15):\n",
        "        if group == \"control\":\n",
        "            p = control_ret_probs.get(d, 0)\n",
        "        else:\n",
        "            p = intervention_ret_probs.get(d, 0)\n",
        "        if np.random.rand() < p:\n",
        "            visit_date = first_date + pd.Timedelta(days=d)\n",
        "            data_rows.append({\n",
        "                \"fullVisitorId\": uid,\n",
        "                \"first_visit_date\": first_date,\n",
        "                \"date\": visit_date,\n",
        "                \"days_since_first_visit\": d,\n",
        "                \"group\": group\n",
        "            })\n",
        "\n",
        "synthetic_df = pd.DataFrame(data_rows)\n",
        "\n",
        "# 3. new_train.csv와 synthetic_df의 컬럼 구조를 맞추기\n",
        "# new_train.csv의 모든 컬럼 리스트\n",
        "main_cols = df_main.columns.tolist()\n",
        "\n",
        "# synthetic_df에 new_train.csv에는 있지만 없는 컬럼을 추가 (기본값은 NaN)\n",
        "for col in main_cols:\n",
        "    if col not in synthetic_df.columns:\n",
        "        synthetic_df[col] = np.nan\n",
        "\n",
        "# 두 데이터프레임 모두 동일한 컬럼 순서로 정렬\n",
        "synthetic_df = synthetic_df[main_cols]\n",
        "\n",
        "# 4. 두 데이터프레임 결합\n",
        "train_final = pd.concat([df_main, synthetic_df], ignore_index=True)\n",
        "\n",
        "# 5. 최종 데이터 CSV 파일로 저장\n",
        "train_final.to_csv('train_final.csv', index=False)\n",
        "print(\"train_final.csv 파일이 생성되었습니다.\")\n",
        "\n",
        "     \n",
        "train_final.csv 파일이 생성되었습니다.\n",
        "원본데이터와 가상데이터를 합치는 과정과 결과\n",
        "원본 데이터 로드:\n",
        "\n",
        "new_train.csv 파일을 df_main이라는 DataFrame으로 읽어옴.\n",
        "\n",
        "이 단계에서는 원본 파일의 내용이 메모리로 복사되므로, 파일 자체는 변경되지 않음.\n",
        "\n",
        "가상 데이터(인위적으로 생성된 데이터) 생성:\n",
        "\n",
        "synthetic_df라는 DataFrame으로 가상 데이터를 생성\n",
        "\n",
        "이 가상 데이터는 원본 파일의 내용과는 별도로 메모리 내에서 만들어짐.\n",
        "\n",
        "컬럼 구조 정렬:\n",
        "\n",
        "df_main과 synthetic_df의 컬럼 구조를 맞추고, 순서를 동일하게 정렬\n",
        "\n",
        "이 작업은 두 DataFrame을 결합하기 위한 준비 단계일 뿐, 원본 파일에는 영향을 주지 않음.\n",
        "\n",
        "데이터프레임 결합 및 파일 저장:\n",
        "\n",
        "pd.concat() 함수를 사용해 원본 데이터(df_main)와 가상 데이터(synthetic_df)를 결합하여\n",
        "\n",
        "새로운 DataFrame인 train_final을 만듦.\n",
        "\n",
        "이 새로운 DataFrame을 train_final.csv라는 파일로 저장\n",
        "\n",
        "이 전체 과정은 메모리 상에서 데이터들을 조작하고 새로운 CSV 파일을 생성하는 작업\n",
        "\n",
        "즉, 원본 파일은 그대로 유지되며, 데이터가 추가된 내용은 새로 생성된 train_final.csv에만 반영.\n",
        "\n",
        "추가된 데이터(가상 데이터)로 인한 변경은 결합된 최종 파일에 반영된다는 의미이고,\n",
        "\n",
        "원본 데이터 내용은 변경되지 않음\n",
        "\n",
        "\n",
        "# 2. Google Colab에서 사용자가 직접 파일 다운로드\n",
        "from google.colab import files\n",
        "files.download('train_final.csv') -->\n",
        "     \n"
      ],
      "metadata": {
        "id": "Omu-a95IDepe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. pandas/geopandas 임포트\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "# 2. CSV 읽어서 DataFrame 생성\n",
        "crosswalk_df = pd.read_csv('강남구_횡단보도_WGS84.csv')\n",
        "streetlight_df = pd.read_csv('streetlight_lat_lon.csv')\n",
        "\n",
        "# 3. GeoDataFrame으로 변환 (WGS84)\n",
        "crosswalk_gdf = gpd.GeoDataFrame(\n",
        "    crosswalk_df,\n",
        "    geometry=gpd.points_from_xy(crosswalk_df['lon_wgs'], crosswalk_df['lat_wgs']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "streetlight_gdf = gpd.GeoDataFrame(\n",
        "    streetlight_df,\n",
        "    geometry=gpd.points_from_xy(streetlight_df['경도'], streetlight_df['위도']),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "# 4. 결과 확인\n",
        "print(crosswalk_gdf.head())\n",
        "print(streetlight_gdf.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L_i3fpwrzRB",
        "outputId": "14006ffd-2a03-4967-d416-abd098ff653f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  순번  자치구           관리번호     횡단보도종류                주소       교차로명  \\\n",
            "0         NaN   1  강남구  06-0000029779  일단(화살표없음)  강남구 역삼동 807-16 도          -   \n",
            "1         NaN   2  강남구  06-0000029780  일단(화살표없음)  강남구 역삼동 807-22 도          -   \n",
            "2         NaN   3  강남구  06-0000029781  일단(화살표없음)    강남구 논현동 29-5 대  논현지구대(연등)   \n",
            "3         NaN   4  강남구  06-0000029782  일단(화살표없음)      강남구 논현동 40 대          -   \n",
            "4         NaN   5  강남구  06-0000029783  일단(화살표있음)     강남구 개포동 185 대          -   \n",
            "\n",
            "             X좌표            Y좌표 도로구분     lon_wgs    lat_wgs  \\\n",
            "0  203980.959268  543978.492769   구도  127.045018  37.495255   \n",
            "1  203969.775125  543892.012018   구도  127.044891  37.494476   \n",
            "2  202383.780719  545913.958803   구도  127.026963  37.512700   \n",
            "3  202292.498840  545800.201730   구도  127.025930  37.511675   \n",
            "4  206292.296929  543350.190898   구도  127.071149  37.489582   \n",
            "\n",
            "                     geometry  \n",
            "0  POINT (127.04502 37.49526)  \n",
            "1  POINT (127.04489 37.49448)  \n",
            "2   POINT (127.02696 37.5127)  \n",
            "3  POINT (127.02593 37.51167)  \n",
            "4  POINT (127.07115 37.48958)  \n",
            "   【 보행등 】            X좌표            Y좌표 도로구분         위도          경도  \\\n",
            "0        1  205374.987783  544360.323503   시도  37.498689  127.060784   \n",
            "1        2  203974.362500  544362.818743   시도  37.498718  127.044945   \n",
            "2        3  202722.182394  544404.931452   시도  37.499102  127.030785   \n",
            "3        4  205839.814630  546182.133439   시도  37.515100  127.066056   \n",
            "4        5  207106.750000  544477.256243   시도  37.499731  127.080370   \n",
            "\n",
            "                     geometry  \n",
            "0  POINT (127.06078 37.49869)  \n",
            "1  POINT (127.04495 37.49872)  \n",
            "2   POINT (127.03078 37.4991)  \n",
            "3   POINT (127.06606 37.5151)  \n",
            "4  POINT (127.08037 37.49973)  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 필요한 라이브러리\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "# 1. 노인정 위치 정의\n",
        "# 1-a) 실제 CSV가 있을 때:\n",
        "# senior_df = pd.read_csv('senior_centers.csv')\n",
        "# senior_gdf = gpd.GeoDataFrame(\n",
        "#     senior_df,\n",
        "#     geometry=gpd.points_from_xy(senior_df.lon, senior_df.lat),\n",
        "#     crs='EPSG:4326'\n",
        "# )\n",
        "\n",
        "# 1-b) 샘플 데이터 사용 예시\n",
        "senior_data = [\n",
        "    {'name': '노인정 A', 'lon': 127.0359, 'lat': 37.4979},\n",
        "    {'name': '노인정 B', 'lon': 127.0452, 'lat': 37.5021}\n",
        "]\n",
        "senior_df = pd.DataFrame(senior_data)\n",
        "senior_gdf = gpd.GeoDataFrame(\n",
        "    senior_df,\n",
        "    geometry=gpd.points_from_xy(senior_df.lon, senior_df.lat),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "# 2. 생성 확인\n",
        "print(senior_gdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1bImJhZj91Z",
        "outputId": "299e1470-6d31-4083-9e50-72f2c1979b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    name       lon      lat                  geometry\n",
            "0  노인정 A  127.0359  37.4979  POINT (127.0359 37.4979)\n",
            "1  노인정 B  127.0452  37.5021  POINT (127.0452 37.5021)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4-1. 노인정 반경 300m & 경고 아이콘 (수정된 부분)\n",
        "for _, row in senior_proj.iterrows():\n",
        "    # 300m 버퍼\n",
        "    buf = row.geometry.buffer(300)\n",
        "    buf_wgs = gpd.GeoSeries([buf], crs=3857).to_crs(epsg=4326)\n",
        "    folium.GeoJson(\n",
        "        buf_wgs.__geo_interface__,\n",
        "        style_function=lambda f: {\n",
        "            'fillColor': 'orange',\n",
        "            'color': 'red',\n",
        "            'fillOpacity': 0.3,\n",
        "            'weight': 2\n",
        "        }\n",
        "    ).add_to(m)\n",
        "\n",
        "    # Shapely Point를 GeoSeries로 감싸서 WGS84로 변환\n",
        "    point_wgs = gpd.GeoSeries([row.geometry], crs=3857).to_crs(epsg=4326)[0]\n",
        "    lat, lon = point_wgs.y, point_wgs.x\n",
        "\n",
        "    folium.Marker(\n",
        "        location=[lat, lon],\n",
        "        icon=folium.Icon(icon='exclamation-triangle', prefix='fa', color='darkred'),\n",
        "        popup=row['name']\n",
        "    ).add_to(m)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "RPFAem6mD3bB",
        "outputId": "e2b2b39d-1253-4781-c392-a6f160784408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'senior_proj' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7479adb63755>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 4-1. 노인정 반경 300m & 경고 아이콘 (수정된 부분)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msenior_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# 300m 버퍼\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbuf_wgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3857\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'senior_proj' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install osmnx\n"
      ],
      "metadata": {
        "id": "qN54cdHbHSRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) pandas/geopandas 불러오기\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "# 2) CSV 읽어서 GeoDataFrame 생성\n",
        "streetlight_df = pd.read_csv('streetlight_lat_lon.csv')\n",
        "\n",
        "# 컬럼명이 한글인 경우:\n",
        "streetlight_gdf = gpd.GeoDataFrame(\n",
        "    streetlight_df,\n",
        "    geometry=gpd.points_from_xy(\n",
        "        streetlight_df['경도'],\n",
        "        streetlight_df['위도']\n",
        "    ),\n",
        "    crs='EPSG:4326'\n",
        ")\n",
        "\n",
        "# (선택) bounding box 확인\n",
        "print(\"streetlight bounds:\", streetlight_gdf.total_bounds)\n"
      ],
      "metadata": {
        "id": "gD9O19YyKpID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab 환경에서 OSMnx 설치\n",
        "!pip install osmnx\n"
      ],
      "metadata": {
        "id": "MrS7KmboMRb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "\n",
        "# streetlight_gdf가 이미 정의된 상태여야 합니다.\n",
        "minx, miny, maxx, maxy = streetlight_gdf.total_bounds\n",
        "north, south, east, west = maxy, miny, maxx, minx\n",
        "\n",
        "# (B) 복지관·병원\n",
        "tags_fac = {'amenity': ['hospital', 'clinic']}\n",
        "facilities = ox.geometries_from_bbox(north, south, east, west, tags_fac)\n",
        "other_gdf = (facilities\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# (C) 노인정\n",
        "tags_sen = {'social_facility': ['senior_centre']}\n",
        "seniors = ox.geometries_from_bbox(north, south, east, west, tags_sen)\n",
        "senior_gdf = (seniors\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# (D) 공원\n",
        "tags_park = {'leisure': ['park']}\n",
        "parks = ox.geometries_from_bbox(north, south, east, west, tags_park)\n",
        "parks_gdf = (parks\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# 결과 개수 확인\n",
        "print(\"복지시설 개수:\", len(other_gdf))\n",
        "print(\"노인정 개수:\",   len(senior_gdf))\n",
        "print(\"공원 개수:\",     len(parks_gdf))\n"
      ],
      "metadata": {
        "id": "6N6poqZNMkbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이렇게 표시된 지점들은 “고령자 주요 이동 장소(노인정)로부터 반경 300m 이내에 횡단보도가 하나도 없는 영역”이기 때문에, 교통약자인 고령자들이 보행 안전을 위해 횡단보도가 특히 필요하다\n",
        "\n",
        "오렌지색 버퍼: 해당 노인정 반경 300m 내에 기존 횡단보도 점이 전혀 없음을 나타냄\n",
        "\n",
        "빨간 삼각형 아이콘: 그 노인정 위치가 실제로 횡단보도 설치가 “급히” 필요한 곳임을 강조\n",
        "\n",
        "다만,\n",
        "\n",
        "반경과 데이터 품질(좌표 정확도, 노인정 위치, 기존 횡단보도 데이터)\n",
        "\n",
        "현장 여건(도로 폭, 교통량, 신호 주기 등)\n",
        "\n",
        "등을 종합적으로 검토해 최종 설치 우선순위를 결정하는 것이 좋다.\n",
        "현재 결과는 “우선적으로 점검·설치가 검토돼야 할 후보 지점”"
      ],
      "metadata": {
        "id": "TMsUWAqL1eyW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"고령자 주요 이동 경로 기반 분석\" 반영\n",
        "1. 분석 범위 확장 요소\n",
        "\n",
        "요소\t설명\n",
        "\n",
        "**노인정**\t기존에 포함된 주요 거점\n",
        "\n",
        "**복지관**\t고령자 복지서비스 제공 시설\n",
        "\n",
        "**병원/보건소**\t정기적 의료 방문지\n",
        "\n",
        "**공공장소**\t공원, 전통시장, 교회 등 고령자 빈번 방문지\n",
        "\n",
        "**고령자 실제 거주지**\t가능하면 주소 기반 인구 데이터 활용\n",
        "\n",
        "이동 경로 설정 기준 설명\n",
        "\n",
        "기준 1: 주요 시설 간 거리\n",
        "\n",
        "노인정 ↔ 복지관\n",
        "\n",
        "노인정 ↔ 병원\n",
        "\n",
        "복지관 ↔ 공원 등\n",
        "\n",
        "→ 500m 이하의 거리이면 보행 경로로 간주\n",
        "\n",
        "기준 2: 실제 도보 네트워크 (심화)\n",
        "\n",
        "OpenStreetMap의 도보 네트워크를 기반으로 osmnx로 경로 생성 가능\n",
        "\n",
        "고령자에게는 도보 10-15분(약 500~700m)이 실질 이동 범위\n",
        "\n",
        "기준 3: 단순화된 경로 (간단 구현용)\n",
        "\n",
        "LineString으로 주요 거점 간 직선 경로 생성 후, 해당 경로를 folium에 표시\n",
        "\n",
        "경로 주변 100m 버퍼에 횡단보도가 없으면 위험 구간으로 표기"
      ],
      "metadata": {
        "id": "gRxtFcZ6tGo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from shapely.geometry import Point, LineString\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 샘플 데이터\n",
        "# -------------------------------\n",
        "senior_data = [\n",
        "    {'name': '노인정 A', 'lon': 127.035, 'lat': 37.498},\n",
        "    {'name': '노인정 B', 'lon': 127.045, 'lat': 37.495}\n",
        "]\n",
        "\n",
        "other_places = [\n",
        "    {'name': '복지관 A', 'lon': 127.037, 'lat': 37.500},\n",
        "    {'name': '병원 B',   'lon': 127.040, 'lat': 37.493}\n",
        "]\n",
        "\n",
        "crosswalk_data = [\n",
        "    {'lon': 127.032, 'lat': 37.497},\n",
        "    {'lon': 127.043, 'lat': 37.492}\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# 2. GeoDataFrame 생성\n",
        "# -------------------------------\n",
        "senior_df = pd.DataFrame(senior_data)\n",
        "other_df = pd.DataFrame(other_places)\n",
        "crosswalk_df = pd.DataFrame(crosswalk_data)\n",
        "\n",
        "senior_gdf = gpd.GeoDataFrame(senior_df, geometry=gpd.points_from_xy(senior_df.lon, senior_df.lat), crs=\"EPSG:4326\")\n",
        "other_gdf = gpd.GeoDataFrame(other_df, geometry=gpd.points_from_xy(other_df.lon, other_df.lat), crs=\"EPSG:4326\")\n",
        "crosswalk_gdf = gpd.GeoDataFrame(crosswalk_df, geometry=gpd.points_from_xy(crosswalk_df.lon, crosswalk_df.lat), crs=\"EPSG:4326\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 좌표계 변환\n",
        "# -------------------------------\n",
        "senior_proj = senior_gdf.to_crs(epsg=3857)\n",
        "other_proj = other_gdf.to_crs(epsg=3857)\n",
        "cross_proj = crosswalk_gdf.to_crs(epsg=3857)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. 지도 생성\n",
        "# -------------------------------\n",
        "m = folium.Map(location=[37.5, 127.03], zoom_start=13, tiles=None)\n",
        "folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri World Imagery',\n",
        "    name='Satellite'\n",
        ").add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 노인정 반경 300m 분석\n",
        "# -------------------------------\n",
        "for idx, sr in senior_proj.iterrows():\n",
        "    buf = sr.geometry.buffer(300)\n",
        "    pts_in_buf = cross_proj[cross_proj.geometry.within(buf)]\n",
        "    if pts_in_buf.empty:\n",
        "        buf_wgs = gpd.GeoSeries([buf], crs=3857).to_crs(epsg=4326)\n",
        "        folium.GeoJson(\n",
        "            buf_wgs.__geo_interface__,\n",
        "            style_function=lambda f: {\n",
        "                'fillColor': 'orange',\n",
        "                'color': 'red',\n",
        "                'fillOpacity': 0.3,\n",
        "                'weight': 2\n",
        "            },\n",
        "            name=f\"{senior_df.loc[idx, 'name']} 주변 미설치\"\n",
        "        ).add_to(m)\n",
        "        folium.Marker(\n",
        "            location=[senior_df.loc[idx, 'lat'], senior_df.loc[idx, 'lon']],\n",
        "            icon=folium.Icon(icon='exclamation-triangle', prefix='fa', color='darkred'),\n",
        "            popup=f\"{senior_df.loc[idx, 'name']} 인근 횡단보도 필요\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 주요 경로(LineString) 시각화\n",
        "# -------------------------------\n",
        "lines = []\n",
        "for s in senior_proj.geometry:\n",
        "    for o in other_proj.geometry:\n",
        "        lines.append(LineString([s, o]))\n",
        "\n",
        "lines_gdf = gpd.GeoDataFrame(geometry=lines, crs=3857).to_crs(epsg=4326)\n",
        "\n",
        "for line in lines_gdf.geometry:\n",
        "    if line and not line.is_empty:\n",
        "        folium.PolyLine(\n",
        "            locations=[(pt[1], pt[0]) for pt in line.coords],\n",
        "            color='blue',\n",
        "            weight=2,\n",
        "            opacity=0.6,\n",
        "            tooltip=\"이동 경로\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 경로 주변 위험구간 (100m 버퍼)\n",
        "# -------------------------------\n",
        "for i, line in enumerate(lines):\n",
        "    buf = line.buffer(100)\n",
        "    hits = cross_proj[cross_proj.geometry.within(buf)]\n",
        "    if hits.empty:\n",
        "        folium.GeoJson(\n",
        "            gpd.GeoSeries([buf], crs=3857).to_crs(epsg=4326).__geo_interface__,\n",
        "            style_function=lambda f: {\n",
        "                'fillColor': 'red',\n",
        "                'color': 'black',\n",
        "                'fillOpacity': 0.2,\n",
        "                'weight': 1,\n",
        "            },\n",
        "            name=f\"위험 경로 {i+1}\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 8. 지도 저장 및 표시\n",
        "# -------------------------------\n",
        "m.save('senior_crosswalk_map.html')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('senior_crosswalk_map.html')\n"
      ],
      "metadata": {
        "id": "-WWJvxqL198G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 결과 요약\n",
        "\n",
        "다운로드된 HTML 파일은 다음 내용을 포함한 인터랙티브 위성지도입니다:\n",
        "\n",
        "노인정 위치 표시\n",
        "\n",
        "복지관 및 병원 등 주요 지점과 노인정 간 연결 경로(LineString) 표시\n",
        "\n",
        "300m 반경 내 횡단보도 미설치 구역: 붉은 원으로 강조\n",
        "\n",
        "이동 경로 주변 100m 내 횡단보도 미존재 시: 반투명 빨간 영역으로 위험 경로 강조\n",
        "\n",
        "Esri 위성지도 위에 Folium 마커와 경로 시각화\n",
        "\n",
        "| 단계                       | 설명                                                         | 사용 코드/기술                                           |\n",
        "| ------------------------ | ---------------------------------------------------------- | -------------------------------------------------- |\n",
        "| **1. 공간데이터 생성**          | `senior_df`, `other_df`, `crosswalk_df`를 GeoDataFrame으로 변환 | `geopandas.GeoDataFrame()`                         |\n",
        "| **2. 좌표계 변환**            | 거리 계산용 평면 좌표계(`EPSG:3857`)로 변환                             | `.to_crs(epsg=3857)`                               |\n",
        "| **3. Folium 지도 생성**      | 위성지도(`Esri World Imagery`) 생성, 서울 중심                       | `folium.Map(tiles=None)` + `folium.TileLayer(...)` |\n",
        "| **4. 300m 버퍼 분석**        | 노인정 위치에서 300m 원형 버퍼 생성                                     | `geometry.buffer(300)`                             |\n",
        "| **5. 횡단보도 미존재 시 시각화**    | 버퍼 내 횡단보도가 없으면 지도에 **붉은 원 + 경고 아이콘** 표시                    | `folium.GeoJson`, `folium.Marker(...)`             |\n",
        "| **6. 경로(LineString) 생성** | 노인정 ↔ 복지시설 간 직선 경로 생성                                      | `shapely.geometry.LineString()`                    |\n",
        "| **7. 경로 시각화**            | 위도/경도 좌표로 변환 후 지도에 파란 선으로 표시                               | `folium.PolyLine(...)`                             |\n",
        "| **8. 위험 경로 탐지**          | 경로 주변 100m 버퍼에 횡단보도 없으면 위험 영역 표시                           | `buffer(100)`, `folium.GeoJson(...)`               |\n",
        "| **9. HTML 저장**           | 지도를 HTML로 저장 후 Colab에서 다운로드                                | `m.save(...)`, `files.download(...)`               |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "79RtNbMuzolr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "from shapely.geometry import Point, LineString\n",
        "\n",
        "# -------------------------------\n",
        "# 1. 샘플 데이터\n",
        "# -------------------------------\n",
        "senior_data = [\n",
        "    {'name': '노인정 A', 'lon': 127.035, 'lat': 37.498},\n",
        "    {'name': '노인정 B', 'lon': 127.045, 'lat': 37.495}\n",
        "]\n",
        "\n",
        "other_places = [\n",
        "    {'name': '복지관 A', 'lon': 127.037, 'lat': 37.500},\n",
        "    {'name': '병원 B',   'lon': 127.040, 'lat': 37.493}\n",
        "]\n",
        "\n",
        "crosswalk_data = [\n",
        "    {'lon': 127.032, 'lat': 37.497},\n",
        "    {'lon': 127.043, 'lat': 37.492}\n",
        "]\n",
        "\n",
        "# -------------------------------\n",
        "# 2. GeoDataFrame 생성\n",
        "# -------------------------------\n",
        "senior_df = pd.DataFrame(senior_data)\n",
        "other_df = pd.DataFrame(other_places)\n",
        "crosswalk_df = pd.DataFrame(crosswalk_data)\n",
        "\n",
        "senior_gdf = gpd.GeoDataFrame(senior_df, geometry=gpd.points_from_xy(senior_df.lon, senior_df.lat), crs=\"EPSG:4326\")\n",
        "other_gdf = gpd.GeoDataFrame(other_df, geometry=gpd.points_from_xy(other_df.lon, other_df.lat), crs=\"EPSG:4326\")\n",
        "crosswalk_gdf = gpd.GeoDataFrame(crosswalk_df, geometry=gpd.points_from_xy(crosswalk_df.lon, crosswalk_df.lat), crs=\"EPSG:4326\")\n",
        "\n",
        "# -------------------------------\n",
        "# 3. 좌표계 변환\n",
        "# -------------------------------\n",
        "senior_proj = senior_gdf.to_crs(epsg=3857)\n",
        "other_proj = other_gdf.to_crs(epsg=3857)\n",
        "cross_proj = crosswalk_gdf.to_crs(epsg=3857)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Folium 위성지도 생성\n",
        "# -------------------------------\n",
        "m = folium.Map(location=[37.5, 127.03], zoom_start=13, tiles=None)\n",
        "folium.TileLayer(\n",
        "    tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',\n",
        "    attr='Esri World Imagery',\n",
        "    name='Satellite'\n",
        ").add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. 노인정 반경 300m 횡단보도 미설치 분석\n",
        "# -------------------------------\n",
        "for idx, sr in senior_proj.iterrows():\n",
        "    buf = sr.geometry.buffer(300)\n",
        "    pts_in_buf = cross_proj[cross_proj.geometry.within(buf)]\n",
        "    if pts_in_buf.empty:\n",
        "        buf_wgs = gpd.GeoSeries([buf], crs=3857).to_crs(epsg=4326)\n",
        "        folium.GeoJson(\n",
        "            buf_wgs.__geo_interface__,\n",
        "            style_function=lambda f: {\n",
        "                'fillColor': 'orange',\n",
        "                'color': 'red',\n",
        "                'fillOpacity': 0.3,\n",
        "                'weight': 2\n",
        "            },\n",
        "            name=f\"{senior_df.loc[idx, 'name']} 주변 미설치\"\n",
        "        ).add_to(m)\n",
        "        folium.Marker(\n",
        "            location=[senior_df.loc[idx, 'lat'], senior_df.loc[idx, 'lon']],\n",
        "            icon=folium.Icon(icon='exclamation-triangle', prefix='fa', color='darkred'),\n",
        "            popup=f\"{senior_df.loc[idx, 'name']} 인근 횡단보도 필요\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 6. 500m 이내 시설 간 보행 경로만 연결\n",
        "# -------------------------------\n",
        "lines = []\n",
        "\n",
        "# 노인정 ↔ 복지시설\n",
        "for i, s in senior_proj.iterrows():\n",
        "    for j, o in other_proj.iterrows():\n",
        "        dist = s.geometry.distance(o.geometry)\n",
        "        if dist <= 500:\n",
        "            lines.append(LineString([s.geometry, o.geometry]))\n",
        "\n",
        "# 복지시설 ↔ 복지시설\n",
        "for i in range(len(other_proj)):\n",
        "    for j in range(i + 1, len(other_proj)):\n",
        "        o1 = other_proj.iloc[i]\n",
        "        o2 = other_proj.iloc[j]\n",
        "        dist = o1.geometry.distance(o2.geometry)\n",
        "        if dist <= 500:\n",
        "            lines.append(LineString([o1.geometry, o2.geometry]))\n",
        "\n",
        "lines_gdf = gpd.GeoDataFrame(geometry=lines, crs=3857).to_crs(epsg=4326)\n",
        "\n",
        "# -------------------------------\n",
        "# 7. 경로 지도에 표시\n",
        "# -------------------------------\n",
        "for line in lines_gdf.geometry:\n",
        "    if line and not line.is_empty:\n",
        "        folium.PolyLine(\n",
        "            locations=[(pt[1], pt[0]) for pt in line.coords],\n",
        "            color='blue',\n",
        "            weight=2,\n",
        "            opacity=0.6,\n",
        "            tooltip=\"500m 이내 보행 경로\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 8. 위험 경로(횡단보도 없는 경우) 탐지\n",
        "# -------------------------------\n",
        "for i, line in enumerate(lines):\n",
        "    buf = line.buffer(100)\n",
        "    hits = cross_proj[cross_proj.geometry.within(buf)]\n",
        "    if hits.empty:\n",
        "        folium.GeoJson(\n",
        "            gpd.GeoSeries([buf], crs=3857).to_crs(epsg=4326).__geo_interface__,\n",
        "            style_function=lambda f: {\n",
        "                'fillColor': 'red',\n",
        "                'color': 'black',\n",
        "                'fillOpacity': 0.2,\n",
        "                'weight': 1,\n",
        "            },\n",
        "            name=f\"위험 경로 {i+1}\"\n",
        "        ).add_to(m)\n",
        "\n",
        "# -------------------------------\n",
        "# 9. 지도 저장 및 다운로드\n",
        "# -------------------------------\n",
        "m.save('senior_crosswalk_map_filtered.html')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('senior_crosswalk_map_filtered.html')\n",
        "m"
      ],
      "metadata": {
        "id": "QktAS1J803Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 시각화 요소        | 이미지 내 확인                                      | 설명                                                              |\n",
        "| ------------- | --------------------------------------------- | --------------------------------------------------------------- |\n",
        "| 🔺 **경고 아이콘** | **2개 존재**, 빨간 경고 삼각형 아이콘 확인됨                  | 각각의 아이콘은 **횡단보도가 300m 반경 내 존재하지 않는 노인정**을 나타냅니다.                |\n",
        "| 🔴 **원형 영역**  | 경고 아이콘 중심으로 **선명한 붉은 원 테두리**, 내부는 **반투명 주황색** | `geometry.buffer(300)`을 기반으로 생성된 **300m 위험 반경**입니다.             |\n",
        "| 🔵 **파란 선**   | 노인정 ↔ 상단에 위치한 다른 지점까지 **파란 직선 경로** 존재         | **직선 LineString 경로**이며, 이전 코드에서 `500m 이하일 때만 생성`되도록 필터링된 결과입니다. |\n",
        "| 🔴 **흐릿한 띠**  | 파란 선 경로를 중심으로 **타원형 붉은 음영 영역** 존재             | `buffer(100)`으로 생성된 **100m 경로 위험지대**로, 횡단보도가 없을 경우만 시각화됩니다.     |\n",
        "| 🌏 **지도 배경**  | 위성 이미지가 선명히 보이며, 거리와 건물 밀집도가 명확               | `Esri World Imagery` 위성지도 타일이 정상 적용된 상태입니다.                     |\n"
      ],
      "metadata": {
        "id": "ExX_HGso1WmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| 항목         | 설명                                                                 |\n",
        "| ---------- | ------------------------------------------------------------------ |\n",
        "| **데이터 소스** | `senior_data` (노인정), `other_places` (복지관 포함)                       |\n",
        "| **연결 방식**  | 각각의 노인정 포인트에서 복지관 포인트까지 거리 계산 후, **500m 이하일 경우에만** `LineString` 생성 |\n",
        "| **코드 반영**  |  \n",
        "                                                                  |\n",
        "for i, s in senior_proj.iterrows():\n",
        "    for j, o in other_proj.iterrows():\n",
        "        dist = s.geometry.distance(o.geometry)\n",
        "        if dist <= 500:\n",
        "            lines.append(LineString([s.geometry, o.geometry]))\n",
        "\n",
        "| 시각화 방식 | 파란색 실선 (folium.PolyLine)으로 지도에 표시 |\n",
        "\n",
        "노인정 ↔ 병원\n",
        "\n",
        "| 항목         | 설명                                                               |\n",
        "| ---------- | ---------------------------------------------------------------- |\n",
        "| **데이터 소스** | `other_places` 내부에 병원 포함 (`{'name': '병원 B'}`)                    |\n",
        "| **연결 방식**  | 복지관과 동일하게, 병원도 `other_proj`에 포함되어 노인정과 거리 비교 대상에 포함됨             |\n",
        "| **코드 반영**  | 위의 `senior_proj ↔ other_proj` 루프에서 병원도 비교 대상이므로 **동일한 로직 내 포함**됨 |\n",
        "| **시각화 방식** | 동일하게 파란 실선 (`folium.PolyLine`)으로 지도에 표시됨                         |\n",
        "\n",
        "복지관 ↔ 공원\n",
        "\n",
        "| 항목         | 설명                                                |\n",
        "| ---------- | ------------------------------------------------- |\n",
        "| **데이터 소스** | 현재 코드에는 `공원` 데이터는 포함되어 있지 않음                      |\n",
        "| **연결 방식**  | `복지관 ↔ 복지관` 또는 `복지시설 ↔ 복지시설` 간 거리 500m 이하인 경우 연결됨 |\n",
        "| **코드 반영**  |                                                   |\n",
        "\n",
        "for i in range(len(other_proj)):\n",
        "\n",
        "    for j in range(i + 1, len(other_proj)):\n",
        "\n",
        "        o1 = other_proj.iloc[i]\n",
        "\n",
        "        o2 = other_proj.iloc[j]\n",
        "\n",
        "        dist = o1.geometry.distance(o2.geometry)\n",
        "\n",
        "        if dist <= 500:\n",
        "\n",
        "            lines.append(LineString([o1.geometry, o2.geometry]))\n",
        "\n",
        "| 공원 연결의 현재 상태 | X\n",
        "공원이 현재 데이터에 포함되지 않아\n",
        "\n",
        "복지관 ↔ 공원 연결은 코드상 불가능함 |\n",
        "\n",
        "| 향후 확장 방식 | other_places에 공원 좌표(예: {'name': '공원 A', 'lon': ..., 'lat': ...})를 추가하고,\n",
        "\n",
        " 위 로직에 포함시키면 연결 가능 |\n",
        "\n",
        " | 연결 기준     | 반영 여부 | 데이터 기준                      | 구현 설명                  |\n",
        "| --------- | ----- | --------------------------- | ---------------------- |\n",
        "| 노인정 ↔ 복지관 | O     | `senior_proj`, `other_proj` | 거리 500m 이하 필터링 후 직선 연결 |\n",
        "| 노인정 ↔ 병원  | O     | 병원 포함된 `other_proj`         | 동일한 거리 기반 필터링 및 연결     |\n",
        "| 복지관 ↔ 공원  | X     | 공원 데이터 미포함                  | 데이터 추가 필요 (확장 가능)      |\n",
        "\n"
      ],
      "metadata": {
        "id": "MICxLlKV2jLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 공원 데이터 추가\n",
        "parks = [{'name': '공원 A', 'lon': 127.041, 'lat': 37.496}]\n",
        "parks_df = pd.DataFrame(parks)\n",
        "\n",
        "# 2. GeoDataFrame 변환 및 복지시설과 병합\n",
        "parks_gdf = gpd.GeoDataFrame(\n",
        "    parks_df,\n",
        "    geometry=gpd.points_from_xy(parks_df.lon, parks_df.lat),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "combined_gdf = pd.concat([other_gdf, parks_gdf], ignore_index=True)\n",
        "combined_proj = combined_gdf.to_crs(epsg=3857)\n",
        "\n",
        "# 3. 200m 초과 거리만 연결\n",
        "lines = []\n",
        "for i in range(len(combined_proj)):\n",
        "    for j in range(i + 1, len(combined_proj)):\n",
        "        p1 = combined_proj.iloc[i]\n",
        "        p2 = combined_proj.iloc[j]\n",
        "        dist = p1.geometry.distance(p2.geometry)\n",
        "        if dist > 200:  # 수정된 거리 조건\n",
        "            lines.append(LineString([p1.geometry, p2.geometry]))\n",
        "\n",
        "# 4. EPSG:4326으로 되돌리고 지도에 표시\n",
        "lines_gdf = gpd.GeoDataFrame(geometry=lines, crs=3857).to_crs(epsg=4326)\n",
        "\n",
        "for line in lines_gdf.geometry:\n",
        "    folium.PolyLine(\n",
        "        locations=[(pt[1], pt[0]) for pt in line.coords],\n",
        "        color='green',\n",
        "        weight=2,\n",
        "        opacity=0.6,\n",
        "        tooltip=\"거리 > 200m 경로\"\n",
        "    ).add_to(m)\n",
        "m"
      ],
      "metadata": {
        "id": "N6HgyDBQ1Y7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"연결된 LineString 수: {len(lines)}\")\n"
      ],
      "metadata": {
        "id": "tpcvGbJ47WqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(combined_proj)):\n",
        "    for j in range(i + 1, len(combined_proj)):\n",
        "        p1 = combined_proj.iloc[i]\n",
        "        p2 = combined_proj.iloc[j]\n",
        "        dist = p1.geometry.distance(p2.geometry)\n",
        "        print(f\"{p1['name']} ↔ {p2['name']} 거리: {dist:.1f}m\")\n",
        "        if dist > 200:\n",
        "            lines.append(LineString([p1.geometry, p2.geometry]))\n"
      ],
      "metadata": {
        "id": "UUZRgRr89hLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 이런 결과값 근거 데이터\n",
        "\n",
        "**1. 데이터 출처**\n",
        "\n",
        "횡단보도 위치 정보\n",
        "\n",
        "파일: 서울특별시_자치구별 신호등 및 횡단보도 위치 및 현황_20230530.xlsx\n",
        "\n",
        "제공기관: 서울열린데이터광장\n",
        "\n",
        "수집일자: 2023-05-30\n",
        "\n",
        "노인정 위치 정보\n",
        "\n",
        "(예시) senior_data 리스트에 수집된 위경도 좌표\n",
        "\n",
        "출처: 시·구청 공공복지시설 목록 또는 직접 현장 조사\n",
        "\n",
        "**2. 전처리 및 좌표 변환**\n",
        "\n",
        "강남구 필터링\n",
        "\n",
        "“자치구” 컬럼에서 == '강남구' 로 레코드를 추출\n",
        "\n",
        "투영 좌표 → WGS84 변환\n",
        "\n",
        "원본 X/Y는 서울 TM(중부벨트) EPSG:5186 기준 미터 단위\n",
        "\n",
        "Transformer.from_crs(\"epsg:5186\",\"epsg:4326\") 로 위도/경도로 일괄 변환\n",
        "\n",
        "노인정 GeoDataFrame\n",
        "\n",
        "senior_df 에서 직접 정의한 노인정 위경도를 GeoDataFrame으로 생성\n",
        "\n",
        "\n",
        "**3. 분석 방법**\n",
        "\n",
        "**버퍼 생성:** 각 노인정 위치에서 반경 300m 버퍼 생성\n",
        "\n",
        "**교차점 확인:**\n",
        "\n",
        "crosswalk_gdf (강남구 횡단보도 지점) 를 WebMercator 투영(3857) 후\n",
        "\n",
        "각 노인정 버퍼 안에 횡단보도 점이 하나도 없는 경우만 필터\n",
        "\n",
        "**표시 기준:**\n",
        "\n",
        "## 버퍼 안에 기존 횡단보도가 없으면 → “횡단보도 설치 필요 구역”그 노인정 위치 → “급히 설치해야 할 지점”\n",
        "\n",
        "**4. 시각화 결과**\n",
        "\n",
        "**오렌지색 반투명 폴리곤**\n",
        "\n",
        "노인정 반경 300m 이내에 횡단보도 점이 전혀 없는 영역\n",
        "\n",
        "**빨간 경고 아이콘**\n",
        "\n",
        "해당 노인정 자체 위치에 “횡단보도 설치가 시급”함을 강조\n",
        "\n",
        "\n",
        "이 분석은\n",
        "\n",
        "고령자 보행 안전권 확보를 위해,\n",
        "\n",
        "실제 노인정 이용 동선을 고려하여,\n",
        "\n",
        "반경 300m 이내 보행 거리에 횡단보도가 없는 곳을\n",
        "찾아낸 것입니다.\n",
        "\n",
        "따라서 지도의 오렌지 영역과 경고 아이콘으로 표시된 지점들은\n",
        "**“고령자가 보행 중 반드시 횡단보도가 필요하다”**는 근거 기반 우선 설치 후보지 입니다."
      ],
      "metadata": {
        "id": "CDJDLztU2eyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각적 해석\n",
        "\n",
        "| 시각 요소     | 내용                                                |\n",
        "| --------- | ------------------------------------------------- |\n",
        "| 🔺 경고 아이콘 | 2개의 노인정 (횡단보도 300m 이내 미존재)                        |\n",
        "| 🔴 반경 원   | 각 노인정을 중심으로 300m 위험 반경 (orange fill + red border) |\n",
        "| 🟢 초록 실선  | 거리 **200m 초과**인 복지시설(복지관, 병원)과 공원 간 연결            |\n",
        "| 🌏 배경     | Esri World Imagery 위성지도                           |\n",
        "\n",
        "생성 기준 및 코드 근거\n",
        "\n",
        "| 항목           | 기준                                 | 코드 반영                                          |\n",
        "| ------------ | ---------------------------------- | ---------------------------------------------- |\n",
        "| **노인정 반경**   | 300m 내 횡단보도 없음 시 위험 표시             | `geometry.buffer(300)`                         |\n",
        "| **보행 경로 연결** | 복지관/병원 ↔ 공원 간 거리 **200m 초과 시만** 연결 | `if dist > 200: lines.append(LineString(...))` |\n",
        "| **지도 출력**    | 초록색 선으로 표시                         | `folium.PolyLine(..., color='green')`          |\n",
        "\n",
        "근거 데이터 출처\n",
        "\n",
        "senior_df – 노인정 위경도 수기 입력\n",
        "\n",
        "other_df – 복지관 및 병원 위경도\n",
        "\n",
        "parks_df – 공원 A (127.041, 37.496)\n",
        "\n",
        "crosswalk_df – 횡단보도 위치\n",
        "\n",
        "\n",
        "시각적 해석\n",
        "\n",
        "| 시각 요소     | 내용                                       |\n",
        "| --------- | ---------------------------------------- |\n",
        "| 🔺 경고 아이콘 | 2개의 노인정 (횡단보도 미존재)                       |\n",
        "| 🔴 반경 원   | 노인정 중심 300m 영역 (위험 지역)                   |\n",
        "| 🔵 보행 연결선 | 복지시설 간 파란 LineString – **500m 이하 거리 기준** |\n",
        "| 🔴 흐릿한 띠  | 보행 연결 경로 주변 100m 이내 횡단보도 없음 → 위험 경로로 표시  |\n",
        "\n",
        "생성 기준 및 코드 근거\n",
        "\n",
        "| 항목                | 기준                                        | 코드 반영              |\n",
        "| ----------------- | ----------------------------------------- | ------------------ |\n",
        "| **노인정 ↔ 복지시설 연결** | 거리 ≤ 500m                                 | `if dist <= 500`   |\n",
        "| **경로 주변 위험 감지**   | 경로 주변 100m 내 횡단보도 없음 시 위험 버퍼 표시           | `line.buffer(100)` |\n",
        "| **지도 출력**         | `folium.GeoJson(..., style_function=...)` |                    |\n",
        "\n",
        "근거 데이터 출처\n",
        "\n",
        "위와 동일 (단, parks_df 미포함 시점)\n",
        "\n",
        "senior_proj, other_proj, cross_proj에 기반하여 거리 계산 및 위험 판단 수행\n",
        "\n",
        "**두 이미지 비교 요약**\n",
        "\n",
        "| 항목       | 이미지 1 (후속)        | 이미지 2 (초기)       |\n",
        "| -------- | ----------------- | ---------------- |\n",
        "| 연결 거리 기준 | **200m 초과만 연결**   | **500m 이하만 연결**  |\n",
        "| 연결 대상    | 복지관/병원 ↔ 공원 포함    | 복지관/병원 간만 연결     |\n",
        "| 색상       | 초록색 선 (`green`)   | 파란색 선 (`blue`)   |\n",
        "| 위험 경로 버퍼 | ❌ 표시되지 않음 (선만 존재) | ✅ 100m 위험 경로 표시됨 |\n",
        "| 공원 반영 여부 | ✅ 포함 (`공원 A`)     | ❌ 미포함            |\n",
        "\n",
        "# 거리 계산용 좌표계 변환\n",
        "combined_proj = combined_gdf.to_crs(epsg=3857)\n",
        "\n",
        "# 거리 기준\n",
        "dist = p1.geometry.distance(p2.geometry)\n",
        "if dist > 200:\n",
        "    lines.append(LineString([p1.geometry, p2.geometry]))\n",
        "\n",
        "# 지도 시각화\n",
        "folium.PolyLine(\n",
        "    locations=[(pt[1], pt[0]) for pt in line.coords],\n",
        "    color='green',\n",
        "    tooltip=\"거리 > 200m 경로\"\n",
        ").add_to(m)\n",
        "\n",
        "ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ\n",
        "\n",
        "# 업로드한 두 이미지는 거리 기준 변경 전후 또는 공원 포함 여부에 따른 시각적 결과\n",
        "\n",
        "차이를 보여주며,\n",
        "\n",
        "각각의 지도는 코드에서 설정한 거리 조건(>200m, ≤500m) 및 시각화 색상(green, blue)을 정확히 반영하고 있습니다.\n",
        "\n",
        "또한 노인정 주변 300m 위험 반경 및 경로 주변 100m 위험 버퍼까지도 조건에 맞게 시각화되어 있으며,\n",
        "\n",
        "공원 데이터는 후속 결과(초록 선)에서만 포함되었습니다."
      ],
      "metadata": {
        "id": "iD_BMzeq-X-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5/21일 강남구_횡단보도_WGS84.csv  /    streetlight_lat_lon.csv\n",
        "두 파일"
      ],
      "metadata": {
        "id": "CUO3icmwkUca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "\n",
        "# streetlight_gdf가 이미 정의된 상태여야 합니다.\n",
        "minx, miny, maxx, maxy = streetlight_gdf.total_bounds\n",
        "north, south, east, west = maxy, miny, maxx, minx\n",
        "\n",
        "# (B) 복지관·병원\n",
        "tags_fac = {'amenity': ['hospital', 'clinic']}\n",
        "facilities = ox.geometries_from_bbox(north, south, east, west, tags_fac)\n",
        "other_gdf = (facilities\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# (C) 노인정\n",
        "tags_sen = {'social_facility': ['senior_centre']}\n",
        "seniors = ox.geometries_from_bbox(north, south, east, west, tags_sen)\n",
        "senior_gdf = (seniors\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# (D) 공원\n",
        "tags_park = {'leisure': ['park']}\n",
        "parks = ox.geometries_from_bbox(north, south, east, west, tags_park)\n",
        "parks_gdf = (parks\n",
        "    .reset_index()\n",
        "    .to_crs(epsg=4326)[['name','geometry']]\n",
        "    .dropna(subset=['name'])\n",
        ")\n",
        "\n",
        "# 결과 개수 확인\n",
        "print(\"복지시설 개수:\", len(other_gdf))\n",
        "print(\"노인정 개수:\",   len(senior_gdf))\n",
        "print(\"공원 개수:\",     len(parks_gdf))\n"
      ],
      "metadata": {
        "id": "VdrY07Ce2Npj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}